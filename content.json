[{"title":"前端通过增加XHR钩子来全局增加header","date":"2023-12-26T16:00:00.000Z","path":"编程/前端通过增加XHR钩子来全局增加header/","text":"引言前端通过修改 XHR 原型来全局增加 header 是采用 XMLHttpRequest 加 hook 方式实现一个简单业务场景。这样可以提高代码的可维护性和可扩展性，减少重复代码的编写。 比如，在用户登录后，后端返回了一个 token，前端需要在发送的每个请求中都携带这个 token 以进行认证。通过修改 XHR 原型来全局增加 header，可以实现全局性的认证信息添加，无需在每个请求中手动设置 header。 模拟接口请求 mock 参数的时候也需要全局拦截 xhr 请求，这个时候就需要 hook 对应的 send、open 函数了。 hook钩子函数在JavaScript中，”hook”（钩子）是一种编程模式，它允许开发者在特定的代码执行点插入自定义的逻辑。钩子函数是用于在这些执行点执行自定义逻辑的函数。 钩子函数通常被设计成可拦截或修改某个操作的执行流程。它们允许开发者在关键步骤中插入自定义的代码，以满足特定的需求，例如添加额外的验证、修改数据、记录日志等。 在JavaScript中，钩子函数可以通过以下两种方式实现： 使用原生提供的钩子函数：有些JavaScript库或框架提供了一些特定的钩子函数，供开发者在特定的时机插入自己的代码。例如，在Vue.js中，可以使用created钩子函数在实例被创建后执行自定义逻辑。 12345new Vue(&#123; created() &#123; // 自定义逻辑 &#125;&#125;); 自定义钩子函数：开发者可以根据需要在自己的代码中定义钩子函数。这些钩子函数可以是普通的函数，在代码的特定位置被调用。例如，在一个JavaScript类中，可以定义一个钩子方法，用于执行一些特定的逻辑。 12345678910111213141516171819202122class MyClass &#123; constructor() &#123; // 构造函数 &#125; beforeMethod() &#123; // 在方法执行之前执行的钩子函数 &#125; myMethod() &#123; this.beforeMethod(); // 在方法执行之前调用钩子函数 // 方法的实际逻辑 this.afterMethod(); // 在方法执行之后调用钩子函数 &#125; afterMethod() &#123; // 在方法执行之后执行的钩子函数 &#125;&#125;const instance = new MyClass();instance.myMethod(); // 执行方法，同时触发钩子函数 通过使用钩子函数，开发者可以在适当的时机执行自定义的逻辑，以满足特定的需求。这种模式提供了更大的灵活性和可扩展性，并允许代码的修改不影响原有的执行流程。 编程例子通过hook方式实现修改XMLHttpRequest的send或者open函数来全局增加header。 方式一，采用闭包修改钩子函数： 123456789101112(function (open, send) &#123; XMLHttpRequest.prototype.open = function () &#123; open.apply(this, arguments); &#125;; XMLHttpRequest.prototype.send = function () &#123; /** * 接口请求前增加自定义业务逻辑处理 */ this.setRequestHeader(&quot;diyHeader&quot;, &quot;diyHeader666666666&quot;); send.apply(this, arguments); &#125;;&#125;)(XMLHttpRequest.prototype.open, XMLHttpRequest.prototype.send); 方式二，通过hook自定义函数修改： 1234567891011function hookXhr(func) &#123; const origin = func; return function () &#123; // arguments 是一个对应于传递给函数的参数的类数组对象。 console.log(arguments); this.setRequestHeader(&quot;diyHeader&quot;, &quot;diyHeader666666666&quot;); return origin.apply(this, arguments); &#125;;&#125;XMLHttpRequest.prototype.send = hookXhr(XMLHttpRequest.prototype.send);// XMLHttpRequest.prototype.open = hookXhr(XMLHttpRequest.prototype.open); tips编程语言中，比如 Java，是支持将方法声明为私有的，即它们只能被同一个类中的其他方法所调用。 而 JavaScript 没有这种原生支持，但我们可以使用闭包来模拟私有方法。私有方法不仅仅有利于限制对代码的访问：还提供了管理全局命名空间的强大能力，避免非核心的方法弄乱了代码的公共接口部分。 下面的示例展现了如何使用闭包来定义公共函数，并令其可以访问私有函数和变量。这个方式也称为模块模式（module pattern）： 123456789101112131415161718192021222324252627var makeCounter = function () &#123; var privateCounter = 0; function changeBy(val) &#123; privateCounter += val; &#125; return &#123; increment: function () &#123; changeBy(1); &#125;, decrement: function () &#123; changeBy(-1); &#125;, value: function () &#123; return privateCounter; &#125;, &#125;;&#125;;var Counter1 = makeCounter();var Counter2 = makeCounter();console.log(Counter1.value()); /* logs 0 */Counter1.increment();Counter1.increment();console.log(Counter1.value()); /* logs 2 */Counter1.decrement();console.log(Counter1.value()); /* logs 1 */console.log(Counter2.value()); /* logs 0 */ 请注意两个计数器 Counter1 和 Counter2 是如何维护它们各自的独立性的。每个闭包都是引用自己词法作用域内的变量 privateCounter 。 每次调用其中一个计数器时，通过改变这个变量的值，会改变这个闭包的词法环境。然而在一个闭包内对变量的修改，不会影响到另外一个闭包中的变量。 参考 mdn xhr setRequestHeader mdn 闭包","tags":[]},{"title":"Java高并发编程基础之Thread构造函数大有内涵","date":"2023-12-26T16:00:00.000Z","path":"高并发编程基础/03-Thread构造函数使用说明/","text":"引言在Java中，Thread类提供了许多丰富的构造函数，以便于创建和管理线程。使得可以根据具体需求来创建和配置线程对象，从而实现更灵活、可扩展的多线程编程。 Thread类的无参构造函数可以创建一个新的线程对象，然后通过调用start()方法来启动线程的执行。 Thread类提供了其他一些常用的构造函数。例如，可以使用带有Runnable参数的构造函数来创建一个线程对象，并传入一个实现了Runnable接口的对象，从而指定线程要执行的任务。这种方式更常用，因为它可以使得代码更具可重用性和灵活性。 Thread类提供了带有线程名称、线程优先级等参数的构造函数，可以通过这些构造函数来设置线程的属性。 使用带有ThreadGroup参数的构造函数将线程添加到特定的线程组中。线程组可以方便地对一组线程进行管理和控制。 Thread的构造函数1234567891011121314151617181920212223242526272829303132333435363738394041public Thread() &#123; this(null, null, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(Runnable target) &#123; this(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;Thread(Runnable target, @SuppressWarnings(&quot;removal&quot;) AccessControlContext acc) &#123; this(null, target, &quot;Thread-&quot; + nextThreadNum(), 0, acc, false);&#125;public Thread(ThreadGroup group, Runnable target) &#123; this(group, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(String name) &#123; this(null, null, name, 0);&#125;public Thread(ThreadGroup group, String name) &#123; this(group, null, name, 0);&#125;public Thread(Runnable target, String name) &#123; this(null, target, name, 0);&#125;public Thread(ThreadGroup group, Runnable target, String name) &#123; this(group, target, name, 0);&#125;public Thread(ThreadGroup group, Runnable target, String name, long stackSize) &#123; this(group, target, name, stackSize, null, true);&#125;public Thread(ThreadGroup group, Runnable target, String name, long stackSize, boolean inheritThreadLocals) &#123; this(group, target, name, stackSize, null, inheritThreadLocals);&#125; 线程的命名在构造线程的时候可以为线程起一个有特殊意义的名字，这也是比较好的一种做法。尤其在一个线程比较多的程序中，为线程赋予一个包含特殊意义的名字有助于问题的排查和线程的跟踪，强烈推荐在构造线程的时候赋予它一个名字。 线程的默认命名使用Thread有的构造函数没有提供名称的参数，这个时候系统会生成一个默认的线程名称。默认的名称都是 Thread-加上线程编码数字 。以下是比较常用的不带线程名称的构造器函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Allocates a new &#123;@code Thread&#125; object. This constructor has the same * effect as &#123;@linkplain #Thread(ThreadGroup,Runnable,String) Thread&#125; * &#123;@code (null, null, gname)&#125;, where &#123;@code gname&#125; is a newly generated * name. Automatically generated names are of the form * &#123;@code &quot;Thread-&quot;+&#125;&lt;i&gt;n&lt;/i&gt;, where &lt;i&gt;n&lt;/i&gt; is an integer. */public Thread() &#123; this(null, null, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;/** * Allocates a new &#123;@code Thread&#125; object. This constructor has the same * effect as &#123;@linkplain #Thread(ThreadGroup,Runnable,String) Thread&#125; * &#123;@code (null, target, gname)&#125;, where &#123;@code gname&#125; is a newly generated * name. Automatically generated names are of the form * &#123;@code &quot;Thread-&quot;+&#125;&lt;i&gt;n&lt;/i&gt;, where &lt;i&gt;n&lt;/i&gt; is an integer. * * @param target * the object whose &#123;@code run&#125; method is invoked when this thread * is started. If &#123;@code null&#125;, this classes &#123;@code run&#125; method does * nothing. */public Thread(Runnable target) &#123; this(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;/** * Allocates a new &#123;@code Thread&#125; object. This constructor has the same * effect as &#123;@linkplain #Thread(ThreadGroup,Runnable,String) Thread&#125; * &#123;@code (group, target, gname)&#125; ,where &#123;@code gname&#125; is a newly generated * name. Automatically generated names are of the form * &#123;@code &quot;Thread-&quot;+&#125;&lt;i&gt;n&lt;/i&gt;, where &lt;i&gt;n&lt;/i&gt; is an integer. * * @param group * the thread group. If &#123;@code null&#125; and there is a security * manager, the group is determined by &#123;@linkplain * SecurityManager#getThreadGroup SecurityManager.getThreadGroup()&#125;. * If there is not a security manager or &#123;@code * SecurityManager.getThreadGroup()&#125; returns &#123;@code null&#125;, the group * is set to the current thread&#x27;s thread group. * * @param target * the object whose &#123;@code run&#125; method is invoked when this thread * is started. If &#123;@code null&#125;, this thread&#x27;s run method is invoked. * * @throws SecurityException * if the current thread cannot create a thread in the specified * thread group */public Thread(ThreadGroup group, Runnable target) &#123; this(group, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125; 命名线程构造函数提供了name作为线程名称的参数用于初始化构造函数，开发过程提供名称更利于问题的排查。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475 /** * Allocates a new &#123;@code Thread&#125; object. This constructor has the same * effect as &#123;@linkplain #Thread(ThreadGroup,Runnable,String) Thread&#125; * &#123;@code (null, null, name)&#125;. * * @param name * the name of the new thread */ public Thread(String name) &#123; this(null, null, name, 0); &#125;/** * Allocates a new &#123;@code Thread&#125; object. This constructor has the same * effect as &#123;@linkplain #Thread(ThreadGroup,Runnable,String) Thread&#125; * &#123;@code (group, null, name)&#125;. * * @param group * the thread group. If &#123;@code null&#125; and there is a security * manager, the group is determined by &#123;@linkplain * SecurityManager#getThreadGroup SecurityManager.getThreadGroup()&#125;. * If there is not a security manager or &#123;@code * SecurityManager.getThreadGroup()&#125; returns &#123;@code null&#125;, the group * is set to the current thread&#x27;s thread group. * * @param name * the name of the new thread * * @throws SecurityException * if the current thread cannot create a thread in the specified * thread group */ public Thread(ThreadGroup group, String name) &#123; this(group, null, name, 0); &#125; /** * Allocates a new &#123;@code Thread&#125; object. This constructor has the same * effect as &#123;@linkplain #Thread(ThreadGroup,Runnable,String) Thread&#125; * &#123;@code (null, target, name)&#125;. * * @param target * the object whose &#123;@code run&#125; method is invoked when this thread * is started. If &#123;@code null&#125;, this thread&#x27;s run method is invoked. * * @param name * the name of the new thread */ public Thread(Runnable target, String name) &#123; this(null, target, name, 0); &#125; /** * * @param group * the thread group. If &#123;@code null&#125; and there is a security * manager, the group is determined by &#123;@linkplain * SecurityManager#getThreadGroup SecurityManager.getThreadGroup()&#125;. * If there is not a security manager or &#123;@code * SecurityManager.getThreadGroup()&#125; returns &#123;@code null&#125;, the group * is set to the current thread&#x27;s thread group. * * @param target * the object whose &#123;@code run&#125; method is invoked when this thread * is started. If &#123;@code null&#125;, this thread&#x27;s run method is invoked. * * @param name * the name of the new thread * * @throws SecurityException * if the current thread cannot create a thread in the specified * thread group or cannot override the context class loader methods. */ public Thread(ThreadGroup group, Runnable target, String name) &#123; this(group, target, name, 0); &#125; 修改线程的名字不论使用的是默认的函数命名规则，还是指定了一个特殊的名字，在线程启动之前还有一个机会可以对其进行修改，一旦线程启动，名字将不再被修改，下面是 Thread 的 setName 源码: 123456789101112131415161718192021222324/** * Changes the name of this thread to be equal to the argument &#123;@code name&#125;. * &lt;p&gt; * First the &#123;@code checkAccess&#125; method of this thread is called * with no arguments. This may result in throwing a * &#123;@code SecurityException&#125;. * * @param name the new name for this thread. * @throws SecurityException if the current thread cannot modify this * thread. * @see #getName * @see #checkAccess() */public final synchronized void setName(String name) &#123; checkAccess(); if (name == null) &#123; throw new NullPointerException(&quot;name cannot be null&quot;); &#125; this.name = name; if (threadStatus != 0) &#123; setNativeName(name); &#125;&#125; 线程的父子关系Thread的所有构造函数，最终都会去调用一个内部方法init（JDK8）或者同一个构造函数java.lang.Thread#Thread(java.lang.ThreadGroup, java.lang.Runnable, java.lang.String, long, java.security.AccessControlContext, boolean)（JDK17）用于线程的真实创建，通过源码发现新创建的任何一个线程都会有一个父线程。 以JDK17创建线程的源码为例： Thread parent = currentThread(); // 调用获取当前线程函数 this.daemon = parent.isDaemon();// 通过父线程守护参数设置当前线程守护线程参数 this.priority = parent.getPriority();// 通过父线程参数设置当前线程优先级参数 完整源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * Initializes a Thread. * * @param g the Thread group * @param target the object whose run() method gets called * @param name the name of the new Thread * @param stackSize the desired stack size for the new thread, or * zero to indicate that this parameter is to be ignored. * @param acc the AccessControlContext to inherit, or * AccessController.getContext() if null * @param inheritThreadLocals if &#123;@code true&#125;, inherit initial values for * inheritable thread-locals from the constructing thread */ @SuppressWarnings(&quot;removal&quot;) private Thread(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; if (name == null) &#123; throw new NullPointerException(&quot;name cannot be null&quot;); &#125; this.name = name; Thread parent = currentThread(); // 调用获取当前线程函数 SecurityManager security = System.getSecurityManager(); if (g == null) &#123; /* Determine if it&#x27;s an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security manager doesn&#x27;t have a strong opinion on the matter, use the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; /* checkAccess regardless of whether or not threadgroup is explicitly passed in. */ g.checkAccess(); /* * Do we have the required permissions? */ if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission( SecurityConstants.SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon();// 通过父线程守护参数设置当前线程守护线程参数 this.priority = parent.getPriority();// 通过父线程参数设置当前线程优先级参数 if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ this.tid = nextThreadID(); &#125; currentThread() 是获取当前线程，在线程生命周期中，线程的最初状态为NEW，没有执行start方法之前，它只能算是一个Thread的实例，并不意味着一个新的线程被创建，因此currentThread代表的将会是创建它的那个线程，可以得出以下结论： 一个线程的创建肯定是由另一个线程完成的。 被创建线程的父线程是创建它的线程。 main函数所在的线程是由JVM创建的，也就是main线程，那就意味着前面示例代码中创建的所有线程，其父线程都是 main 线程。 Thread 与 ThreadGroup在初始化线程的构造函数有如下这段代码： 1234567891011121314151617181920212223242526272829303132333435Thread parent = currentThread(); // 调用获取当前线程函数SecurityManager security = System.getSecurityManager();if (g == null) &#123; /* Determine if it&#x27;s an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security manager doesn&#x27;t have a strong opinion on the matter, use the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125;&#125;/* checkAccess regardless of whether or not threadgroup is explicitly passed in. */g.checkAccess();/* * Do we have the required permissions? */if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission( SecurityConstants.SUBCLASS_IMPLEMENTATION_PERMISSION); &#125;&#125;g.addUnstarted();this.group = g; 通过对源码分析，在创建线程时没有显示给出 ThreadGroup g，也就是 g==null这个判断为true，构造函数会隐式的给当前线程实例添加一个默认的ThreadGroup。这个ThreadGroup就是当前运行线程（或者说是父线程）的ThreadGroup。 通过代码测试如下： 1234567891011121314151617package engineer.concurrent.battle.onebasic;/** * 测试 Thread 与 ThreadGroup */public class ThreadGroupTest &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(&quot;t1&quot;); ThreadGroup group = new ThreadGroup(&quot;group1&quot;); Thread t2 = new Thread(group,&quot;t2&quot;); ThreadGroup mainThreadGroup = Thread.currentThread().getThreadGroup(); System.out.println(&quot;Main thread belong group:&quot;+ mainThreadGroup.getName()); System.out.println(&quot;tl and main belong the same group:&quot; + (mainThreadGroup== t1.getThreadGroup())); System.out.println(&quot;t2 thread group not belong main group:&quot; + (mainThreadGroup== t2.getThreadGroup())); System.out.println(&quot;t2 thread group belong main TestGroup:&quot; + (group == t2.getThreadGroup())); &#125;&#125; 输出结果如下： 1234Main thread belong group:maintl and main belong the same group:truet2 thread group not belong main group:falset2 thread group belong main TestGroup:true Thread与stack size在Thread的构造函数中有一个stackSize参数，说明内容为the desired stack size for the new thread, or zero to indicate that this parameter is to be ignored.。翻译过来的意思是stackSize指的是新线程栈的大小，可以传0代表忽略这个参数而使用默认的栈内存大小。栈内存大小这块内容是与JVM配置栈大小相关的。下面基于此分析。 https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Thread.html 中提到了stackSize。具体内容如下： 1234567891011121314151617181920212223The stack size is the approximate number of bytes of address space that the virtual machine is to allocate for this thread&#x27;s stack. The effect of the stackSize parameter, if any, is highly platform dependent.On some platforms, specifying a higher value for the stackSize parameter may allow a thread to achieve greater recursion depth before throwing a StackOverflowError. Similarly, specifying a lower value may allow a greater number of threads to exist concurrently without throwing an OutOfMemoryError (or other internal error). The details of the relationship between the value of the stackSize parameter and the maximum recursion depth and concurrency level are platform-dependent. On some platforms, the value of the stackSize parameter may have no effect whatsoever.The virtual machine is free to treat the stackSize parameter as a suggestion. If the specified value is unreasonably low for the platform, the virtual machine may instead use some platform-specific minimum value; if the specified value is unreasonably high, the virtual machine may instead use some platform-specific maximum. Likewise, the virtual machine is free to round the specified value up or down as it sees fit (or to ignore it completely).Specifying a value of zero for the stackSize parameter will cause this constructor to behave exactly like the Thread(ThreadGroup, Runnable, String) constructor.Due to the platform-dependent nature of the behavior of this constructor, extreme care should be exercised in its use. The thread stack size necessary to perform a given computation will likely vary from one JRE implementation to another. In light of this variation, careful tuning of the stack size parameter may be required, and the tuning may need to be repeated for each JRE implementation on which an application is to run.Implementation note: Java platform implementers are encouraged to document their implementation&#x27;s behavior with respect to the stackSize parameter.堆栈大小是虚拟机为该线程的堆栈分配的大致字节数。stackSize参数的效果在很大程度上取决于平台。在某些平台上，为stackSize参数指定较高的值可能允许线程在引发StackOverflowError之前实现更大的递归深度。同样，指定较低的值可能允许更多的线程并发存在，而不会引发OutOfMemoryError（或其他内部错误）。stackSize参数的值与最大递归深度和并发级别之间的关系细节因平台而异。在某些平台上，stackSize参数的值可能根本不起作用。虚拟机可以将stackSize参数视为建议。如果指定的值对于平台来说过低，虚拟机可能会使用一些特定于平台的最小值；如果指定的值过高，虚拟机可能会使用一些特定于平台的最大值。同样地，虚拟机可以自行决定是否将指定的值向上舍入或向下舍入（或完全忽略它）。对于stackSize参数设置为0，该构造函数的行为将与Thread(ThreadGroup, Runnable, String)构造函数完全相同。由于此构造函数的行为依赖于平台，使用时应极度谨慎。执行给定计算所需的线程堆栈大小可能因JRE实现而异。鉴于这种差异，可能需要对stackSize参数进行仔细调整，并且在应用程序要运行的每个JRE实现上可能需要重复调整。实施注意事项：鼓励Java平台实现者记录其实现与stackSize参数相关的行为。 通过翻译总结有如下几个要点： 堆栈大小是虚拟机为该线程的堆栈分配的大致字节数。 stackSize参数的效果在很大程度上取决于平台。 执行给定计算所需的线程堆栈大小可能因JRE实现而异。 在应用程序要运行的每个JRE实现上可能需要重复调整。 一般情况下stackSize参数指定较高的值可能允许线程在引发StackOverflowError之前实现更大的递归深度，指定较低的值可能允许更多的线程并发存在，而不会引发OutOfMemoryError（或其他内部错误）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package engineer.concurrent.battle.onebasic;import org.junit.jupiter.api.Test;public class ThreadStackSizeTest &#123; private final static int THREAD_COUNT = Integer.MAX_VALUE; @Test public void testStackSize1() &#123; // 6914 stackSizeRunMethod(10); &#125; @Test public void testStackSize2() &#123; // 4009 stackSizeRunMethod(100); &#125; @Test public void testStackSize3() &#123; //6461 stackSizeRunMethod(1000); &#125; @Test public void testStackSize4() &#123; //153 stackSizeRunMethod(10000); &#125; public static void stackSizeRunMethod(int stackSize) &#123; ThreadGroup group = new ThreadGroup(&quot;stackSizeRunMethod&quot;); Runnable runnable = new Runnable() &#123; public void run() &#123; int i = 1; try &#123; recurse(i); &#125; catch (Exception e) &#123; System.out.println(e.getMessage()); &#125; catch (Error e) &#123; System.out.println(e.getMessage()); &#125; &#125; private void recurse(int i) &#123; System.out.println(i); if (i &lt; THREAD_COUNT) &#123; recurse(i + 1); &#125; &#125; &#125;; Thread thread = new Thread(group, runnable, &quot;ThreadStackSizeTest&quot;, stackSize); thread.start(); &#125;&#125; 经过测试笔者选择的Oracle OpenJDK 17，stackSize与递归深度关系不是很大，有的时候甚至成反比。 守护线程Java中通过将线程设置为守护线程（daemon thread）来指示该线程为守护线程。守护线程在没有用户线程（也就是剩余线程均为守护线程，JVM会退出）继续运行时会自动终止。这对于执行后台任务或提供服务的线程非常有用，因为它们可以在不再需要时自动关闭。 要将线程设置为守护线程，可以使用setDaemon(true)方法。这应该在启动线程之前调用。 守护线程应该谨慎使用，因为它们可能会在程序退出时突然终止，这可能导致一些任务未能完成。 以下是一个简单的示例： 12345678910111213141516171819202122package engineer.concurrent.battle.onebasic;public class DaemonThread &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; while (true) &#123; System.out.println(&quot;I am a daemon thread&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); // 将线程设置为守护线程 thread.setDaemon(true); thread.start(); Thread.sleep(2000); System.out.println(&quot;I am main thread and end&quot;); &#125;&#125; 上面例子中main主线程运行结束则守护线程thread线程也结束运行。 参考 《Java高并发编程详解：多线程与架构设计》 Java Thread Doc 关于作者来自一线全栈程序员nine的八年探索与实践，持续迭代中。欢迎关注“雨林寻北”或添加个人卫星codetrend（备注技术）。","tags":[]},{"title":"高并发编程基础线程知识说明","date":"2023-12-25T16:00:00.000Z","path":"高并发编程基础/02-线程基础知识说明/","text":"引言现在几乎所有操作系统都支持多任务执行，其中每个任务被视为一个进程。在每个进程内部，至少有一个线程在运行，线程也被称为轻量级进程。 线程可以看作是程序执行的一条路径，每个线程都有自己的局部变量表、程序计数器（指向当前正在执行的指令）以及各自的生命周期。现代操作系统通常支持同时运行多个线程。例如，在启动Java虚拟机（JVM）时，操作系统会创建一个新的进程（即JVM进程），并在该进程中生成多个派生或创建的线程。 线程生命周期flowchart TD A[新建New] --> B[就绪Runnable] B --> C[运行Running] C --> D[阻塞Blocked] D --> E[就绪Runnable] E --> F[运行Running] F --> G[终止Terminated] D --> H[等待Waiting] H --> I[唤醒Notify] I --> E D --> J[超时等待Timed Waiting] J --> K[唤醒Notify] K --> E 在JDK17版本的JVM线程的生命周期共7个状态，可以在java.lang.Thread.State枚举类看到，具体如下： 新建状态（New）：当一个Thread类或其子类的对象被创建时，该线程处于新建状态。此时它尚未启动，即没有开始执行run()方法。 就绪状态（Runnable）：当线程对象调用了start()方法之后，该线程进入就绪状态。此时该线程已经有了执行资格，只等待CPU的调度，也就是分配时间片。 运行状态（Running）：当就绪状态的线程获得了CPU时间片，开始执行run()方法时，该线程进入运行状态。 阻塞状态（Blocked）：在某些情况下，线程可能会暂时失去对CPU的控制权，暂停执行。这时线程进入阻塞状态。例如，线程调用了sleep()方法、I/O操作、等待synchronized锁等都会使线程进入阻塞状态。 等待状态（Waiting）：当线程执行wait()、join()、park()等方法之后，线程进入等待状态。此时线程不会占用CPU资源，也不会释放持有的锁，需要其他线程的唤醒才能继续执行。 超时等待状态（Timed Waiting）：与等待状态类似，但是可以设置等待的时间。当线程调用了带有时间参数的sleep()、wait()、join()方法或者LockSupport.parkNanos()、LockSupport.parkUntil()方法时，线程进入超时等待状态。 终止状态（Terminated）：线程执行完run()方法后，或者出现异常而结束时，线程进入终止状态。此时线程已经彻底结束，不会再回到其他状态。 这些线程状态在Java中非常重要，理解它们的含义和转换规则有助于我们编写高效、正确的多线程程序。 线程的生命周期是从新建状态开始，通过调用 start() 方法进入可运行状态，然后可能进入阻塞、等待或者被中断，最后进入终止状态。JVM 管理线程状态的转换，可以通过 Thread 类的状态相关方法来查询当前线程的状态。 Running状态的转换 直接进入 TERMINATED 状态，比如用JDK已经不推荐使用的stop法或者判断某个逻辑标识。 进入 BLOCKED 状态，比如调用了 sleep 或者 wait 方法而加入了 waitSet 中。 进行某个阻塞的 IO 操作，比如因网络数据的读写而进入了 BLOCKED 状态获取某个锁资源，从而加人到该锁的阻塞队列中而进入了 BLOCKED 状态。 由于CPU的调度器轮询使该线程放弃执行，进入RUNNABLE 状态。 线程主动调用 yield 方法，放弃 CPU 执行权，进入 RUNNABLE 状态。 Blocked状态的转换 直接进人 TERMINATED 状态，比如调用JDK已经不推荐使用的 stop 方法或者意外死亡(JVM Crash)。 线程阻塞的操作结束，比如读取了想要的数据字节进入到 RUNNABLE 状态。 线程完成了指定时间的休眠，进入到了 RUNNABLE 状态。 Wait 中的线程被其他线程 notify/notifyall 唤醒，进入RUNNABLE状态。 线程获取到了某个锁资源，进人 RUNNABLE 状态。 线程在阻塞过程中被打断，比如其他线程调用了 interrupt 方法，进入RUNNABLE状态。 Terminated状态的形成 线程运行正常结束，结束生命周期。 线程运行出错意外结束。 JVM Crash，导致所有的线程都结束。 线程的创建创建线程只有一种方式那就是构造Thread类，而实现线程的执行单元则有两种方式。 重写Thread的run方法。 实现 Runnable 接口的run方法，并且将Runnable 实例用作构造Thread 的参数。 123456789101112131415161718192021222324public class MyThread extends Thread &#123; public void run() &#123; // 定义线程执行的任务 System.out.println(&quot;This is a new thread.&quot;); &#125; public static void main(String[] args) &#123; MyThread myThread = new MyThread(); myThread.start(); // 启动线程 &#125;&#125;public class MyRunnable implements Runnable &#123; public void run() &#123; // 定义线程执行的任务 System.out.println(&quot;This is a new thread.&quot;); &#125; public static void main(String[] args) &#123; MyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); // 将实现了 Runnable 接口的对象作为参数传递给 Thread 类的构造方法 thread.start(); // 启动线程 &#125;&#125; 线程中的策略模式无论是 Runnable 接口的 run() 方法，还是 Thread 类本身的 run() 方法，都遵循了将线程的控制逻辑与业务逻辑分离的原则，以实现职责分明、功能单一的设计思想。这种设计方式与 GoF（Gang of Four）设计模式中的策略模式有相似之处。 在策略模式中，将可变的算法封装成独立的策略类，并通过接口或抽象类与调用者进行解耦。调用者可以根据需要选择不同的策略来完成特定的任务。类似地，Java 中的线程创建方式也将线程的执行逻辑封装在一个单独的类（实现 Runnable 接口或继承 Thread 类）中，通过调用 start() 方法来启动线程。 使用这种设计模式，可以使线程控制逻辑与业务逻辑分离，提高代码的可维护性和可扩展性。例如，可以根据不同的业务需求，定义不同的 Runnable 实现类或 Thread 子类，并在启动线程时选择合适的线程对象，从而实现不同的业务逻辑。 总结来说，Java 中线程的创建方式与策略设计模式相似，都体现了将控制逻辑与具体业务逻辑分离的设计原则，以实现代码的灵活性和可扩展性。 线程中的Runnable复用重写 Thread 类的 run() 方法和实现 Runnable 接口的 run() 方法有一个关键的不同点。Thread 类的 run() 方法是无法共享的，也就是说，一个线程的 run() 方法不能被另一个线程当作自己的执行单元。相比之下，使用 Runnable 接口可以实现线程执行单元的共享。通过传递同一个实现了 Runnable 接口的对象给多个 Thread 实例，可以使多个线程共享同一个执行单元，从而提高代码的复用性和可维护性。 1234567891011121314public class MyRunnable implements Runnable &#123; public void run() &#123; // 定义线程执行的任务 System.out.println(&quot;This is a new thread.&quot;); &#125; public static void main(String[] args) &#123; MyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); thread.start(); // 启动线程 Thread thread2 = new Thread(myRunnable); thread2.start(); // 启动线程 &#125;&#125; 例子创建线程123456789101112131415161718192021222324252627282930313233343536package engineer.concurrent.battle.onebasic;import java.util.concurrent.TimeUnit;public class TryConcurrent &#123; public static void main(String[] args) &#123; new Thread(TryConcurrent::writeCode).start(); listenMusic(); &#125; private static void listenMusic() &#123; for(;;)&#123; System.out.println(&quot;music is good&quot;); sleep(1); &#125; &#125; private static void writeCode() &#123; for(;;)&#123; System.out.println(&quot;write code and work hard&quot;); sleep(1); &#125; &#125; private static void sleep(int i) &#123; try &#123; TimeUnit.SECONDS.sleep(i); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 多线程排队模拟1234567891011121314151617181920212223242526/** * 叫号机排队模拟，通过多线程并发 */public class TicketWindow extends Thread &#123; private final String name; private final static int MAX = 100; private static AtomicInteger index = new AtomicInteger(1); public TicketWindow(String name) &#123; this.name = name; &#125; public void run() &#123; while (index.get() &lt;= MAX) &#123; System.out.println(name + &quot;柜台正在排队，排队号码为：&quot; + index); index.getAndIncrement(); &#125; &#125; public static void main(String[] args) &#123; new TicketWindow(&quot;一号窗口&quot;).start(); new TicketWindow(&quot;二号窗口&quot;).start(); new TicketWindow(&quot;三号窗口&quot;).start(); new TicketWindow(&quot;四号窗口&quot;).start(); &#125;&#125; 参考 《Java高并发编程详解：多线程与架构设计》 Java Thread Doc","tags":[]},{"title":"高并发编程基础-引言","date":"2023-12-06T16:00:00.000Z","path":"高并发编程基础/01-引言/","text":"5W1H这里用“六何”的分析方法概括下即将开始的新主题高并发编程基础系列文章。 what何事： 高并发编程指同一时间进行大量任务的处理，同时保持过程稳定和结果一致。Java中使用多线程技术来支撑高并发的场景。“高并发编程基础”指的就是多线程这块技术的内容。 随着JDK版本的迭代，JDK已经出到23，本文主要基于JDK17版本的源码和api来说明多线程编程技术的使用。一个是因为这个版本稳定兼容性好，第二个是相较于8的版本更加新和优秀。 why何因： Java为多线程提供了基本的工具来支持在多核处理器进行编程的工具类，通过对这款内容的学习可以加深对并发框架的使用原理的了解以及满足日常多线程开发过程的使用。 where何地： “高并发编程基础”会发表在各大技术论坛（掘金、知乎、CSDN等）、公众号和博客（https://r0ad.github.io/）中。 when何时: 预计需要花费一个月时间完成整个基础教程的输出。 who何人: 适合希望使用或学习多线程编程或想要自我检查学习成果的人。不足之处可以随时交流指出 how何法: 通过源码分析加DEMO实战加图片文字说明的方式输出整个系文档。 大纲整个“高并发编程基础”可能的大纲如下，随着后续迭代可能进行增删。 线程基础知识说明 Thread构造函数使用说明 Thread常用API使用说明 线程安全与数据同步 并发中的基础概念Monitor 线程间通信 AQS的原理和实现 Java中锁的概念和原理 对象共享中的可见性问题 ThreadGroup的使用 Hook线程以及捕获线程执行异常 线程池原理以及自定义线程池 线程上下文通讯 单例模式与多线程 Lock的使用 CAS 原子操作及相关类 Future 和 FutureTask 线程池工作原理 ThreadLocal 底层原理 等等 参考由于水平限制，“高并发编程基础”参考了很多资料来编写。 JDK 17 官方文档，用于自查和权威核对 https://docs.oracle.com/en/java/javase/17/ 涉及JDK源码、基础原理介绍的书：《Java高并发编程详解：多线程与架构设计》（基于JDK8） 涉及Java标准介绍和多线程基础说明的书： 《Java多线程编程核心技术》（基于JDK8） 关于作者来自一线全栈程序员nine的八年探索与实践，持续迭代中。欢迎关注“雨林寻北”或添加个人卫星codetrend（备注技术）。","tags":[]},{"title":"Gitlab使用或替换外部Nginx方法说明","date":"2023-08-15T16:00:00.000Z","path":"运维/Gitlab使用或替换外部Nginx方法说明/","text":"Gitlab 版本没更新就会导致依赖的组件库版本没更新，如果Nginx有漏洞，则需要升级Gitlab，或者第二个选择就是使用外部的Nginx作为服务容器。 升级步骤** 请勿直接在生产或者线上主机上执行。 具体操作步骤如下： 备份配置文件 cp /etc/gitlab/gitlab.rb /etc/gitlab/gitlab.rb.20230822.bak 禁用捆绑的 NGINX，在 /etc/gitlab/gitlab.rb 中设置： 1nginx[&#x27;enable&#x27;] = false 下载正确的网络服务器配置，访问地址： GitLab recipes repository 下面以http的Nginx为例说明，把配置文件放入/etc/nginx/conf.d（默认）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445upstream gitlab-workhorse &#123; # On GitLab versions before 13.5, the location is # `/var/opt/gitlab/gitlab-workhorse/socket`. Change the following line # accordingly. server unix:/var/opt/gitlab/gitlab-workhorse/sockets/socket;&#125;## Normal HTTP hostserver &#123; ## Either remove &quot;default_server&quot; from the listen line below 如果遇到问题可以删除 default_server ## or delete the /etc/nginx/sites-enabled/default file. This will cause gitlab ## to be served if you visit any address that your server responds to, eg. ## the ip address of the server (http://x.x.x.x/)n 0.0.0.0:80 default_server; listen 0.0.0.0:8088 default_server; # 修改你需要监听的端口 listen [::]:8088 default_server; server_name localhost; ## Replace this with something like gitlab.example.com # 修改配置的域名 server_tokens off; ## Don&#x27;t show the nginx version number, a security best practice root /opt/gitlab/embedded/service/gitlab-rails/public; # 默认位置就是这里 ## See app/controllers/application_controller.rb for headers set ## Individual nginx logs for this GitLab vhost access_log /var/log/nginx/gitlab_access.log; error_log /var/log/nginx/gitlab_error.log; location / &#123; client_max_body_size 0; gzip off; ## https://github.com/gitlabhq/gitlabhq/issues/694 ## Some requests take more than 30 seconds. proxy_read_timeout 300; proxy_connect_timeout 300; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://gitlab-workhorse; &#125;&#125; 执行 sudo gitlab-ctl reconfigure 命令以使更改生效。 启动 nginx。 遇到的问题 权限不够，界面返回502。解决办法是修改nginx配置文件的启动用户为root或者授权给对应用户。 出现如下错误： 1connect() to unix:/var/opt/gitlab/gitlab-workhorse/sockets/socket failed (13:Permission denied) while connecting to upstream 选择以下选项之一进行修复： 更新到 14.3 或更高版本，其中包含更新的 SELinux 策略。 手动获取和更新策略： 12wget https://gitlab.com/gitlab-org/omnibus-gitlab/-/raw/a9d6b020f81d18d778fb502c21b2c8f2265cabb4/files/gitlab-selinux/rhel/7/gitlab-13.5.0-gitlab-shell.ppsemodule -i gitlab-13.5.0-gitlab-shell.pp 参考 NGINX 配置-Gitlab","tags":[]},{"title":"Windows端微信多开的技巧","date":"2023-07-31T16:00:00.000Z","path":"编程/Windows端微信多开的技巧/","text":"Windows端微信会根据用户ID创建对应的目录，用于数据的保护和隔离。也就是说微信本身和QQ一样是支持多个同时登陆的，但是在PC端通过常规的方式打开微信只会打开同一个微信。 下面通过简单的教程教会微信多开的方法。 通过脚本多开 安装Windows版本微信，下载地址： https://weixin.qq.com/ 找到对应的安装位置。有几种方法。 在桌面找到微信图标，右键“属性”，点击“快捷方式”，其中“目标”的值就是接下来需要的内容。这里的内容是 “C:\\Program Files (x86)\\Tencent\\WeChat\\WeChat.exe” 在桌面找到微信图标，右键“属性”，点击“快捷方式”，点击“打开文件所在位置”，其中地址栏的路径和文件名“WeChat.exe”就是我们需要的内容。这里的路径也是 “C:\\Program Files (x86)\\Tencent\\WeChat\\WeChat.exe” 在桌面创建一个文本文件，重命名为“微信多开.bat”。 12start C:\\&quot;Program Files (x86)\\Tencent\\WeChat\\WeChat.exe&quot;start C:\\&quot;Program Files (x86)\\Tencent\\WeChat\\WeChat.exe&quot; 注意事项如下： 需要多开几个就复制几行。 路径的盘符也就是上面的“C”需要放在引号外面。 下次需要多开微信的时候直接运行“微信多开.bat”即可多开。 使用命令提示符多开 安装Windows版本微信，下载地址： https://weixin.qq.com/ 找到对应的安装位置。在桌面找到微信图标，右键“属性”，点击“快捷方式”，点击“打开文件所在位置”，其中地址栏的路径和文件名“WeChat.exe”就是我们需要的内容。这里的路径也是 “C:\\Program Files (x86)\\Tencent\\WeChat\\WeChat.exe” 在文件夹路径里面输入“cmd”即可打开命令提示符。 输入命令：start WeChat.exe &amp; WeChat.exe 并按回车。即可实现多开。","tags":[]},{"title":"基于Linux系统Java服务启停的通用shell","date":"2023-07-27T16:00:00.000Z","path":"编程/基于Linux系统Java服务启停的通用shell/","text":"引言应用程序的启停最为显著的特征是端口的占用情况，例如Nginx、Tomcat。除此之外也可以通过进程的文件信息判断进程启停情况。在Linux系统常用的两个命令分别为 lsof 和 ps。在应用的启停中通过监听端口去判断是否存在进行启停是更合理的一种方式。实际使用过程中都会使用到。 lsof用法1234567891011121314151617181920212223242526272829303132333435363738NAME lsof - list open filesSYNOPSIS lsof [ -?abChKlnNOPRtUvVX ] [ -A A ] [ -c c ] [ +c c ] [ +|-d d ] [ +|-D D ] [ +|-e s ] [ +|-E ] [ +|-f [cfgGn] ] [ -F [f] ] [ -g [s] ] [ -i [i] ] [ -k k ] [ +|-L [l] ] [ +|-m m ] [ +|-M ] [ -o [o] ] [ -p s ] [ +|-r [t[m&lt;fmt&gt;]] ] [ -s [p:s] ] [ -S [t] ] [ -T [t] ] [ -u s ] [ +|-w ] [ -x [fl] ] [ -z [z] ] [ -Z [Z] ] [ -- ] [names]DESCRIPTION Lsof revision 4.89 lists on its standard output file information about files opened by processes for the following UNIX dialects: Apple Darwin 9 and Mac OS X 10.[567] FreeBSD 8.[234], 9.0, 10.0 and 11.0 for AMD64-based systems Linux 2.1.72 and above for x86-based systems Solaris 9, 10 and 11 (See the DISTRIBUTION section of this manual page for information on how to obtain the latest lsof revision.) An open file may be a regular file, a directory, a block special file, a character special file, an executing text reference, a library, a stream or a network file (Internet socket, NFS file or UNIX domain socket.) A specific file or all the files in a file system may be selected by path. Instead of a formatted display, lsof will produce output that can be parsed by other programs. See the -F, option description, and the OUT‐ PUT FOR OTHER PROGRAMS section for more information. In addition to producing a single output list, lsof will run in repeat mode. In repeat mode it will produce output, delay, then repeat the output operation until stopped with an interrupt or quit signal. See the +|-r [t[m&lt;fmt&gt;]] option description for more information. ps用法123456789101112131415161718192021222324252627282930313233NAME ps - report a snapshot of the current processes.SYNOPSIS ps [options]DESCRIPTION ps displays information about a selection of the active processes. If you want a repetitive update of the selection and the displayed information, use top(1) instead. This version of ps accepts several kinds of options: 1 UNIX options, which may be grouped and must be preceded by a dash. 2 BSD options, which may be grouped and must not be used with a dash. 3 GNU long options, which are preceded by two dashes. Options of different types may be freely mixed, but conflicts can appear. There are some synonymous options, which are functionally identical, due to the many standards and ps implementations that this ps is compatible with. Note that &quot;ps -aux&quot; is distinct from &quot;ps aux&quot;. The POSIX and UNIX standards require that &quot;ps -aux&quot; print all processes owned by a user named &quot;x&quot;, as well as printing all processes that would be selected by the -a option. If the user named &quot;x&quot; does not exist, this ps may interpret the command as &quot;ps aux&quot; instead and print a warning. This behavior is intended to aid in transitioning old scripts and habits. It is fragile, subject to change, and thus should not be relied upon. By default, ps selects all processes with the same effective user ID (euid=EUID) as the current user and associated with the same terminal as the invoker. It displays the process ID (pid=PID), the terminal associated with the process (tname=TTY), the cumulated CPU time in [DD-]hh:mm:ss format (time=TIME), and the executable name (ucmd=CMD). Output is unsorted by default. The use of BSD-style options will add process state (stat=STAT) to the default display and show the command args (args=COMMAND) instead of the executable name. You can override this with the PS_FORMAT environment variable. The use of BSD-style options will also change the process selection to include processes on other terminals (TTYs) that are owned by you; alternately, this may be described as setting the selection to be the set of all processes filtered to exclude processes owned by other users or not on a terminal. These effects are not considered when options are described as being &quot;identical&quot; below, so -M will be considered identical to Z and so on. Except as described below, process selection options are additive. The default selection is discarded, and then the selected processes are added to the set of processes to be displayed. A process will thus be shown if it meets any of the given selection criteria. 通过监听端口停止应用使用lsof加关键词LISTEN获取端口，脚本如下： 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash#author： sunz#file name: killProcessByPort.sh## 参数通过运行时传入port1=$1MSG=&quot;shutdown port %s at pid %s %s \\n&quot;killByPort()&#123;pids=$(lsof -i:$port1 | grep LISTEN | awk &#x27;&#123;print $2&#125;&#x27; |xargs)pids_len=$&#123;#pids[*]&#125;if test $pids_len -ne 1thenprintf &quot;port %s has been killed or not start yet. \\n&quot; $port1fifor pid in $pids; doprintf &quot;shutdown port %s at pid %s %s \\n&quot; $port1 $pid &#x27;start&#x27;kill -9 $pidCheckKillResult $? $piddone&#125;CheckKillResult()&#123;result=$1pid=$2if test $result -eq 0then printf &quot;shutdown port %s at pid %s %s \\n&quot; $port1 $pid &quot;successs&quot;elseprintf &quot;shutdown port %s at pid %s %s \\n&quot; $port1 $pid &quot;failed&quot;fi&#125;killByPort# eg $killProcessByPort 9430 通过文件名停止应用使用ps+awk加应用名关键词获取pid，脚本如下： 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash#author： sunz#file name: killProcessByName.sh## 参数通过运行时传入name=$1MSG=&quot;shutdown app %s at pid %s %s \\n&quot;killByName()&#123;pids=$(ps -ef | grep $name |grep java | awk &#x27;&#123;print $2&#125;&#x27; |xargs)pids_len=$&#123;#pids[*]&#125;if test $pids_len -ne 1thenprintf &quot;app %s has been killed or not start yet. \\n&quot; $namefifor pid in $pids; doprintf &quot;shutdown app %s at pid %s %s \\n&quot; $name $pid &#x27;start&#x27;kill -9 $pidCheckKillResult $? $piddone&#125;CheckKillResult()&#123;result=$1pid=$2if test $result -eq 0then printf &quot;shutdown app %s at pid %s %s \\n&quot; $name $pid &quot;successs&quot;elseprintf &quot;shutdown app %s at pid %s %s \\n&quot; $name $pid &quot;failed&quot;fi&#125;killByName# eg $killProcessByName spring-boot.jar 通用启动Java程序脚本通过函数式编写启动Java程序脚本有如下优点： 简化启动应用的脚本维护； 统一维护一类程序的JVM参数； 脚本信息如下： 1234567891011121314151617181920212223242526272829#!/bin/bash#author： sunz#file name: startJavaProcess.sh## 参数通过运行时传入APP=$1startJavaProcess()&#123; echo &quot;start $APP &quot; ## JVM参数基于Java8 JVM=&quot; -Xmx1344M -Xms1344M -Xmn448M -XX:MaxMetaspaceSize=256M -XX:MetaspaceSize=256M -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses -XX:+CMSClassUnloadingEnabled -XX:+ParallelRefProcEnabled -XX:+CMSScavengeBeforeRemark &quot; ## 特殊版本java的路径可以通过全路径制定 nohup java $JVM -jar $APP &gt;/dev/null 2&gt;&amp;1 &amp; CheckStartResult $? $APP&#125;CheckStartResult()&#123;result=$1pid=$2if test $result -eq 0then printf &quot;startup %s %s \\n&quot; $2 &quot;successs&quot;elseprintf &quot;startup %s %s \\n&quot; $2 &quot;failed&quot;fi&#125;startJavaProcess# eg $startJavaProcess zuul-boot-2.0.0-SNAPSHOT.jar 通过 ~/.bashrc 简化程序脚本.bashrc 在用户登录时获取该文件的 aslias 等信息。维护人员可以通过别名简化程序脚本，增加维护效率。 .bash_profile 文件可以维护环境变量，也可以简化该脚本。 .bash_profile 修改过程如下： 12345678910# 编辑 bash_profile# vi .bash_profileSHELL_HOME=&quot;/home/sunz/文档/files/shell/cshell&quot;killProcessByPort=&#x27;sh $SHELL_HOME/killProcessByPort.sh &#x27;export killProcessByPortstartJavaProcess=&#x27;sh $SHELL_HOME/startJavaProcess.sh &#x27;export startJavaProcess# 更新 bash_profile# source .bash_profile .bashrc 修改过程如下： 123456# 编辑 bash_profile# vi .bash_profile# 使用 alias 方法SHELL_HOME=&quot;/home/sunz/文档/files/shell/cshell&quot;alias startJavaProcess=&#x27;sh $SHELL_HOME/startJavaProcess.sh &#x27;alias killProcessByPort=&#x27;sh $SHELL_HOME/killProcessByPort.sh &#x27; 注意不同系统的文件名可能存在差异。 以user-gatewayin-svc为例子说明使用服务部署路径信息 /app/user_projects/user-gatewayin-svc ,目录结构如下： 1234drwxr-xr-x 3 app sunz 4096 2月 1 13:40 config-rw-r--r-- 1 app sunz 86 2月 1 13:47 start.sh-rw-r--r-- 1 app sunz 19 12月 9 15:57 stop.sh-rw-r--r-- 1 app sunz 57520835 1月 5 16:10 zuul-boot-2.0.0-SNAPSHOT.jar 其中 start.sh 内容如下; 1$startJavaProcess &quot;zuul-boot-2.0.0-SNAPSHOT.jar --spring.profiles.active=dev,dev-in&quot; 其中 stop.sh 内容如下; 1$killProcess 9450","tags":[]},{"title":"Visual Studio Code 中开发前端常用插件","date":"2023-07-24T16:00:00.000Z","path":"编程/VsCode中开发前端常用插件/","text":"Visual Studio Code 是一款开源全平台的代码开发工具，支持三大平台Windows、Linux、Mac。除了Mac平台没有使用过外，Linux的开发体验和Windows基本一致。 虽然Visual Studio Code 支持多种语言的开发，但是在后端有IntelliJ IDEA这样的开源版本提供使用，所以在Java Web开发中一般使用IDEA开发后端，Vs Code开发前端。 Visual Studio Code 作为一款轻量级的IDE，本身不是很强大，但是在开发插件的支持下，前端代码开发也能如鱼得水。 以下基于笔者开发Web过程中常用插件的推荐。 Prettier - Code formatter代码格式对于开发过程来说是很重要的一件事，统一的代码格式能够代码更好的代码阅读体验。 Prettier 支持多种语言的代码格式化，包括 Js、Vue、Html、Css等等。 通过搜索 Prettier - Code formatter 安装。 Vue Language Features (Volar)Vue 官方出品支持Vue框架源码开发的插件，使得开发Vue源码更加方便。 包括 Vue文件的高亮显示、ESLint的语法集成支持、代码格式化等等。开发Vue必备。 通过搜索 Volar 安装。 其它开发vue的辅助推荐还包括 Vue Peek 文件跳转、 vue-helper 对 Element-UI, VUX, IVIEW 的增加开发体验。 JavaScript (ES6) code snippets提供 ES6 语法的代码提示，通过缩写就能写出常用的代码。 例如输入 clo 就能打印对象 console.log(&#39;object :&gt;&gt; &#39;, object); 。 支持的缩写包括 Import and export 、 Various methods 、Console methods 等等。 通过搜索 JavaScript (ES6) code snippets 安装。 Markdown Preview Enhanced程序员写文档必备的markdown语法，这款插件提供markdown的文档、图标语法、函数语法的支持。还可以导出和预览markdown文档。 通过搜索 Markdown Preview Enhanced 安装。 markdownlintmarkdown的语法检查支持，还提供了一部分程序修正功能。很实用、很方便。对于不熟悉markdown语法的人很是有用。 通过搜索 markdownlint 安装。 GitLens — Git superchargedVsCode的git使用体验不是很好，通过该插件能增强git的使用过程。 通过搜索 GitLens 安装。 参考 Visual Studio Code Doc","tags":[]},{"title":"RabbitMQ 的安装和使用","date":"2023-03-16T16:00:00.000Z","path":"中间件实战/RabbitMQ的安装和使用/","text":"引言RabbitMQ 作为一个开源的消息中间件广泛使用。 支持分布式部署。 异步消息传递，支持多种消息协议、消息队列、送达确认、灵活的队列路由、多种交换类型。 提供多种监听和管理工具，HTTP-API, 命令行工具command line tool, UI界面。 安装容器安装目前最新版本安装和启动命令如下： 1docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.11-management Linux或Windows安装通过官网提供的安装包安装即可。具体安装方法可查看 https://www.rabbitmq.com/install-windows.html 。 先安装Erlang。 安装对应的 RabbitMQ 安装包。 RabbitMQ访问通过UI界面访问对应的系统。 登录地址 127.0.0.1:15762 。 账号密码默认 guest\\guest 。 Springboot集成RabbitMQ 修改依赖加入RabbitMQ启动项目，此处以maven为例子说明。 1234567&lt;!-- rabbitmq --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 增加 rabbitmq 配置。 1234567891011spring: application: name: boot-rabbitmq # rabbitmq 配置 rabbitmq: # Redis 服务器地址 host: 127.0.0.1 # 连接端口号 port: 5672 username: guest password: guest 增加 rabbit相关配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 自定义注入配置bean相关组件 */@Configuration@Slf4jpublic class RabbitMQConfig &#123; // 自动装配RabbitMQ的链接工厂实例 @Autowired private CachingConnectionFactory connectionFactory; // 自动装配消息监听器所在的容器工厂配置类实例 @Autowired private SimpleRabbitListenerContainerFactoryConfigurer factoryConfigurer; /** * 单一消费者 * @return */ @Bean(name = &quot;singleListenerContainer&quot;) public SimpleRabbitListenerContainerFactory listenerContainer()&#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setConcurrentConsumers(1); factory.setMaxConcurrentConsumers(1); factory.setPrefetchCount(1); return factory; &#125; /** * 多个消费者 * @return */ @Bean(name = &quot;multiListenerContainer&quot;) public SimpleRabbitListenerContainerFactory multiListenerContainer()&#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factoryConfigurer.configure(factory,connectionFactory); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setAcknowledgeMode(AcknowledgeMode.NONE); factory.setConcurrentConsumers(10); factory.setMaxConcurrentConsumers(15); factory.setPrefetchCount(10); return factory; &#125; /** * RabbitMQ发送消息的操作组件实例 * @return */ @Bean public RabbitTemplate rabbitTemplate()&#123; connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMandatory(true); rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -&gt; log.info(&quot;消息发送成功:correlationData(&#123;&#125;),ack(&#123;&#125;),cause(&#123;&#125;)&quot;,correlationData,ack,cause)); rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; log.info(&quot;消息丢失:exchange(&#123;&#125;),route(&#123;&#125;),replyCode(&#123;&#125;),replyText(&#123;&#125;),message:&#123;&#125;&quot;,exchange,routingKey,replyCode,replyText,message)); return rabbitTemplate; &#125;&#125; Springboot使用RabbitMQ 启动的配置类注入对应的队列，包括队列名称、交换机、路由。 使用 RabbitTemplate 作为生产者发送消息。 @RabbitListener 作为消费者监听对应队列消费消息。 12345## 环境变量配置mq.env=localmq.basic.info.queue.name=$&#123;mq.env&#125;.middleware.mq.basic.info.queuemq.basic.info.exchange.name=$&#123;mq.env&#125;.middleware.mq.basic.info.exchangemq.basic.info.routing.key.name=$&#123;mq.env&#125;.middleware.mq.basic.info.routing.key 12345678910111213141516171819202122232425262728/** * springboot 启动时去5672 端口监听配置的所有监听队列， * 若这个队列不存在，监听不到则会报错，需要在程序启动时注入这个队列 *///定义读取配置文件的环境变量实例 @Autowired private Environment env; /**创建简单消息模型：队列、交换机和路由 **/ //创建队列 @Bean(name = &quot;basicQueue&quot;) public Queue basicQueue()&#123; return new Queue(env.getProperty(&quot;mq.basic.info.queue.name&quot;),true); &#125; //创建交换机：在这里以DirectExchange为例，在后面章节中我们将继续详细介绍这种消息模型 @Bean public DirectExchange basicExchange()&#123; return new DirectExchange(env.getProperty(&quot;mq.basic.info.exchange.name&quot;),true,false); &#125; //创建绑定 @Bean public Binding basicBinding()&#123; return BindingBuilder.bind(basicQueue()).to(basicExchange()).with(env.getProperty(&quot;mq.basic.info.routing.key.name&quot;)); &#125; 123456789101112131415161718192021222324252627@Autowired private RabbitTemplate rabbitTemplate; @Autowired private Environment env; /** * 发送消息 * @param message */ public void sendMsg(String message)&#123; if (!ObjectUtils.isEmpty(message))&#123; try &#123; rabbitTemplate.setExchange(env.getProperty(&quot;mq.basic.info.exchange.name&quot;)); rabbitTemplate.setRoutingKey(env.getProperty(&quot;mq.basic.info.routing.key.name&quot;)); Message msg=MessageBuilder.withBody(message.getBytes(&quot;utf-8&quot;)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT).build(); rabbitTemplate.convertAndSend(msg); log.info(&quot;基本消息模型-生产者-发送消息：&#123;&#125; &quot;,message); &#125;catch (Exception e)&#123; log.error(&quot;基本消息模型-生产者-发送消息发生异常：&#123;&#125; &quot;,message,e.fillInStackTrace()); &#125; &#125; &#125; 123456789@RabbitListener(queues = &quot;$&#123;mq.basic.info.queue.name&#125;&quot;,containerFactory = &quot;singleListenerContainer&quot;) public void consumeMsg(@Payload byte[] msg)&#123; try &#123; String message=new String(msg,&quot;utf-8&quot;); log.info(&quot;基本消息模型-消费者-监听消费到消息：&#123;&#125; &quot;,message); &#125;catch (Exception e)&#123; log.error(&quot;基本消息模型-消费者-发生异常：&quot;,e.fillInStackTrace()); &#125; &#125; RabbitMQ常见消息模式Simple 模式Simple 模式是最简单的一个模式，由一个生产者，一个队列，一个消费者组成，生产者将消息通过交换机（此时，图中并没有交换机的概念，如不定义交换机，会使用默认的交换机）把消息存储到队列，消费者从队列中取出消息进行处理。 Fanout 模式Fanout——发布订阅模式，是一种广播机制。 此模式包括：一个生产者、一个交换机 (exchange)、多个队列、多个消费者。生产者将消息发送到交换机，交换机不存储消息，将消息存储到队列，消费者从队列中取消息。如果生产者将消息发送到没有绑定队列的交换机上，消息将丢失。 Direct 模式Direct 模式是在 Fanout 模式基础上添加了 routing key，Fanout（发布/订阅）模式是交换机将消息存储到所有绑定的队列中，而 Direct 模式是在此基础上，添加了过滤条件，交换机只会将消息存储到满足 routing key 的队列中。 Topic 模式Topic 模式是生产者通过交换机将消息存储到队列后，交换机根据绑定队列的 routing key 的值进行通配符匹配，如果匹配通过，消息将被存储到该队列，如果 routing key 的值匹配到了多个队列，消息将会被发送到多个队列；如果一个队列也没匹配上，该消息将丢失。 RabbitMQ常见使用场景解耦、削峰、异步 解耦在微服务架构体系中，微服务A需要与微服务B进行通信，传统的做法是A调用B的接口。但这样做如果系统B无法访问或连接超时，系统A需要等待，直到系统B做出响应，并且A与B存在严重的耦合现象。如果引入消息队列进行系统AB的通信，流程是这样的： 系统A将消息存储到消息队列中，返回成功信息 系统B从队列中获取消息，进行处理操作 系统A将消息放到队列中，就不用关心系统B是否可以获取等其他事情了，实现了两个系统间的解耦。 使用场景： 短信、邮件通知 削峰系统A每秒请求100个，系统可以稳定运行，但如果在秒杀活动中，每秒并发达到1w个，但系统最大处理能力只能每秒处理 1000 个，所以，在秒杀活动中，系统服务器会出现宕机的现象。如果引入 MQ ，可以解决这个问题。每秒 1w个请求会导致系统崩溃，那我们让用户发送的请求都存储到队列中，由于系统最大处理能力是每秒1000个请求，让系统A每秒只从队列中拉取1000个请求，保证系统能稳定运行，在秒杀期间，请求大量进入到队列，积压到MQ中，而系统每秒只从队列中取1000个请求处理。这种短暂的高峰期积压是没问题的，因为高峰期一旦过去，每秒请求数迅速递减，而系统每秒还是从队列中取1000个请求进行处理，系统会快速将积压的消息消费掉。 使用场景： 秒杀活动团抢活动 异步用户注册，需要发送注册邮件和注册短信，传统的做法有两种：串行、并行。 串行方式：将注册信息写库后（50ms），发送邮件（50ms），再发送短信（50ms），任务完成后，返回客户端，共耗时（150ms） 并行方式：将注册信息写库后（50ms），开启子线程让发送邮件和发送短信同时进行（50ms），返回客户端，共耗时（100ms） 引入MQ，将注册信息写库（50ms），将发送邮件和短信的操作写入队列（5ms），返回客户端，而消费者什么时候从队列中取消息进行处理，不用关心，共耗时（55ms） 使用场景： 将不是必须等待响应结果的业务逻辑进行异步处理 参考 Downloading and Installing RabbitMQ 一文搞懂 RabbitMQ 常用模式","tags":[]},{"title":"Redis的安装和使用","date":"2023-03-15T16:00:00.000Z","path":"中间件实战/Redis的安装和使用/","text":"引言Redis 是基于内存的、采用Key-Value结构化存储的NoSQL数据库，底层采用单线程和多路IO复用模型加快查询速度。 支持多种数据格式的存储； 支持持久化存储； 支持集群部署。 安装Windows安装Redis 官方不支持Windows的安装，通过启用windows自带的WSL2 （(Windows Subsystem for Linux）Linux子系统工具可以使用和安装。Windows 版本要求大于10 。 具体安装流程和Linux安装一致。 Linux安装大多数Linux发行版本提供了Redis的安装包，通过安装软件包命令可以从远程安装对应的工具。 Ubuntu/Debian 系统的安装流程如下： 添加Redis官方软件仓库源到Apt软件。 123456curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpgecho &quot;deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main&quot; | sudo tee /etc/apt/sources.list.d/redis.listsudo apt-get updatesudo apt-get install redis 前置要求:如果运行的像是docker这类最小发行版本需要先安装 lsb-release 。 1sudo apt install lsb-release Redis启动Linux Ubuntu/Debian 系统启动命令如下： 1sudo service redis-server start Redis访问通过官方的Cli工具访问： 1234567891011redis-cli Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]] -h &lt;hostname&gt; Server hostname (default: 127.0.0.1). -p &lt;port&gt; Server port (default: 6379). -s &lt;socket&gt; Server socket (overrides hostname and port). -a &lt;password&gt; Password to use when connecting to the server. You can also use the REDISCLI_AUTH environment variable to pass this password more safely (if both are used, this argument takes precedence). Redis配置详细配置例子查看 https://redis.io/docs/management/config-file/ 123456789101112131415161718# Accept connections on the specified port, default is 6379 (IANA #815344).# If port 0 is specified Redis will not listen on a TCP socket.port 6379# Close the connection after a client is idle for N seconds (0 to disable)timeout 60# IMPORTANT NOTE: starting with Redis 6 &quot;requirepass&quot; is just a compatibility# layer on top of the new ACL system. The option effect will be just setting# the password for the default user. Clients will still authenticate using# AUTH &lt;password&gt; as usually, or more explicitly with AUTH default &lt;password&gt;# if they follow the new protocol: both will work.## The requirepass is not compatible with aclfile option and the ACL LOAD# command, these will cause requirepass to be ignored.#requirepass redis1234 分布式部署需要修改集群的相关配置，此处从略。 详情可参考网络或者 https://redis.io/docs/management/replication/ 1234567################################ REDIS CLUSTER ################################ Normal Redis instances can&#x27;t be part of a Redis Cluster; only nodes that are# started as cluster nodes can. In order to start a Redis instance as a# cluster node enable the cluster support uncommenting the following:#cluster-enabled yes Springboot集成redis 修改依赖加入Redis启动项目，此处以maven为例子说明。 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置，指定redis启动。 1234567891011121314151617181920212223spring: # Redis 配置 redis: # Redis 服务器地址 host: 127.0.0.1 # 连接端口号 port: 6379 # 数据库索引（0 - 15） password: redis1234 database: 0 # 连接超时时间（毫秒） timeout: 600000 # lettuce 参数 lettuce: pool: # 最大连接数(使用负值表示没有限制) 默认为 8 max-active: 10 # 最大阻塞等待时间(使用负值表示没有限制) 默认为 -1 ms max-wait: -1 # 最大空闲连接 默认为 8 max-idle: 5 # 最小空闲连接 默认为 0 min-idle: 0 增加 RedisTemplate 序列化配置，以FastJSON2为例子说明。 123456789101112131415@Configurationpublic class RedisConfiguration &#123; @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(redisConnectionFactory); GenericFastJsonRedisSerializer fastJsonRedisSerializer = new GenericFastJsonRedisSerializer(); redisTemplate.setDefaultSerializer(fastJsonRedisSerializer);//设置默认的Serialize，包含 keySerializer &amp; valueSerializer redisTemplate.setKeySerializer(fastJsonRedisSerializer);//单独设置keySerializer redisTemplate.setValueSerializer(fastJsonRedisSerializer);//单独设置valueSerializer return redisTemplate; &#125;&#125; 使用的demo，通过RedisTemplate访问。 123456789101112131415161718192021222324252627282930313233@RestController@Api(tags = &quot;demo&quot;)@RequestMapping(&quot;/v1/demo/&quot;)@Slf4jpublic class RedisDemo &#123; @Autowired private RedisTemplate redisTemplate; @ApiOperation(value = &quot;get&quot;) @PostMapping(&quot;get&quot;) @ResponseBody public Object get(String key) &#123; ValueOperations valueOperations = redisTemplate.opsForValue(); Object val = valueOperations.get(key); return val; &#125; @ApiOperation(value = &quot;set&quot;) @PostMapping(&quot;set&quot;) @ResponseBody public Boolean set(String key,String val) &#123; ValueOperations valueOperations = redisTemplate.opsForValue(); valueOperations.set(key,val); return true; &#125; @ApiOperation(value = &quot;delete&quot;) @PostMapping(&quot;delete&quot;) @ResponseBody public Boolean delete(String key) &#123; return redisTemplate.delete(key); &#125;&#125; 参考 Install Redis on Linux","tags":[]},{"title":"Java函数式编程","date":"2023-03-11T16:00:00.000Z","path":"JavaEngineer/Java函数式编程/","text":"总结 现在主流的编程范式主要有三种，面向过程、面向对象和函数式编程。函数式编程作为一种补充，有很大存在、发展和学习的意义。 函数内部涉及的变量都是局部变量，不会像面向对象编程那样，共享类成员变量，也不会像面向过程编程那样，共享全局变量。 函数式接口可以将函数作为一个参数传入方法中进行使用。 概述函数式编程因其编程的特殊性，仅在科学计算、数据处理、统计分析等领域，才能更好地发挥它的优势，所以它并不能完全替代更加通用的面向对象编程范式。但是作为一种补充，它也有很大存在、发展和学习的意义。 函数式编程更符合数学上函数映射的思想。具体到编程语言层面，我们可以使用Lambda表达式来快速编写函数映射，函数之间通过链式调用连接到一起，完成所需业务逻辑。Java的Lambda表达式是后来才引入的，由于函数式编程在并行处理方面的优势，正在被大量应用在大数据计算领域。 编程范式现在主流的编程范式主要有三种，面向过程、面向对象和函数式编程。 面向对象编程最大的特点是：以类、对象作为组织代码的单元以及它的四大特性。 面向过程编程最大的特点是：以函数作为组织代码的单元，数据与方法相分离。 函数式编程并非一个很新的东西，早在50多年前就已经出现了。近几年，函数式编程越来越被人关注，出现了很多新的函数式编程语言，比如Clojure、Scala、Erlang等。一些非函数式编程语言也加入了很多特性、语法、类库来支持函数式编程，比如Java、Python、Ruby、JavaScript等。除此之外，Google Guava也有对函数式编程的增强功能。 函数式编程因其编程的特殊性，仅在科学计算、数据处理、统计分析等领域，才能更好地发挥它的优势，所以它并不能完全替代更加通用的面向对象编程范式。但是作为一种补充，它也有很大存在、发展和学习的意义。 函数式编程中的“函数”，并不是指我们编程语言中的“函数”概念，而是指数学“函数”或者“表达式”（例如：y=f(x)）。不过，在编程实现的时候，对于数学“函数”或“表达式”，我们一般习惯性地将它们设计成函数。 函数式编程最独特的地方在于它的编程思想。函数式编程认为程序可以用一系列数学函数或表达式的组合来表示。函数式编程是程序面向数学的更底层的抽象，将计算过程描述为表达式。 并不是所有的程序都适合这么做。函数式编程有它自己适合的应用场景，比如科学计算、数据处理、统计分析等。在这些领域，程序往往比较容易用数学表达式来表示，比起非函数式编程，实现同样的功能，函数式编程可以用很少的代码就能搞定。但是，对于强业务相关的大型业务系统开发来说，费劲吧啦地将它抽象成数学表达式，硬要用函数式编程来实现，显然是自讨苦吃。相反，在这种应用场景下，面向对象编程更加合适，写出来的代码更加可读、可维护。 函数式编程跟面向过程编程一样，也是以函数作为组织代码的单元。不过，它跟面向过程编程的区别在于，它的函数是无状态的。何为无状态？简单点讲就是，函数内部涉及的变量都是局部变量，不会像面向对象编程那样，共享类成员变量，也不会像面向过程编程那样，共享全局变量。函数的执行结果只与入参有关，跟其他任何外部变量无关。同样的入参，不管怎么执行，得到的结果都是一样的。这实际上就是数学函数或数学表达式的基本要求。 Java对函数式编程的支持Java为函数式编程引入了三个新的语法概念：Stream类、Lambda表达式和函数接口（Functional Inteface）。Stream类用来支持通过“.”级联多个函数操作的代码编写方式；引入Lambda表达式的作用是简化代码编写；函数接口的作用是让我们可以把函数包裹成函数接口，来实现把函数当做参数一样来使用（Java 不像C那样支持函数指针，可以把函数直接当参数来使用）。 stream： stream “.”表示调用某个对象的方法。为了支持上面这种级联调用方式，我们让每个函数都返回一个通用的Stream类对象。在Stream类上的操作有两种：中间操作和终止操作。中间操作返回的仍然是Stream类对象，而终止操作返回的是确定的值结果。 map、filter是中间操作，返回Stream类对象，可以继续级联其他操作；max是终止操作，返回的是OPTIONAL类对象。 lambda： lambda表达式在Java中只是一个语法糖而已，底层是基于函数接口来实现的。Lambda表达式包括三部分：输入、函数体、输出。 函数接口： Java没有函数指针这样的语法。所以它通过函数接口，将函数包裹在接口中，当作变量来使用。实际上，函数接口就是接口。不过，它也有自己特别的地方，那就是要求只包含一个未实现的方法。因为只有这样，Lambda表达式才能明确知道匹配的是哪个方法。如果有两个未实现的方法，并且接口入参、返回值都一样，那Java在翻译Lambda表达式的时候，就不知道表达式对应哪个方法了。 1234567public static void stream(String[] args) &#123; Optional&lt;Integer&gt; result = Stream.of(&quot;f&quot;, &quot;ba&quot;, &quot;hello&quot;) // of返回Stream&lt;String&gt;对象 .map(s -&gt; s.length()) // map返回Stream&lt;Integer&gt;对象 .filter(l -&gt; l &lt;= 3) // filter返回Stream&lt;Integer&gt;对象 .max((o1, o2) -&gt; o1 - o2); // max终止操作：返回Optional&lt;Integer&gt; System.out.println(result.get()); // 输出2 &#125; 函数式接口@FunctionalInterface注解使用场景： 一个接口只要满足只有一个抽象方法的条件，即可以当成函数式接口使用，有没有 @FunctionalInterface 都无所谓。 如果使用了此注解，再往接口中新增抽象方法，编译器就会报错，编译不通过。换句话说，@FunctionalInterface 就是一个承诺，承诺该接口世世代代都只会存在这一个抽象方法。因此，凡是使用了这个注解的接口，开发者可放心大胆的使用Lambda来实例化。当然误用 @FunctionalInterface 带来的后果也是极其惨重的：如果哪天你把这个注解去掉，再加一个抽象方法，则所有使用Lambda实例化该接口的客户端代码将全部编译错误。 自定义函数式编程接口过程： 通过 @FunctionalInterface 注解，申明一个函数式接口。 在方法中使用函数接口作为入参使用； 调用方法，传入函数接口的实现方法。 123456789101112131415161718192021222324252627282930public class MyFuncInterface &#123; /** * 声明一个函数式接口 * @param &lt;T&gt; */ @FunctionalInterface public interface ToLongFunction&lt;T&gt; &#123; long applyAsLong(T value); &#125; /** * 工具函数定义使用函数接口作为参数 */ public static class Util&#123; public static Long mapToLong(ToLongFunction&lt;? super Collection&gt; mapper, List&lt;String&gt; val) &#123; Objects.requireNonNull(mapper); return mapper.applyAsLong(val); &#125; &#125; /** * 使用例子 * @param args */ public static void main(String[] args) &#123; List&lt;String&gt; arr = Arrays.asList(&quot;ddd&quot;, &quot;222&quot;, &quot;3333&quot;); Long size = Util.mapToLong((item)-&gt; item.size(),arr); System.out.println(size); &#125;&#125; 参考 Java如何支持函数式编程？","tags":[]},{"title":"Java 注解机制和应用","date":"2023-03-11T16:00:00.000Z","path":"JavaEngineer/Java注解机制和应用/","text":"总结 Java注解是一种很常见的开发辅助模式，Java语言中的类、方法、变量、参数和包等都可以被标注。 通过自定义注解的使用可以优化业务开发的使用。 概述Java注解又称Java标注，是Java语言5.0版本开始支持加入源代码的特殊语法元数据。为我们在代码中添加信息提供了一种形式化的方法，使我们可以在稍后某个时刻非常方便的使用这些数据。 Java语言中的类、方法、变量、参数和包等都可以被标注。和Javadoc不同，Java标注可以通过反射获取注解内容。在编译器生成类文件时，注解可以被嵌入到字节码中。Java虚拟机可以保留注解内容，在运行时可以获取到注解内容。 常见注解Java内置注解Java 定义了一套注解，共有 7 个，3 个在 java.lang 中，剩下 4 个在 java.lang.annotation 中。 1、作用在代码的注解是 @Override - 检查该方法是否是重写方法。如果发现其父类，或者是引用的接口中并没有该方法时，会报编译错误。 @Deprecated - 标记过时方法。如果使用该方法，会报编译警告。 @SuppressWarnings - 指示编译器去忽略注解中声明的警告。 2、作用在其他注解的注解(或者说元注解)是: @Retention - 标识这个注解怎么保存，是只在代码中，还是编入class文件中，或者是在运行时可以通过反射访问。 @Documented - 标记这些注解是否包含在用户文档中。 @Target - 标记这个注解应该是哪种 Java 成员。 @Inherited - 标记这个注解是继承于哪个注解类(默认 注解并没有继承于任何子类) 3、从 Java 7 开始，额外添加了 3 个注解: @SafeVarargs - Java 7 开始支持，忽略任何使用参数为泛型变量的方法或构造函数调用产生的警告。 @FunctionalInterface - Java 8 开始支持，标识一个匿名函数或函数式接口。 @Repeatable - Java 8 开始支持，标识某注解可以在同一个声明上使用多次。 常见的库中的注解日常开发使用的库中也有着大量的注解，例如Jackson、SpringMvc等，下面就简单介绍下常见库中的常见注解使用 JacksonJackson是一个通用的序列化库，程序员使用过程中可以使用它提供的注解机制对序列化进行定制化操作，比如: 使用@JsonIgnore和@JsonIgnoreProperties配置序列化的过程中忽略部分字段 使用@JsonManagedReference和@JsonBackReference可以配置实例之间的互相引用 使用@JsonProperty和@JsonFormat配置序列化的过程中字段名称和属性字段的格式等 Servlet3.0 随着web开发技术的发展，Java web已经发展到了Servlet3.0，在早期使用Servlet的时候，我们只能在web.xml中配置，但是当我们使用Servlet3.0的时候开始，已经开始支持注解了，比如我们可以使用@WebServlet配置一个类为Servlet类。 SpringMvc 同样的，在web开发中，我们往往还会使用SpringMvc框架来简化开发，其框架的大量注解可以帮助我们减少大量的业务代码，例如一个请求的参数和字段/实例之间的映射关系，一个方法使用的是Http的什么请求方法，对应请求的某个路径，同样的请求如何解析，返回的响应报文格式定义等，这些都可以使用注解来简化实现，一个简单的Mvc操作如下: 其中@Controller注解标明当前的类是SpringMvc接管的一个Bean实例，@RequestMapping(“/hello”)则是代表当前Bean的前置请求路径比如是/hello开头， @GetMapping(“/test”)则是表示test方法被访问必须是Http请求的get请求，并且路径必须是/hello/test为路径前置，@ResponseBody注解则是标明了当前请求的相应信息按照默认的格式返回(根据后缀名来确定格式) 注解创建12345@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface Label &#123; String value() default &quot;&quot;;&#125; @Target注解表示当前注解可以使用在什么类型的元素上，这里的值可以多选，即一个注解可以作用在多种不同类型的元素上，具体的可选值在ElementType枚举类中，值如下: 取值 解释 TYPE 表示作用在类、接口上 FIELD 表示作用在字段，包括枚举常量中 METHOD 表示作用在方法中 PARAMETER 表示作用在方法中的参数中 CONSTRUCTOR 表示作用在构造方法中 LOCAL_VARIABLE 表示作用在本地常量中 MODULE 表示作用在部分模块中(Java9引入的概念) ANNOTATION_TYPE 表示当前注解作用在定义其他注解中，即元注解 PACKAGE 表示当前注解使用在包的申明中 TYPE_PARAMETER 表明当前注解使用在类型参数的申明中(Java8新增) TYPE_USE 表明当前注解使用在具体使用类型中(Java8新增) 当使用多个作用域范围的时候，使用{}包裹多个参数，比如@SuppressWarnings注解的Target就有多个，在Java7中的定义为: 123@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE) public @interface SuppressWarnings &#123; String[] value();&#125; @Retention@Retention注解则是表明了当前注解可以保留到Java多个阶段的哪一个阶段，参数类型为RetentionPolicy枚举类，可取值如下: 取值 解释 SOURCE 此注解仅在源代码阶段保留，编译后即丢失注解部分 CLASS 表示编译后依然保留在Class字节码中，但是加载时不一定会在内存中 RUNTIME 表示不仅保留在Class字节码中，一直到内存使用时仍然存在 此注解有默认值，即当我们没有申明@Retention的时候，默认则是Class取值范围 @Documented@Documented注解没有具体的参数，使用此元注解，则表示带有类型的注解将由javadoc记录 @Inherited @Inherited 注解与注解的继承有关系，具体关系为如果使用了当前的元注解，则表示此注解可以被其他的注解的子类直接继承，但是需要注意的是对已实现接口上的注解将没有作用。 @Inherited 注释表明注释类型可以从超类继承。当用户查询注释类型并且该类没有此类型的注释时，将查询类的超类以获取注释类型（默认情况下不是这样）。此注释仅适用于类声明。 应用业务开发的使用基于Spring提供的AOP开发方法，可以简化业务代码开发中冗余的业务代码，对接口调用过程的前置处理、过程处理、后置处理。 金融借贷系统对接了很多第三方的风控接口。调用接口前需要校验报文体中的签名字段 sign 。 每个方法开头都写一份签名验签的代码。 将验签代码抽取成方法，方便复用。 新建 @SignCheck 注解，在切面里面写业务逻辑。 应用开发过程的日志记录需要保存到消息中间件或者数据库。 每个方法开头都写一份记录日志的代码。 将记录日志抽取成方法，方便复用。 新建 @LogAccess 注解，在切面里面写日志记录逻辑。 工具开发的使用 Lombok 通过注解 @Getter @Setter 等主机，在源码编译时添加对应的模板方法。 Fastjson 通过 @JSONField 定制序列化方法。指定JSON代码文本生成的别名。 自定义注解例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import lombok.Getter;import lombok.Setter;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import java.lang.reflect.Field;import java.text.SimpleDateFormat;import java.util.Date;import java.util.TimeZone;public class AnnotationTestAll &#123; /** * 自定义注解 Format */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface Format &#123; String pattern() default &quot;yyyy-MM-dd HH:mm:ss&quot;; String timezone() default &quot;GMT+8&quot;; &#125; @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface Label &#123; String value() default &quot;&quot;; &#125; /** * 通过反射 Format Label，并且获取值做运算 */ public static class SimpleFormatter &#123; public static String format(Object obj) &#123; try &#123; Class&lt;?&gt; cls = obj.getClass(); StringBuilder builder = new StringBuilder(); for (Field field : cls.getDeclaredFields()) &#123; if (!field.isAccessible()) &#123; field.setAccessible(true); &#125; // 获取Label注解-输出的字段名称 Label label = field.getAnnotation(Label.class); String name = null == label ? field.getName() : label.value(); Object value = field.get(obj); if (value != null &amp;&amp; field.getType() == Date.class) &#123; value = formatter(field, value); &#125; builder.append(String.format(&quot;%s ? %s \\n&quot;, name, value)); &#125; return builder.toString(); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(&quot;格式化输出失败：&quot; + e.getMessage()); &#125; &#125; private static Object formatter(Field field, Object value) &#123; Format format = field.getAnnotation(Format.class); if (null == format) &#123; return value; &#125; String pattern = format.pattern(); String timezone = format.timezone(); SimpleDateFormat sdf = new SimpleDateFormat(pattern); sdf.setTimeZone(TimeZone.getTimeZone(timezone)); return sdf.format(value); &#125; &#125; /** * 测试的一个bo */ @Getter @Setter public static class Student &#123; @Label(&quot;姓名&quot;) private String name; @Label(&quot;出生日期&quot;) @Format(pattern = &quot;yyyy/MM/dd&quot;) private Date born; @Label(&quot;分数&quot;) private Double score; &#125; /** * 测试运算结果 * @param args */ public static void main(String[] args) &#123; Student student = new Student(); student.setBorn(new Date()); student.setName(&quot;张三&quot;); student.setScore(244.0); System.out.println(SimpleFormatter.format(student)); /** * 输出： * 姓名 ? 张三 * 出生日期 ? 2023/03/12 * 分数 ? 244.0 */ &#125;&#125; 参考 详解Java注解机制 怎样理解 Java 注解和运用注解编程？ - bravo1988的回答 - 知乎","tags":[]},{"title":"Java反射机制与应用","date":"2023-03-07T16:00:00.000Z","path":"JavaEngineer/Java反射机制与应用/","text":"总结 Java的反射机制提供了运行时分析处理类的能力。 Spring框架的IOC容器使用了反射技术，可以简化代码编写。 使用Spring+策略模式可以解决代码中if或switch代码块的代码耦合问题。 概述反射机制提供的功能: 在运行时判断任意一个对象所属的类 在运行的时候构造任意一个类的对象 在运行时判断一个类所具有的成员变量和方法 在运行时调用任何一个对象的方法 生成动态代理 反射机制Java反射机制类12345java.lang.Class; //类java.lang.reflect.Constructor;//构造方法java.lang.reflect.Field; //类的成员变量java.lang.reflect.Method;//类的方法java.lang.reflect.Modifier;//访问权限 优点和缺点 优点：运行期类型的判断，动态类加载，动态代理使用反射。 缺点：性能是一个问题，反射相当于一系列解释操作，通知jvm要做的事情，性能比直接的java代码要慢很多。 反射机制的应用场景 逆向代码 ，例如反编译 与注解相结合的框架 例如Retrofit 单纯的反射机制应用框架 例如EventBus 2.x 动态生成类框架 例如Gson 反射机制的应用Spring框架的IOCIOC中最基本的技术就是“反射(Reflection)”编程，，通俗来讲就是根据给出的类名（字符串方式）来动态地生成对象，这种编程方式可以让对象在生成时才决定到底是哪一种对象。只是在Spring中要生产的对象都在配置文件中给出定义，目的就是提高灵活性和可维护性。 我们可以把IOC容器的工作模式看做是工厂模式的升华，可以把IOC容器看作是一个工厂，这个工厂里要生产的对象都在配置文件中给出定义，然后利用编程语言的的反射编程，根据配置文件中给出的类名生成相应的对象。从实现来看，IOC是把以前在工厂方法里写死的对象生成代码，改变为由配置文件来定义，也就是把工厂和对象生成这两者独立分隔开来，目的就是提高灵活性和可维护性。 Spring反射的策略模式如果不是用设计模式来做的情况下，会出现很多个 if-else 或者 switch 语句块。这样的话，代码耦合性也会非常高，将来再增加一个需求，则会导致一直增加判断语句块。也违反了面向对象的开闭原则。耦合性也会非常高，将来再增加一个需求，则会导致一直增加判断语句块。也违反了面向对象的开闭原则。反射+策略模式解决代码中if或switch代码块的代码耦合问题。 12345678910111213141516171819202122232425262728@Componentpublic class MyStragtrgyReflexContent implements ApplicationContextAware,InitializingBean &#123; private Map&lt;String,MyStragtegy&gt; beanMap ; private ApplicationContext applicationContext; /** * 实现ApplicationContextAware接口，Spring容器会在创建MyStragtrgyReflexContent类之后， * 自动调用实现接口的setApplicationContextAware()方法， * 调用该方法时，会将ApplicationContext(容器本身)作为参数传给该方法， * 我们可以在该方法中将Spring传入的参数ApplicationContext赋给MyStragtrgyReflexContent对象的applicationContext实例变量，因此接下来可以通过该applicationContext实例变量来访问容器本身。 */ @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; /** * 实现InitializingBean接口，该接口提供了afterPropertiesSet方法。 * spirng容器在初始化bean的时候会执行afterPropertiesSet方法， * 我们可以在该方法中调用applicationContext接口提供的getBeansOfType方法获得实现MyStragtegy类的Bean，将之存储至map集合中 */ @Override public void afterPropertiesSet() throws Exception &#123; Map&lt;String,MyStragtegy&gt; map = applicationContext.getBeansOfType(MyStragtegy.class); this.beanMap = map; &#125; public MyStragtegy getMyStragtegy(String beanName)&#123; return this.beanMap.get(beanName); &#125;&#125; 12345678910111213141516@Servicepublic class StragtegyReflexService &#123; @Autowired private MyStragtrgyReflexContent reflexContent; public String play(String type)&#123; MyStragtegy myStragtegy = reflexContent.getMyStragtegy(type); if (myStragtegy!=null)&#123; return myStragtegy.play(); &#125;else &#123; return &quot;还没有这个宠物哟！~&quot;; &#125; &#125;&#125; 参考 Java反射机制及应用场景 - 王道通 - 工作LIFE Spring反射+策略模式Demo - Java程序猿部落 Spring使用反射机制后实现注解实例化Bean注入 Spring的IOC（控制反转）/DI（依赖注入）原理（一）：用到“反射”编程 - Freer","tags":[]},{"title":"Java泛型机制和应用","date":"2023-03-07T16:00:00.000Z","path":"JavaEngineer/Java泛型机制和应用/","text":"总结 泛型解决了参数类型缺少检查造成的问题。 泛型可以在类、接口、函数上使用。 通配符是为了让Java泛型支持范围限定，这样使得泛型的灵活性提升，同时也让通用性设计有了更多的空间。 概述编译期是指把源码交给编译器编译成计算机可执行文件的过程。运行期是指把编译后的文件交给计算机执行，直到程序结束。在Java中就是把.java文件编译成.class文件，再把编译后的文件交给JVM加载执行。 泛型又叫“参数化类型”。泛型就是在定义类、接口、方法的时候指定某一种特定类型（碗），让类、接口、方法的使用者来决定具体用哪一种类型的参数（盛的东西）。Java的泛型是在1.5引入的，只在编译期做泛型检查，运行期泛型就会消失，我们把这称为“泛型擦除”，最终类型都会变成 Object。 泛型主要解决的问题： 集合对元素类型没有任何限制引发的业务问题。 把对象写入集合，在获取对象的时候进行强制类型转换出现问题。 语法规则使用菱形语法表示泛型，例如 List&lt;String&gt; strList= new ArrayList&lt;&gt;(); 。 泛型允许在定义类、接口、方法时使用类型参数，这个类型形参将在变量声明、创建对象、调用方法时动态得指定。 泛型类类上定义泛型，作用于类的成员变量与函数，代码实例如下： 12345678910111213141516171819202122232425public class Apple&lt;T&gt; &#123; // 使用T类型形参定义实际变量 private T info; public T getInfo() &#123; return info; &#125; public void setInfo(T info) &#123; this.info = info; &#125; public Apple(T info) &#123; this.info = info; &#125; public static void main(String[] args) &#123; // 创建变量时候指定泛型类型，构造器只能使用对应类型 Apple&lt;String&gt; a1 = new Apple&lt;&gt;(&quot;苹果&quot;); System.out.printf(a1.getInfo()); Apple&lt;Double&gt; a2 = new Apple&lt;&gt;(2.13); System.out.printf(a2.getInfo()+&quot;&quot;); &#125;&#125; 泛型接口接口上定义泛型，作用于函数，代码实例如下： 12345678public interface GenericInterface&lt;T&gt; &#123; public T get(); public void set(T t); public T delete(T t); default T defaultFunction(T t)&#123; return t; &#125;&#125; 泛型函数函数返回类型旁加上泛型，作用于函数，代码实例如下： 12345678910public class GenericFunction &#123; public &lt;T&gt; void function(T t) &#123; &#125; public &lt;T&gt; T functionTwo(T t) &#123; return t; &#125; public &lt;T&gt; String functionThree(T t) &#123; return &quot;&quot;; &#125;&#125; 通配符通配符是为了让Java泛型支持范围限定，这样使得泛型的灵活性提升，同时也让通用性设计有了更多的空间。 &lt;?&gt;：无界通配符，即类型不确定，任意类型 &lt;? extends T&gt;：上边界通配符，即?是继承自T的任意子类型，遵守只读不写 &lt;? super T&gt;：下边界通配符，即?是T的任意父类型，遵守只写不读 「 通配符限定的范围是体现在确认“参数化类型”的时候，而不是“参数化类型”填充后 」 123456789101112131415161718192021222324/** * 1.创建泛型为Number的List类，Integer、Double、Long等都是Number的子类 * new ArrayList&lt;&gt;() 等价于 new ArrayList&lt;Number&gt;() */List&lt;Number&gt; numberList = new ArrayList&lt;Number&gt;();/** * 2.添加不同子类 */numberList.add(1);//添加Integer类型numberList.add(0.5);//添加Double类型numberList.add(10000L);//添加Long类型/** * 3.创建泛型为Number的List类，Integer、Double、Long等都是Number的子类 * 引用是泛型类别是Number，但具体实现指定的泛型是Integer */List&lt;Number&gt; numberListTwo = new ArrayList&lt;Integer&gt;();//err 异常编译不通过/** * 4.创建泛型为Integer的List类，把该对象的引用地址指向泛型为Number的List */List&lt;Integer&gt; integerList = new ArrayList&lt;Integer&gt;();List&lt;Number&gt; numberListThree = integerList;//err 异常编译不通过 上边界通配符只读不写，下边界通配符只写不读。 &lt;? extends T&gt;上边界通配符不作为函数入参，只作为函数返回类型，比如List&lt;? extends T&gt;的使用add函数会编译不通过，get函数则没问题。 &lt;? super T&gt;下边界通配符不作为函数返回类型，只作为函数入参，比如List&lt;? super T&gt;的add函数正常调用，get函数也没问题，但只会返回Object。 设计原则可以参考 PECS (producer-extends,consumer-super)原则。PECS原则也就是说，如果参数化类型表示一个生产者E，就使用&lt;? extends E&gt;，如果参数化类型表示一个消费者E，则使用&lt;? super E&gt;。 1234567891011121314151617181920212223242526272829public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125;public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125;public void forEach(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); final int expectedModCount = modCount; @SuppressWarnings(&quot;unchecked&quot;) final E[] elementData = (E[]) this.elementData; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) &#123; action.accept(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; 参考 一文通关苦涩难懂的Java泛型 - 程序猿阿星 《疯狂Java讲义-第9章 泛型》 Java泛型的PECS原则","tags":[]},{"title":"网文大纲从零开始编写","date":"2023-03-01T16:00:00.000Z","path":"网文学习/网文大纲从零开始编写/","text":"概述 编写大致框架； 撰写设定落地； 撰写完善细纲。 教程准备阶段 记录灵感。 选定脑洞，刷同类文+查资料。 大纲阶段第一部分：编写大致框架 步骤一： 一句话核心梗。 一句话概括模板，谁（和谁）遭遇了什么，然后做（经历）了什么，最后结局如何。 一个好的作品，主题鲜明统一，有且仅有一个主题。 步骤二：三百字～五百字简纲（全文梗概）。对一句话核心进行扩写。 步骤三：一干字～五干字粗纲（进一步细化的全文梗概）。 第二部分：设定落地。 步骤一：世界观（设定）。 用一个文档写定这个故事的世界观。 世界观和设定写的越详细越好。 步骤二：人设（人物小传）。 Ta经历过些什么，ta被他人、被世界如何对待，从而让ta成为了现在的性格与模样？ Ta是一个这样的人，为什么？ 编写人物基本资料卡。 构思一个具体的场景，把不同人物放进去看是什么反应。 步骤三：人物线。 固定某个角色的视角，把你的故事（粗纲）重新讲一遍。 从每个角色的视角，重新经历一遍这个故事。 两个关键点，人物动机（为什么这么做）和行动（做了什么）。 在人物线路，你要百分百尊重这个角色。 第三部分：完善细纲。 步骤一：阶段 步骤二：事件（具体时间） 步骤三：细节（章纲） 将步骤一到三用一个Excel罗列编写。 步骤四：人物弧光（性格成长线+感情线） 参考 超完整网文大纲教程（最新版）- 爱斯基布拉斯基-竹子","tags":[]},{"title":"开源软件靠什么赚钱","date":"2023-02-20T16:00:00.000Z","path":"技术人生/开源软件靠什么赚钱/","text":"使用CSDN的 ChatGPT （ https://so.csdn.net/so/chat ）询问“开源项目靠什么赚钱”会得到如下答案。 开源项目通常是免费使用的，但是这并不意味着开发者不能赚钱。开源项目可以通过以下方式获得收益： 提供商业支持和服务：开发者可以为使用开源项目的企业或个人提供商业支持和服务，例如帮助他们安装、调试、维护和升级软件。 开发附加功能或插件：开发者可以为开源项目开发附加功能或插件，并向使用者收费。 接受捐赠：开发者可以在自己的网站上提供捐赠按钮，供感谢他们的用户捐赠。 在线广告：如果开源项目有一个网站或在线应用程序，开发者可以在其中放置广告来获得收益。 开展培训或咨询业务：开发者可以通过提供培训或咨询服务来获得收益，帮助使用者更好地使用开源项目。 其他方式：还有其他许多方法可以让开源项目开发者赚钱，例如出版书籍、举办会议等。 通过知乎网站（个人搞开源怎么赚钱？ - OSCHINA的文章 - 知乎https://zhuanlan.zhihu.com/p/355411897 ）获取答案会获得更加全面的回答，相比chatgpt的简洁回答，知乎回答的更有理有据。 “在不违反开源许可证以及开源社区基本道德准则的前提下，开发者从开源项目中合理获利并不是一件坏事。 自由软件运动领袖 Richard Stallman （RMS）曾鼓励自由与开源软件作者合理利用开源软件赚钱，以更好地维持项目的研发和推广。Linux Kernel 维护者 Linus Torvalds 也接受着来自各大厂商的资助，从而能够全职进行 Linux Kernel 的维护工作。” Bug 赏金计划 BUG 赏金计划是很多大型开源机构面向个人开发者推出的一种赚钱的方式。开发者可以通过报告开源项目上的 BUG，也可以直接修复这些 BUG 获得来自项目官方不同程度的奖金。 提供付费支持 提供付费支持是很多开源项目团队获利的经典方式之一。 如果开发者决定开始为某开源项目提供付费支持，则可以向其他人提供他们需要的有偿服务，这里有些例子：帮助进行基本安装或使用。代码和错误修复。添加新的和额外的功能。提供书面文件（例如书籍和教程）。但要注意，如果你提供的支持包括对项目源代码进行更改，则需要核对项目采用的开源许可证，以确保其允许该类型的活动。当然，你不能只修改项目原作者的原始代码，你必须维护自己的产品副本。 出售增强功能/插件 例如，开发人员销售 WordPress 插件。用户可以免费下载并安装 WordPress，但WordPress 拥有丰富的付费插件生态，用户会根据自己的需求购买用于修改或增强现有功能的付费插件，开发者可以通过开发并出售这些插件获利。 出售代码以外的内容 写和出售关于该项目的书籍教程。这可以通过与出版社推荐主题来完成。后者将负责编辑过程和发布步骤，让你专注于写作。当然，你必须与出版社分配收入，但这是值得的。 为一些内容付费平台创建视频课程。这样做会产生被动收入，就像书出版后一样。另外，这些平台通常会提供视频培训。 撰写有关产品的推广帖子。这并不意味着开源产品的所有者要向您付费以撰写这些帖子，而是使某些博客对该主题感兴趣，并愿意向你付费以提供有关其他主题的内容。 来自用户的捐赠 GitHub、Gitee 等代码托管平台都拥有用户捐赠的功能，开源项目拥有者可以从这些平台获得来自用户的自发捐赠，当然这项收入的大小要取决于你的项目是否足够强大，以及你所在地区的用户是否足够慷慨。 用参与开源提升自己的职场竞争力 有时单纯的参与开源项目的代码贡献并不能带来直接的金钱利益，但开发者可以将这段经历写进简历里，以获得更多的就业机会。也可以通过参与大型公司旗下的开源项目，从而获得进入这家公司工作的机会。 CSDN的 ChatGPT 也是使用开源模型建立的，开源产品也可以商业化也就是一个例子。通过开源产品能赚钱，但是有难度。但总的来说对于技术的提升、个人影响力的提升都是很重要的一种方法。","tags":[]},{"title":"使用Springboot集成MybatisGenerator","date":"2023-02-19T16:00:00.000Z","path":"编程/使用Springboot集成MybatisGenerator/","text":"概述Mybatis Generator 可以生成mybatis的模板代码，包括动态脚本、实体类、Mapper映射访问类。Mybatis Generator 有多种使用方式，此处介绍一种线上环境比较用的多的场景，通过Maven插件使用。 使用方法如下： 通过核心jar包cmd使用。 例如 java -jar mybatis-generator-core-x.x.x.jar -configfile \\temp\\generatorConfig.xml -overwrite 通过 Ant task 使用。 通过 java程序使用。 通过 Maven Plugin 使用。 前置条件 JDK 1.8+ SpringBoot 2.1+ mybatis 3+ 引入 MybatisGenerator 引入mybatis，用于后续的代码使用。 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.4&lt;/version&gt;&lt;/dependency&gt; MybatisGenerator Maven Plugin的引入和配置。 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt; &lt;configuration&gt; &lt;!-- 指定配置文件地址--&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generatorConfigSqlLite.xml&lt;/configurationFile&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; MBG配置使用MBG配置有两种形式，一种是xml、一种是java代码。此处演示使用的是xml配置的方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt; &lt;!-- 指定数据库连接池用到的依赖 --&gt; &lt;classPathEntry location=&quot;E:\\repo\\mvn-repo\\org\\xerial\\sqlite-jdbc\\3.40.1.0\\sqlite-jdbc-3.40.1.0.jar&quot; /&gt; &lt;context id=&quot;DB2Tables&quot; targetRuntime=&quot;MyBatis3&quot;&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt; &lt;/commentGenerator&gt; &lt;!-- 指定 数据库链接配置 --&gt; &lt;jdbcConnection driverClass=&quot;org.sqlite.JDBC&quot; connectionURL=&quot;jdbc:sqlite:E:\\ws-research\\backend\\rssboot\\src\\main\\resources\\db\\rssboot.db&quot; userId=&quot;&quot; password=&quot;&quot;&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver &gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot; /&gt; &lt;/javaTypeResolver&gt; &lt;!-- 指定javaBean生成的位置 --&gt; &lt;javaModelGenerator targetPackage=&quot;io.rainforest.rss.dao.po&quot; targetProject=&quot;./src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot; /&gt; &lt;/javaModelGenerator&gt; &lt;!--指定sql映射文件生成的位置 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;./src/main/resources/mybatis&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot; /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 指定dao接口生成的位置，mapper接口 --&gt; &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;io.rainforest.rss.dao.mapper&quot; targetProject=&quot;./src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot; /&gt; &lt;/javaClientGenerator&gt; &lt;!-- table指定每个表的生成策略 --&gt; &lt;table tableName=&quot;rss_follow&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;MySql&quot; identity=&quot;true&quot; /&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 参考 Running MyBatis Generator - http://mybatis.org/generator/running/running.html","tags":[]},{"title":"使用Springboot集成Sqlite","date":"2023-02-19T16:00:00.000Z","path":"编程/使用Springboot集成Sqlite/","text":"概述SQLite，是一款轻型的数据库，是遵守ACID的关系型数据库管理系统，它包含在一个相对小的C库中。它是D.RichardHipp建立的公有领域项目。它的设计目标是嵌入式的，而且已经在很多嵌入式产品中使用了它，它占用资源非常的低，在嵌入式设备中，可能只需要几百K的内存就够了。 简单来说，通过一个文件就能启动和使用关系型数据库管理。 前置条件 JDK 1.8+ SpringBoot 2.1+ 引入sqlite 引入sqlite依赖和数据库依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.xerial&lt;/groupId&gt; &lt;artifactId&gt;sqlite-jdbc&lt;/artifactId&gt; &lt;version&gt;3.40.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 修改启动配置： 12345## 数据库连接池## 驱动使用sqlitespring.datasource.driver-class-name=org.sqlite.JDBC# 指定数据库位置，相对或者绝对定位spring.datasource.url=jdbc:sqlite::resource:db/rssboot.db 使用 通过mybatis操作数据库。 通过JdbcTemplate操作数据库。 通过 JPA 操作数据库。 参考无","tags":[]},{"title":"02-Spring中的设计模式之模板模式","date":"2022-12-07T16:00:00.000Z","path":"深度讲解Spring5底层原理/02-Spring中的设计模式之模板模式/","text":"模板模式模板方法模式在一个方法中定义一个算法骨架，并将某些步骤推迟到子类中实现。模板方法模式可以让子类在不改变算法整体结构的情况下，重新定义算法中的某些步骤。这里的“算法”，我们可以理解为广义上的“业务逻辑”，并不特指数据结构和算法中的“算法”。这里的算法骨架就是“模板”，包含算法骨架的方法就是“模板方法”，这也是模板方法模式名字的由来。 模板模式有两大作用：复用和扩展。其中复用指的是，所有的子类可以复用父类中提供的模板方法的代码。扩展指的是，框架通过模板模式提供功能扩展点，让框架用户可以在不修改框架源码的情况下，基于扩展点定制化框架的功能。 除此之外，我们还讲到回调。它跟模板模式具有相同的作用：代码复用和扩展。在一些框架、类库、组件等的设计中经常会用到，比如 JdbcTemplate 就是用了回调。相对于普通的函数调用，回调是一种双向调用关系。A 类事先注册某个函数 F 到 B 类，A 类在调用 B 类的 P 函数的时候，B 类反过来调用 A 类注册给它的 F 函数。这里的 F 函数就是“回调函数”。A 调用 B，B 反过来又调用 A，这种调用机制就叫作“回调”。 回调可以细分为同步回调和异步回调。从应用场景上来看，同步回调看起来更像模板模式，异步回调看起来更像观察者模式。回调跟模板模式的区别，更多的是在代码实现上，而非应用场景上。回调基于组合关系来实现，模板模式基于继承关系来实现。回调比模板模式更加灵活。 Spring中的模板方法 DefaultListableBeanFactory 中的 BeanFactoryPostProcessor 。 DefaultListableBeanFactory 中的 BeanPostProcessor 。 12345org.springframework.context.annotation.internalConfigurationAnnotationProcessor // 注解配置处理org.springframework.context.annotation.internalAutowiredAnnotationProcessor // 自动注入处理org.springframework.context.annotation.internalCommonAnnotationProcessor // 通用注解处理org.springframework.context.event.internalEventListenerProcessor // 事件处理类org.springframework.context.event.internalEventListenerFactory // 事件监听类 同一调用postProcessBeanFactory接口方法执行对BeanFactory的后置处理。 同一调用 postProcessBeforeInitialization postProcessAfterInitialization 接口方法执行对Bean的后置处理。 12345678910111213@FunctionalInterfacepublic interface BeanFactoryPostProcessor &#123; /** * Modify the application context&#x27;s internal bean factory after its standard * initialization. All bean definitions will have been loaded, but no beans * will have been instantiated yet. This allows for overriding or adding * properties even to eager-initializing beans. * @param beanFactory the bean factory used by the application context * @throws org.springframework.beans.BeansException in case of errors */ void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 12345678910111213141516171819202122package org.springframework.beans.factory.config;import org.springframework.beans.BeansException;import org.springframework.lang.Nullable;/** * Factory hook that allows for custom modification of new bean instances &amp;mdash; * for example, checking for marker interfaces or wrapping beans with proxies. */public interface BeanPostProcessor &#123; @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125;&#125; 参考代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package engineer.spring.design;import java.util.ArrayList;import java.util.List;/** * 模板方法设计模式 * * @author Q */public class TemplateMethodTest &#123; public static void main(String[] args) &#123; MyBeanFactory beanFactory = new MyBeanFactory(); beanFactory.addBeanPostProcessor((bean) -&gt; System.out.println(&quot;注入 @Autowired&quot; + bean)); beanFactory.addBeanPostProcessor((bean) -&gt; System.out.println(&quot;注入 @Resource&quot; + bean)); beanFactory.addBeanPostProcessor((bean) -&gt; System.out.println(&quot;注入 @Configuration&quot; + bean)); System.out.println(beanFactory.getBean()); &#125; static class MyBeanFactory &#123; public Object getBean() &#123; Object bean = new Object(); System.out.println(&quot;构造 &quot; + bean); // 1. 解析@Autowired // 2. 解析@Resource System.out.println(&quot;依赖注入 &quot; + bean); postProcessorList.forEach(beanPostProcessor -&gt; &#123; beanPostProcessor.inject(bean); &#125;); System.out.println(&quot;初始化 &quot; + bean); // 扩展功能需要修改代码 return bean; &#125; public void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123; postProcessorList.add(beanPostProcessor); &#125; private List&lt;BeanPostProcessor&gt; postProcessorList = new ArrayList&lt;&gt;(); &#125; static interface BeanPostProcessor &#123; // 依赖注入模板方法，通过调用接口，具体得实现将某些步骤推迟到子类中实现 void inject(Object bean); &#125;&#125; 参考 74 | 总结回顾23种经典设计模式的原理、背后的思想、应用场景等","tags":[]},{"title":"01-Spring中BeanFacory和ApplicationContext的功能与实现","date":"2022-12-06T16:00:00.000Z","path":"深度讲解Spring5底层原理/01-Spring中BeanFacory和ApplicationContext的功能与实现/","text":"导图flowchart LR A(Spring) --> B(BeanFacory) A --> C(ApplicationContext) C --> 1(功能) C --> 2(实现) B --> 3(功能) B --> 4(实现) A --> 5(差异) 差异org.springframework.beans 和 org.springframework.context 是Spring框架IoC容器的基础包。 BeanFactory 接口提供了一种高级配置机制，能够管理任何类型的对象。ApplicationContext是BeanFactory的子接口，添加了如下功能： 更容易与Spring的AOP功能集成 消息资源处理（用于国际化） 事件发布 特定应用层的上下文，如用于web应用程序的WebApplicationContext Table 9. Feature Matrix Feature BeanFactory ApplicationContext Bean instantiation/wiring Bean的实例化和自动装配 Yes Yes Integrated lifecycle management 集成bean生命周期管理 No Yes Automatic BeanPostProcessor registration Bean后置处理器自动注册 No Yes Automatic BeanFactoryPostProcessor registration BeanFactory后置处理器自动注册 No Yes Convenient MessageSource access (for internationalization) 国际化资源访问 No Yes Built-in ApplicationEvent publication mechanism 内置事件发布机制 No Yes 常见实现ApplicationContext： AnnotationConfigApplicationContext 基于注解配置的A加载上下文 ClassPathXmlApplicationContext 基于xml配置的加载上下文 FileSystemXmlApplicationContext 基于xml配置的加载上下文 GenericApplicationContext 通用的上下文，更加灵活加载配置 BeanFactory： DefaultListableBeanFactory 默认BeanFactory 代码示例beanFactory 不会做的事情： 不会主动调用 beanFactory的后处理器 不会主动添加Bean的后处理器 不会主动初始化单例 不会解析beanFactory，还不会解析 ${} 占位符 #{} EL表达式 通过 DefaultListableBeanFactory 实现 ApplicationContext的功能： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107package engineer.spring.ioc.context;import javax.annotation.Resource;public class AppBeanFactory &#123; protected final Log log = LogFactory.getLog(getClass()); public static void main(String[] args) &#123; DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); // bean的定义 初始化 销毁 class scope 生命周期定义 AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition(Config.class) .setScope(BeanDefinition.SCOPE_SINGLETON).getBeanDefinition(); beanFactory.registerBeanDefinition(&quot;config&quot;, beanDefinition); // 给beanFactory添加常用的后置处理器 // 设置排序方法 AnnotationConfigUtils.registerAnnotationConfigProcessors(beanFactory); // beanFactory 执行后置处理器类 补充一些bean的定义 beanFactory.getBeansOfType(BeanFactoryPostProcessor.class).values().stream().sorted(beanFactory.getDependencyComparator()).forEach(beanFactoryPostProcessor -&gt; &#123; System.out.println(&quot;BeanFactoryPostProcessor: &quot; + beanFactoryPostProcessor.getClass()); beanFactoryPostProcessor.postProcessBeanFactory(beanFactory); &#125;); // bean 执行后置处理器类 补充一些bean的扩展处理 如 @autowired @resource beanFactory.getBeansOfType(BeanPostProcessor.class).values().forEach(beanPostProcessor -&gt; &#123; System.out.println(&quot;BeanPostProcessor: &quot; + beanPostProcessor.getClass()); beanFactory.addBeanPostProcessor(beanPostProcessor); &#125;); // 预处理单例类 beanFactory.preInstantiateSingletons(); System.out.println(beanFactory.getBean(Bean1.class).getBean2()); for (String beanDefinitionName : beanFactory.getBeanDefinitionNames()) &#123; System.out.println(beanDefinitionName); &#125; // beanFactory 后处理器有排序的逻辑 System.out.println(beanFactory.getBean(Bean1.class).getInter()); &#125; @Configuration static class Config &#123; @Bean public Bean1 bean1() &#123; return new Bean1(); &#125; @Bean public Bean2 bean2() &#123; return new Bean2(); &#125; @Bean public Bean3 bean3() &#123; return new Bean3(); &#125; @Bean public Bean4 bean4() &#123; return new Bean4(); &#125; &#125; static class Bean1 &#123; @Autowired private Bean2 bean2; @Autowired @Resource(name = &quot;bean4&quot;) private Inter bean3; public Bean1() &#123; System.out.println(&quot;Bean1构造器初始化&quot;); &#125; public Bean2 getBean2() &#123; return bean2; &#125; public Inter getInter() &#123; return bean3; &#125; &#125; static class Bean2 &#123; public Bean2() &#123; System.out.println(&quot;Bean2构造器初始化&quot;); &#125; &#125; interface Inter &#123; &#125; static class Bean3 implements Inter &#123; &#125; static class Bean4 implements Inter &#123; &#125;&#125; 参考 1.16.1. BeanFactory or ApplicationContext?","tags":[]},{"title":"把工作当做热爱","date":"2022-06-22T16:00:00.000Z","path":"技术人生/把工作当做热爱/","text":"一个人每周至少要工作40个小时，而平均每个人的工作年限是35年，也就是说除了睡觉以外，占据你最多时间的是——工作。你是要浑浑噩噩度过一天中精力最充足的时间，还是集中精力解决一个个抛过来的难题磨练自己的技能，选择权在于你。 稻盛和夫曾说过：“劳动的意义不仅在于追求业绩，更在于完善人的内心。” 而你会发现，当你不再“逃跑”，而是选择面对直视问题的时候，你的人格就得到了磨练，你逐渐从从一个喜欢逃避、厌恶麻烦、随意任性的人变成一个直接面对问题、有责任感、值得信任的成熟社会人。 就是如果你一心扑在工作上，不管吃饭也好、睡觉也好，都在想着工作，那么那个困扰你很久的问题就可能在某个时刻得到启示。 每天吃吃喝喝的生活，在第一个星期的时候或许会觉得享受，但如果把这样的生活持续一个月、甚至半年，你会发现，你根本感觉不到快乐了。因为幸福是一种对比，或者说是一种感受的落差。 不可否认的是，工作能够给人带来意义感。 正如稻盛和夫所说，“拼命工作的背后隐藏着快乐和欢喜，正像慢慢长夜结束后，曙光就会到来一样。” 在《干法》中，稻盛和夫将人分为三种类型： 1）不燃型：点火也烧不起来的人；2）可燃型：点火就着的人；3）自燃型：没人点自己就能熊熊燃烧的人。 自燃型的他们有极强的自主驱动力，长期处于学习区，他们不认为工作是一种任务，相反的是，他们认为工作很有意思，他们从来不会等别人吩咐了才去干，而是在被人吩咐之前就自发去干。 把工作当做热爱的认识能够持久的发光发热，温柔度过漫长的日子。 摘录自： 《人为什么要热爱工作？这是我听过最好的答案》https://mp.weixin.qq.com/s/_CNAsITDLyTMpOuVJrYh4Q","tags":[]},{"title":"06-追踪微服务调用","date":"2022-05-08T16:00:00.000Z","path":"从0开始学微服务/06-追踪微服务调用/","text":"概要12345678910111213141516@startmindmap* 追踪微服务调用** 服务追踪的作用*** 优化系统瓶颈*** 优化链路调用*** 生成网络拓扑*** 透明传输数据** 服务追踪系统原理*** traceId，用于标识某一次具体的请求 ID。*** spanId，用于标识一次 RPC 调用在分布式请求中的位置。*** annotation，用于业务自定义埋点数据。** 服务追踪系统实现*** 数据采集层，负责数据埋点并上报。*** 数据处理层，负责数据的存储与计算。*** 数据展示层，负责数据的图形化展示。@endmindmap 微服务架构下，由于进行了服务拆分，一次请求往往需要涉及多个服务，每个服务可能是由不同的团队开发，使用了不同的编程语言，还有可能部署在不同的机器上，分布在不同的数据中心。 服务追踪的作用 第一，优化系统瓶颈。通过记录调用经过的每一条链路上的耗时，我们能快速定位整个系统的瓶颈点在哪里 第二，优化链路调用。通过服务追踪可以分析调用所经过的路径，然后评估是否合理。 第三，生成网络拓扑。通过服务追踪系统中记录的链路信息，可以生成一张系统的网络调用拓扑图，它可以反映系统都依赖了哪些服务，以及服务之间的调用关系是什么样的。 第四，透明传输数据。 服务追踪系统原理Dapper, a Large-Scale Distributed Systems Tracing Infrastructure：调用链：通过一个全局唯一的 ID 将分布在各个服务节点上的同一次请求串联起来，从而还原原有的调用关系，可以追踪系统问题、分析调用数据并统计各种系统指标。 traceId，用于标识某一次具体的请求 ID。当用户的请求进入系统后，会在 RPC 调用网络的第一层生成一个全局唯一的 traceId，并且会随着每一层的 RPC 调用，不断往后传递，这样的话通过 traceId 就可以把一次用户请求在系统中调用的路径串联起来。 spanId，用于标识一次 RPC 调用在分布式请求中的位置。当用户的请求进入系统后，处在 RPC 调用网络的第一层 A 时 spanId 初始值是 0，进入下一层 RPC 调用 B 的时候 spanId 是 0.1，继续进入下一层 RPC 调用 C 时 spanId 是 0.1.1，而与 B 处在同一层的 RPC 调用 E 的 spanId 是 0.2，这样的话通过 spanId 就可以定位某一次 RPC 请求在系统调用中所处的位置，以及它的上下游依赖分别是谁。 annotation，用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户 UID。 服务追踪系统实现 数据采集层，负责数据埋点并上报。 数据处理层，负责数据的存储与计算。 数据展示层，负责数据的图形化展示。 参考 [从 0 开始学微服务 - 极客时间 - 胡忠想]","tags":[]},{"title":"05-监控微服务调用","date":"2022-04-28T16:00:00.000Z","path":"从0开始学微服务/05-监控微服务调用/","text":"概要1234567891011121314151617181920212223@startmindmap* 监控微服务** 监控对象*** 用户端监控*** 接口监控*** 资源监控*** 基础监控** 监控指标*** 请求量*** 响应时间*** 错误率** 监控维度*** 全局维度*** 分机房维度*** 单机维度*** 时间维度*** 核心维度** 监控系统原理*** 数据采集*** 数据传输*** 数据处理*** 数据展示@endmindmap 与单体应用相比，在微服务架构下，一次用户调用会因为服务化拆分后，变成多个不同服务之间的相互调用，这也就需要对拆分后的每个服务都监控起来。 监控对象 用户端监控。通常是指业务直接对用户提供的功能的监控。 接口监控。通常是指业务提供的功能所依赖的具体 RPC 接口的监控。 资源监控。通常是指某个接口依赖的资源的监控。 基础监控。通常是指对服务器本身的健康状况的监控。 监控指标 请求量。请求量监控分为两个维度，一个是实时请求量，一个是统计请求量。实时请求量用 QPS（Queries Per Second）即每秒查询次数来衡量，它反映了服务调用的实时变化情况。统计请求量一般用 PV（Page View）即一段时间内用户的访问量来衡量，比如一天的 PV 代表了服务一天的请求量，通常用来统计报表。 响应时间。大多数情况下，可以用一段时间内所有调用的平均耗时来反映请求的响应时间。 错误率。错误率的监控通常用一段时间内调用失败的次数占调用总次数的比率来衡量，比如对于接口的错误率一般用接口返回错误码为 503 的比率来表示。 监控维度 全局维度。从整体角度监控对象的的请求量、平均耗时以及错误率，全局维度的监控一般是为了让你对监控对象的调用情况有个整体了解。 分机房维度。 单机维度。即便是在同一个机房内部，可能由于采购年份和批次的不同，位于不同机器上的同一个监控对象的各种指标也会有很大差异。 时间维度。同一个监控对象，在每天的同一时刻各种指标通常也不会一样，这种差异要么是由业务变更导致，要么是运营活动导致。 核心维度。业务上一般会依据重要性程度对监控对象进行分级，最简单的是分成核心业务和非核心业务。核心业务和非核心业务在部署上必须隔离，分开监控，这样才能对核心业务做重点保障。 监控系统原理监控系统主要包括四个环节：数据采集、数据传输、数据处理和数据展示。 数据采集通常有两种数据收集方式： 服务主动上报，这种处理方式通过在业务代码或者服务框架里加入数据收集代码逻辑，在每一次服务调用完成后，主动上报服务的调用信息。 代理收集，这种处理方式通过服务调用后把调用的详细信息记录到本地日志文件中，然后再通过代理去解析本地日志文件，然后再上报服务的调用信息。 数据传输数据传输最常用的方式有两种： UDP 传输，这种处理方式是数据处理单元提供服务器的请求地址，数据采集后通过 UDP 协议与服务器建立连接，然后把数据发送过去。 Kafka 传输，这种处理方式是数据采集后发送到指定的 Topic，然后数据处理单元再订阅对应的 Topic，就可以从 Kafka 消息队列中读取到对应的数据。 一般数据传输时采用的数据格式有两种： 二进制协议，最常用的就是 PB 对象，它的优点是高压缩比和高性能，可以减少传输带宽并且序列化和反序列化效率特别高。 文本协议，最常用的就是 JSON 字符串，它的优点是可读性好，但相比于 PB 对象，传输占用带宽高，并且解析性能也要差一些。 数据处理数据处理是对收集来的原始数据进行聚合并存储。数据聚合通常有两个维度： 接口维度聚合。把实时收到的数据按照接口名维度实时聚合在一起，这样就可以得到每个接口的实时请求量、平均耗时等信息。 机器维度聚合。把实时收到的数据按照调用的节点维度聚合在一起，这样就可以从单机维度去查看每个接口的实时请求量、平均耗时等信息。 聚合后的数据需要持久化到数据库中存储，所选用的数据库一般分为两种： 索引数据库，比如 Elasticsearch，以倒排索引的数据结构存储，需要查询的时候，根据索引来查询。 时序数据库，比如 OpenTSDB，以时序序列数据的方式存储，查询的时候按照时序如 1min、5min 等维度来查询。 数据展示数据展示是把处理后的数据以 Dashboard 的方式展示给用户。数据展示有多种方式，比如曲线图、饼状图、格子图展示等。 曲线图。一般是用来监控变化趋势的。 饼状图。一般是用来监控占比分布的。 格子图。主要做一些细粒度的监控。 参考 [从 0 开始学微服务 - 极客时间 - 胡忠想]","tags":[]},{"title":"04-实现RPC远程服务调用","date":"2022-04-27T16:00:00.000Z","path":"从0开始学微服务/04-实现RPC远程服务调用/","text":"概要123456789101112@startmindmap* RPC远程服务调用** 客户端和服务端建立网络连接*** HTTP 通信*** Socket 通信** 服务端处理请求*** 同步阻塞方式（BIO）*** 同步非阻塞方式 (NIO)*** 异步非阻塞方式（AIO）** 数据传输协议** 数据序列化和反序列化@endmindmap 在单体应用时，一次服务调用发生在同一台机器上的同一个进程内部，也就是说调用发生在本机内部，因此也被叫作本地方法调用。在进行服务化拆分之后，服务提供者和服务消费者运行在两台不同物理机上的不同进程内，它们之间的调用相比于本地方法调用，可称之为远程方法调用，简称 RPC（Remote Procedure Call）。 把服务消费者叫作客户端，服务提供者叫作服务端，两者通常位于网络上两个不同的地址，要完成一次 RPC 调用，就必须先建立网络连接。建立连接后，双方还必须按照某种约定的协议进行网络通信，这个协议就是通信协议。双方能够正常通信后，服务端接收到请求时，需要以某种方式进行处理，处理成功后，把请求结果返回给客户端。为了减少传输的数据大小，还要对数据进行压缩，也就是对数据进行序列化。 客户端和服务端建立网络连接客户端和服务端之间基于 TCP 协议建立网络连接最常用的途径有两种。 HTTP 通信 Socket 通信 HTTP 通信HTTP 通信是基于应用层 HTTP 协议的，而 HTTP 协议又是基于传输层 TCP 协议的。一次 HTTP 通信过程就是发起一次 HTTP 调用，而一次 HTTP 调用就会建立一个 TCP 连接，经历一次下图所示的“三次握手”的过程来建立连接。 完成请求后，再经历一次“四次挥手”的过程来断开连接。 Socket 通信Socket 通信是基于 TCP/IP 协议的封装，建立一次 Socket 连接至少需要一对套接字，其中一个运行于客户端，称为 ClientSocket ；另一个运行于服务器端，称为 ServerSocket 。Socket 通信的过程分为四个步骤：服务器监听、客户端请求、连接确认、数据传输。 服务器监听：ServerSocket 通过调用 bind() 函数绑定某个具体端口，然后调用 listen() 函数实时监控网络状态，等待客户端的连接请求。 客户端请求：ClientSocket 调用 connect() 函数向 ServerSocket 绑定的地址和端口发起连接请求。 服务端连接确认：当 ServerSocket 监听到或者接收到 ClientSocket 的连接请求时，调用 accept() 函数响应 ClientSocket 的请求，同客户端建立连接。 数据传输：当 ClientSocket 和 ServerSocket 建立连接后，ClientSocket 调用 send() 函数，ServerSocket 调用 receive() 函数，ServerSocket 处理完请求后，调用 send() 函数，ClientSocket 调用 receive() 函数，就可以得到得到返回结果。 服务端处理请求客户端和服务端已经建立了网络连接，服务端处理客户端的请求有三种方式。 同步阻塞方式（BIO），客户端每发一次请求，服务端就生成一个线程去处理。当客户端同时发起的请求很多时，服务端需要创建很多的线程去处理每一个请求，如果达到了系统最大的线程数瓶颈，新来的请求就没法处理了。 同步非阻塞方式 (NIO)，客户端每发一次请求，服务端并不是每次都创建一个新线程来处理，而是通过 I/O 多路复用技术进行处理。就是把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求。这种方式的优势是开销小，不用为每个请求创建一个线程，可以节省系统开销。 异步非阻塞方式（AIO），客户端只需要发起一个 I/O 操作然后立即返回，等 I/O 操作真正完成以后，客户端会得到 I/O 操作完成的通知，此时客户端只需要对数据进行处理就好了，不需要进行实际的 I/O 读写操作，因为真正的 I/O 读取或者写入操作已经由内核完成了。这种方式的优势是客户端无需等待，不存在阻塞等待问题。 数据传输协议最常用的有 HTTP 协议，它是一种开放的协议，各大网站的服务器和浏览器之间的数据传输大都采用了这种协议。还有一些定制的私有协议，比如阿里巴巴开源的 Dubbo 协议，也可以用于服务端和客户端之间的数据传输。 通常协议契约包括两个部分：消息头和消息体。其中消息头存放的是协议的公共字段以及用户扩展字段，消息体存放的是传输数据的具体内容。 数据序列化和反序列化一般数据在网络中进行传输前，都要先在发送方一端对数据进行编码，经过网络传输到达另一端后，再对数据进行解码，这个过程就是序列化和反序列化。 常用的序列化方式分为两类：文本类如 XML/JSON 等，二进制类如 PB/Thrift 等，而具体采用哪种序列化方式，主要取决于三个方面的因素。 支持数据结构类型的丰富度。数据结构种类支持的越多越好，这样的话对于使用者来说在编程时更加友好，有些序列化框架如 Hessian 2.0 还支持复杂的数据结构比如 Map、List 等。 跨语言支持。序列化方式是否支持跨语言也是一个很重要的因素，否则使用的场景就比较局限，比如 Java 序列化只支持 Java 语言，就不能用于跨语言的服务调用了。 性能。主要看两点，一个是序列化后的压缩比，一个是序列化的速度。以常用的 PB 序列化和 JSON 序列化协议为例来对比分析，PB 序列化的压缩比和速度都要比 JSON 序列化高很多，所以对性能和存储空间要求比较高的系统选用 PB 序列化更合适；而 JSON 序列化虽然性能要差一些，但可读性更好，更适合对外部提供服务。 参考 [从 0 开始学微服务 - 极客时间 - 胡忠想] The Transmission Control Protocol","tags":[]},{"title":"02-发布和引用服务","date":"2022-04-19T16:00:00.000Z","path":"从0开始学微服务/02-发布和引用服务/","text":"123456@startmindmap* 服务描述协议** RESTful API** XML 配置** IDL 文件@endmindmap 想要构建微服务，首先要解决的问题是，服务提供者如何发布一个服务，服务消费者如何引用这个服务。最常见的服务发布和引用的方式有三种： RESTful API XML 配置 IDL 文件 RESTful APIRESTful API 的方式，主要被用作 HTTP 或者 HTTPS 协议的接口定义。 RESTful API 的优点： 因为 HTTP 协议本身是一个公开的协议，对于服务消费者来说几乎没有学习成本，比较适合用作跨业务平台之间的服务协议。 行为和资源分离，更容易理解。 提出使用版本号（例如v1、v2），更加规范。 XML 配置XML 配置方式的服务发布和引用主要分三个步骤： 服务提供者定义接口，并实现接口。 服务提供者进程启动时，通过加载 server.xml 配置文件将接口暴露出去。 服务消费者进程启动时，通过加载 client.xml 配置文件来引入要调用的接口。 一般是私有 RPC 框架会选择 XML 配置这种方式来描述接口，因为私有 RPC 协议的性能要比 HTTP 协议高，所以在对性能要求比较高的场景下，采用 XML 配置的方式比较合适。 IDL 文件IDL 就是接口描述语言（interface description language）的缩写，通过一种中立的方式来描述接口，使得在不同的平台上运行的对象和不同语言编写的程序可以相互通信交流。 IDL 主要是用作跨语言平台的服务之间的调用，有两种最常用的 IDL：一个是 Facebook 开源的 Thrift 协议，另一个是 Google 开源的 gRPC 协议。一般是私有 RPC 框架会选择 XML 配置这种方式来描述接口，因为私有 RPC 协议的性能要比 HTTP 协议高，所以在对性能要求比较高的场景下，采用 XML 配置的方式比较合适。 gRPC 协议的服务描述是通过 proto 文件来定义接口的，然后再使用 protoc 来生成不同语言平台的客户端和服务端代码，从而具备跨语言服务调用能力。 参考 [从 0 开始学微服务 - 极客时间 - 胡忠想]","tags":[]},{"title":"03-注册中心原理和实现方式","date":"2022-04-19T16:00:00.000Z","path":"从0开始学微服务/03-注册中心原理和实现方式/","text":"概要1234567891011121314151617181920@startmindmap* 注册中心** 注册中心原理*** 服务提供者（RPC Server）*** 服务消费者（RPC Client）*** 和服务注册中心（Registry)** 注册中心实现方式*** 注册中心 API**** 服务注册接口**** 服务反注册接口**** 心跳汇报接口**** 服务订阅接口**** 服务变更查询接口**** 服务查询接口**** 服务修改接口*** 集群部署*** 目录存储*** 服务健康状态检查*** 服务状态变更通知@endmindmap 注册中心原理在微服务架构下，主要有三种角色：服务提供者（RPC Server）、服务消费者（RPC Client）和服务注册中心（Registry）。 RPC Server 提供服务，在启动时，根据服务发布文件 server.xml 中的配置的信息，向 Registry 注册自身服务，并向 Registry 定期发送心跳汇报存活状态。 RPC Client 调用服务，在启动时，根据服务引用文件 client.xml 中配置的信息，向 Registry 订阅服务，把 Registry 返回的服务节点列表缓存在本地内存中，并与 RPC Sever 建立连接。 当 RPC Server 节点发生变更时，Registry 会同步变更，RPC Client 感知后会刷新本地内存中缓存的服务节点列表。 RPC Client 从本地缓存的服务节点列表中，基于负载均衡算法选择一台 RPC Sever 发起调用。 当 RPC Server 节点发生变更时，RPC Client 可以通过拉取的方式获取最新服务节点。Registry 也可以推送节点变化的消息。 注册中心实现方式1. 注册中心 API 服务注册接口：服务提供者通过调用服务注册接口来完成服务注册。 服务反注册接口：服务提供者通过调用服务反注册接口来完成服务注销。 心跳汇报接口：服务提供者通过调用心跳汇报接口完成节点存活状态上报。 服务订阅接口：服务消费者通过调用服务订阅接口完成服务订阅，获取可用的服务提供者节点列表。 服务变更查询接口：服务消费者通过调用服务变更查询接口，获取最新的可用服务节点列表。 2. 集群部署注册中心作为服务提供者和服务消费者之间沟通的桥梁，它的重要性不言而喻。所以注册中心一般都是采用集群部署来保证高可用性，并通过分布式一致性协议来确保集群中不同节点之间的数据保持一致。 3. 目录存储注册中心存储服务信息一般采用层次化的目录结构。 4. 服务健康状态检测注册中心除了要支持最基本的服务注册和服务订阅功能以外，还必须具备对服务提供者节点的健康状态检测功能，这样才能保证注册中心里保存的服务节点都是可用的。 5. 服务状态变更通知一旦注册中心探测到有服务提供者节点新加入或者被剔除，就必须立刻通知所有订阅该服务的服务消费者，刷新本地缓存的服务节点信息，确保服务调用不会请求不可用的服务提供者节点。 参考 [从 0 开始学微服务 - 极客时间 - 胡忠想]","tags":[]},{"title":"00-微服务定义","date":"2022-04-15T16:00:00.000Z","path":"从0开始学微服务/00-微服务定义/","text":"12因素应用和微服务12-Factor 为构建如下的 SaaS 应用提供了方法论： 使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。 满足12 因素的app大概是这样的： 123456789101112131415161718192021222324I. 基准代码一份基准代码，多份部署II. 依赖显式声明依赖关系III. 配置在环境中存储配置IV. 后端服务把后端服务当作附加资源V. 构建，发布，运行严格分离构建和运行VI. 进程以一个或多个无状态进程运行应用VII. 端口绑定通过端口绑定提供服务VIII. 并发通过进程模型进行扩展IX. 易处理快速启动和优雅终止可最大化健壮性X. 开发环境与线上环境等价尽可能的保持开发，预发布，线上环境相同XI. 日志把日志当作事件流XII. 管理进程后台管理任务当作一次性进程运行 微服务作为一个概念是满足12因素的多应用方案，是一个可以具体落地的方案。 单体服务与微服务单体服务，以 MVC 架构为例，业务通常是通过部署一个 WAR 包到 Tomcat 中，然后启动 Tomcat，监听某个端口即可对外提供服务。早期在业务规模不大、开发团队人员规模较小的时候，采用单体应用架构，团队的开发和运维成本都可控。存在问题如下： 部署效率低下。 团队协作开发成本高。 系统高可用性差。 线上发布变慢。 服务化，就是把传统的单机应用中通过 JAR 包依赖产生的本地方法调用，改造成通过 RPC 接口产生的远程方法调用。通过服务化，可以解决单体应用膨胀、团队开发耦合度高、协作效率低下的问题。 单体服务的线上服务稳定容易被其他功能模块影响。 单体服务在进行多个功能模块开发的时候混合进行开发、测试部署。不同功能之间容易影响。 服务化的思想进一步演化，演变为今天我们所熟知的微服务。微服务相比于服务化的不同： 服务拆分粒度更细。 服务独立部署。 服务独立维护。 服务治理能力要求高。 常见的服务拆分方式： 纵向拆分，从业务角度拆分，按照业务的关联独立程度来决定。独立功能，关联较为深的拆分微服务。 横向拆分，从公共且独立功能维度拆分。多个公共服务被调用，且依赖资源独立不与其他业务耦合。 参考 12-factors app [从 0 开始学微服务 - 极客时间 - 胡忠想]","tags":[]},{"title":"01-微服务架构定义","date":"2022-04-15T16:00:00.000Z","path":"从0开始学微服务/01-微服务架构定义/","text":"基本组件微服务架构下，服务调用主要依赖下面几个基本组件： 服务描述 注册中心 服务框架 服务监控 服务追踪 服务治理 服务描述服务调用首先要解决的问题就是服务如何对外描述。 常用的服务描述方式包括 RESTful API、XML 配置以及 IDL 文件三种。 注册中心有了服务的接口描述，下一步要解决的问题就是服务的发布和订阅，就是说你提供了一个服务，如何让外部想调用你的服务的人知道。 注册中心的工作流程是： 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务。 注册中心返回服务提供者地址列表给服务消费者。 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者。 服务框架通过注册中心，服务消费者就可以获取到服务提供者的地址，有了地址后就可以发起调用。发起调用之前，服务框架需要解决问题如下： 服务通信采用什么协议。服务提供者和服务消费者之间以什么样的协议进行网络通信，是采用四层 TCP、UDP 协议，还是采用七层 HTTP 协议。 数据传输采用什么方式。服务提供者和服务消费者之间的数据传输采用哪种方式，是同步还是异步，是在单连接上传输，还是多路复用。 数据压缩格式。通常数据传输都会对数据进行压缩，来减少网络传输的数据量，从而减少带宽消耗和网络传输时间，比如常见的 JSON 序列化、 Java 对象序列化以及 Protobuf 序列化等。 服务监控一旦服务消费者与服务提供者之间能够正常发起服务调用，你就需要对调用情况进行监控，以了解服务是否正常。通常来讲，服务监控主要包括三个流程。 指标收集。就是要把每一次服务调用的请求耗时以及成功与否收集起来，并上传到集中的数据处理中心。 数据处理。有了每次调用的请求耗时以及成功与否等信息，就可以计算每秒服务请求量、平均耗时以及成功率等指标。 数据展示。数据收集起来，经过处理之后，还需要以友好的方式对外展示，才能发挥价值。通常都是将数据展示在 Dashboard 面板上，并且每隔 10s 等间隔自动刷新，用作业务监控和报警等。 服务追踪除了需要对服务调用情况进行监控之外，你还需要记录服务调用经过的每一层链路，以便进行问题追踪和故障定位。 服务追踪的工作原理大致如下： 服务消费者发起调用前，会在本地按照一定的规则生成一个 requestid，发起调用时，将 requestid 当作请求参数的一部分，传递给服务提供者。 服务提供者接收到请求后，记录下这次请求的 requestid，然后处理请求。如果服务提供者继续请求其他服务，会在本地再生成一个自己的 requestid，然后把这两个 requestid 都当作请求参数继续往下传递。 服务治理服务监控能够发现问题，服务追踪能够定位问题所在，而解决问题就得靠服务治理了。服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行。 单机故障。通常遇到单机故障，都是靠运维发现并重启服务或者从线上摘除故障节点。然而集群的规模越大，越是容易遇到单机故障，在机器规模超过一百台以上时，靠传统的人肉运维显然难以应对。而服务治理可以通过一定的策略，自动摘除故障节点，不需要人为干预，就能保证单机故障不会影响业务。 单 IDC 故障。你应该经常听说某某 App，因为施工挖断光缆导致大批量用户无法使用的严重故障。而服务治理可以通过自动切换故障 IDC 的流量到其他正常 IDC，可以避免因为单 IDC 故障引起的大批量业务受影响。 赖服务不可用。比如你的服务依赖依赖了另一个服务，当另一个服务出现问题时，会拖慢甚至拖垮你的服务。而服务治理可以通过熔断，在依赖服务异常的情况下，一段时期内停止发起调用而直接返回。 参考 [从 0 开始学微服务 - 极客时间 - 胡忠想]","tags":[]},{"title":"微服务核心组件分析","date":"2022-03-09T02:48:07.000Z","path":"编程/微服务框架介绍和技术细节/","text":"单体服务与微服务 单体服务的线上服务稳定容易被其他功能模块影响。 单体服务在进行多个功能模块开发的时候混合进行开发、测试部署。不同功能之间容易影响。 服务拆分方式： 纵向拆分，从业务角度拆分，按照业务的关联独立程度来决定。独立功能，关联较为深的拆分微服务。 横向拆分，从公共且独立功能维度拆分。多个公共服务被调用，且依赖资源独立不与其他业务耦合。 微服务框架解决的问题服务定义对于单体应用来说，不同功能模块之前相互交互时，通常是以类库的方式来提供各个模块的功能。无论采用哪种通讯协议，是 HTTP 还是 RPC，服务之间的调用都通过接口描述来约定，约定内容包括接口名、接口参数以及接口返回值。 服务管理 服务管理 服务发现 服务订阅 单体应用由于部署在同一个 WAR 包里，接口之间的调用属于进程内的调用。而拆分为微服务独立部署后，服务提供者该如何对外暴露自己的地址，服务调用者该如何查询所需要调用的服务的地址呢？这个时候你就需要一个类似登记处的地方，能够记录每个服务提供者的地址以供服务调用者查询，在微服务架构里，这个地方就是注册中心。 服务监控通常对于一个服务，我们最关心的是 QPS（调用量）、AvgTime（平均耗时）以及 P999（99.9% 的请求性能在多少毫秒以内）这些指标。这时候你就需要一种通用的监控方案，能够覆盖业务埋点、数据收集、数据处理，最后到数据展示的全链路功能。 服务治理拆分为微服务架构后，服务的数量变多了，依赖关系也变复杂了。比如一个服务的性能有问题时，依赖的服务都势必会受到影响。可以设定一个调用性能阈值，如果一段时间内一直超过这个值，那么依赖服务的调用可以直接返回，这就是熔断，也是服务治理最常用的手段之一。 故障定位在单体应用拆分为微服务之后，一次用户调用可能依赖多个服务，每个服务又部署在不同的节点上，如果用户调用出现问题，你需要有一种解决方案能够将一次用户请求进行标记，并在多个依赖的服务系统中继续传递，以便串联所有路径，从而进行故障定位。 微服务框架解决方案 服务管理 服务注册 服务订阅 服务调用 外部调用（网关） 内部调用（ESB） 服务框架 开发框架 远程调用 交互协议 服务治理 配置中心 熔断 负载均衡 服务定义 RESTful API（http协议） XML配置（PRC协议） IDL文件（跨语言服务调用） 服务追踪 调用链路 调用记录 Spring Cloud Spring CLoud Netflix zuul 服务路由 服务过滤器 eureka 服务注册 服务发现 Ribbon 客户端负载均衡 断路器 服务降级调用 Hystrix 控制面板 spring cloud config （配置中心） spring boot （开发框架） Spring Cloud Alibaba gateway nacos dubbo/springboot Spring Cloud Netflix 服务管理 Eureka 服务注册 服务订阅 服务调用 外部调用（网关） Zuul 内部调用（ESB）Feign 服务框架 开发框架 Spring boot 远程调用 Feign 交互协议 Rest协议 服务治理 配置中心 无，可使用spring cloud config （配置中心） 熔断 Hystrix工具 负载均衡 Ribbon客户端负载均衡 服务定义 RESTful API（http协议） 服务追踪 SkyWaliking\\ELK等框架集成 调用链路 调用记录 发展前景 Service Mesh: Service Mesh 是一种新型的用于处理服务与服务之间通信的技术，尤其适用以云原生应用形式部署的服务，能够保证服务与服务之间调用的可靠性。在实际部署时，Service Mesh 通常以轻量级的网络代理的方式跟应用的代码部署在一起，从而以应用无感知的方式实现服务治理。 Docker 能帮助解决服务运行环境可迁移问题的关键，就在于 Docker 镜像的使用上，实际在使用 Docker 镜像的时候往往并不是把业务代码、依赖的软件环境以及操作系统本身直接都打包成一个镜像，而是利用 Docker 镜像的分层机制，在每一层通过编写 Dockerfile 文件来逐层打包镜像。这是因为虽然不同的微服务依赖的软件环境不同，但是还是存在大大小小的相同之处，因此在打包 Docker 镜像的时候，可以分层设计、逐层复用，这样的话可以减少每一层镜像文件的大小。 参考 Spring Cloud -https://spring.io/projects/spring-cloud","tags":[{"name":"微服务","slug":"微服务","permalink":"https://r0ad.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"谈论架构师的时候到底在谈论什么","date":"2022-03-08T16:00:00.000Z","path":"技术人生/谈论架构的时候到底在谈论什么/","text":"同理心的修炼：认同他人的能力 你接手的代码量，比前面我们架构实战案例 “画图程序” 长得多，动辄几百万甚至上千万行的源代码。文档也要少得多，没有清晰的网络协议和接口文档，更别提详细设计文档。有句程序员界的名言：“程序员最讨厌的两件事情：一件事情是写文档，一件事情是接手的代码发现没文档”。这是很真实的对现实的写照。 最值得研究的是重构。重构不为改善用户体验，它的目标是为了改善系统质量，清除代码中的臭味。但现实中也有不小比例的重构实际上是在让问题变得更糟糕。 架构师最重要的是有同理心，要有认同他人的能力。不要在没有全面理解他人思想的情况下去调整既有代码的设计逻辑。 经验积累得多了，看到源代码就能很快体会别人的思想。这背后所依赖的，其实也是架构能力。架构师往往对一个需求场景会有多条实现路径的思考和评估。这样的思考和评估做多了，看到别人的代码就容易建立熟悉感，一眼看出别人的思路是什么。 全局观的修炼：保持好奇心与韧性 有了骨架，就有了全貌，有了全局的视角。 很多人都有关于 “广度” 与 “深度” 的辩证与困惑。全局观这件事情，对于心性上的修炼，比的是好奇心与韧性。 保持对这个世界的好奇心。看到新科技与新思想，先认同它，去体会它，理解它产生的需求背景与技术脉络，以此融入自己的知识体系。 怎么深耕，更多的是结合自己的工作内容和兴趣。很多工程师会有困惑，觉得自己的工作内容平淡无奇，没法让自己进步，但实际上瓶颈不在于工作内容，在于自己心性的修炼。 迭代能力的修炼：学会否定自己 关于码代码，不少优秀的工程师都有这样的体会：洋洋洒洒写了好多代码，过了半年一年，自己看着怎么看怎么不爽。 你是捏着鼻子忍着，继续接老板安排下来的新任务；还是，百忙里抽出一点时间，把之前写的代码改到你满意的样子。 通过迭代而升华。这是架构能力提升之路。你的收益不会只是你重构的那一个模块本身。通过重构，你建立了新的知识体系。它是内在根本性的变化，看不见但你自己可以体会得到。 从技能来说，我们可能把架构师能力去归结为：理需求的能力；读代码的能力；抽象系统的能力。 架构师修炼之道更难的是在心性上，这包括：同理心的修炼，认同他人的能力。全局观的修炼，保持好奇心和学习的韧性。迭代能力的修炼，学会反思，学会在自我否定中不断成长。 笔者认为架构师练成非一日之功，在于日积月累，平凡的事也能做出不平凡的事。核心点在于方法的使用，理解别人的框架（同理心），持续迭代和反思。 摘录自《许式伟的架构课 - 心性：架构师的修炼之道》。","tags":[]},{"title":"一种Vue组件引入报错解决方法","date":"2022-02-22T02:48:07.000Z","path":"编程/Vue组件引入报错解决方法/","text":"代码异常123456789101112131415vue.runtime.esm.js:587 [Vue warn]: Unknown custom element: &lt;search_ui&gt; - did you register the component correctly? For recursive components, make sure to provide the &quot;name&quot; option.found in---&gt; &lt;FormRenderHt&gt; at src\\components\\FormRender\\module\\form-ht.vue &lt;HTUi&gt; at src\\components\\FormRender\\widget\\element\\HT.vue &lt;ElRow&gt; &lt;ElForm&gt; at packages/form/src/form.vue &lt;FormRender&gt; at src\\components\\FormRender\\module\\form.vue &lt;FormRender2&gt; at src\\components\\FormRender\\module\\form2.vue &lt;ProductEdit&gt; at src\\views\\ordercreate\\product\\productInfoEdit.vue &lt;Index&gt; at src\\views\\ordercreate\\main\\index.vue &lt;App&gt; at src\\App.vue &lt;Root&gt; 原因分析 组件引入方法有问题，不符合vue语法。例如 import 和 components 都需要放入引入的自定义组件。 12345import FormRenderHt from &#x27;@/components/FormRender/module/form-ht&#x27;export default &#123; components: &#123; FormRenderHt &#125;,&#125; 组件引入方法无问题，不符合vue机制。 通过对比分析，排除第一种异常情况，聚焦在第二种情况。可能的原因出现在： 异步引入产生的组件延迟引入，一个同步异步问题。（解决，修改组件引入都为异步） 组件嵌套太多，vue本身不支持这么多嵌套。(排除，支持多级嵌套) 12345// FormRenderHt 内部存在异步组件， FormRenderHt的引入也采用懒加载引入const FormRenderHt = () =&gt; import(&#x27;@/components/FormRender/module/form-ht&#x27;)export default &#123; components: &#123; FormRenderHt &#125;,&#125; 参考 Vue 路由懒加载 - https://router.vuejs.org/zh/guide/advanced/lazy-loading.html","tags":[{"name":"前端编程","slug":"前端编程","permalink":"https://r0ad.github.io/tags/%E5%89%8D%E7%AB%AF%E7%BC%96%E7%A8%8B/"}]},{"title":"Java与JS去掉小数部分的方法","date":"2022-02-18T02:48:07.000Z","path":"编程/Java与JS去掉小数部分的方法/","text":"由于除法、编程语言等特性，小数计算总是可能无法获取到精确的结果。但是金额计算又要求有精确的结果，这样的矛盾可以通过整数计算加去除小数部分来获取想要的结果。 乘法： 单价为9.99元的某物品购买9个，总价为89.91元。 除法： 总价 89.90，数量为9，通过舍去小数部分的单价为 9.98。 解决办法： 将元为单位的金额乘以100换算为分进行计算，对结果取整，除以100获得真实金额。 1let price = Math.floor((89.90*100)/9)/100 JavaScript 处理方法JavaScript 去掉小数部分的方法常用的去掉小数部分的方法： Math.ceil(.6) // 向上取整，向上舍入到一个整数 Math.floor(.6) // 向下取整，向下舍入到一个整数 Math.round(.6) // 四舍五入，舍入到最近整数 Number.toFixed(n) 四舍六入五成双,保留小数 toFixed它是一个四舍六入五成双的方法(也叫银行家算法)，”四舍六入五成双”含义：对于位数很多的近似数，当有效位数确定后，其后面多余的数字应该舍去，只保留有效数字最末一位，这种修约（舍入）规则是“四舍六入五成双”，也即“4舍6入5凑偶”这里“四”是指≤4 时舍去，”六”是指≥6时进上，”五”指的是根据5后面的数字来定，当5后有数时，舍5入1；当5后无有效数字时，需要分两种情况来讲：①5前为奇数，舍5入1；②5前为偶数，舍5不进。（0是偶数） 1234var price = 10.99;var quantity = 7;var needPay = parseFloat(price * quantity);// needPay的正确结果应该是76.93元 但是运行后发现needPay为76.93000000000001 通过 Number.toFixed(2) 方法修正。 将元为单位的金额乘以100换算为分进行计算。s 1234var price = 10.99var quantity = 7var needPay = Math.floor(parseFloat(price*100 * quantity))/100;// parseFloat(price*100 * quantity)的计算结果是7693.000000000001 使用Math.floor()方法向下取整，再除100 即为正确的结果 JavaScript 保留小数两位的方法通过 Number.toFixed(2) 方法实现任意小数的保留 123456// 通过 Number.toFixed(2) 方法var price = 10.9var quantity = 7var needPay = Math.floor(parseFloat(price*100 * quantity))/100;var needPay2 = needPay.toFixed(2)// parseFloat(price*100 * quantity)的计算结果是7693.000000000001 使用Math.floor()方法向下取整，再除100 即为正确的结果 Java 处理方法Java 去掉小数部分的方法 Math.ceil(0.6) //向上取整，向上舍入到一个整数 Math.floor(0.6) //向下取整，向下舍入到一个整数 Math.round(0.6) //四舍五入，舍入到最近整数 1234double price = 10.99;double quantity = 7;double needPay = Math.floor(Double.valueOf(price*100 * quantity))/100;System.out.println(needPay); Java 保留小数两位的方法 DecimalFormat String.format(“%.2f”, f) NumberFormat 123456789101112131415161718192021222324252627282930313233public class BigDecimalFormat &#123; double f = 111231.5585; public void m1() &#123; BigDecimal bg = new BigDecimal(f); double f1 = bg.setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); System.out.println(f1); &#125; /** * DecimalFormat 转换最简便 */ public void m2() &#123; DecimalFormat df = new DecimalFormat(&quot;#.00&quot;); System.out.println(df.format(f)); &#125; /** * String.format打印最简便 */ public void m3() &#123; System.out.println(String.format(&quot;%.2f&quot;, f)); &#125; public void m4() &#123; NumberFormat nf = NumberFormat.getNumberInstance(); nf.setMaximumFractionDigits(2); System.out.println(nf.format(f)); &#125; public static void main(String[] args) &#123; BigDecimalFormat f = new BigDecimalFormat(); f.m1(); f.m2(); f.m3(); f.m4(); &#125;&#125; 参考 js金额计算解决精度问题 - 作者：春秋若北 - https://www.jianshu.com/p/efd798b235ad java保留小数点两位的4种方法 - https://www.cnblogs.com/yw09041432/p/5842204.html","tags":[]},{"title":"Spring 生态解决方案","date":"2022-02-15T16:00:00.000Z","path":"编程/Spring生态解决方案项目全景介绍/","text":"Microservices 微服务 Reactive 响应式编程 Event Driven 事件驱动编程 Cloud 云服务 Web Applications 网络服务应用 Serverless 无服务计算 Batch 批量计算 Spring 开发软件框架Microservices 微服务解决方案Spring Boot 可以作为最小单元进行微服务架构的开发。Spring Cloud 提供容错、易管理的微服务架构方案。 Microservice architectures are the ‘new normal’. Building small, self-contained, ready to run applications can bring great flexibility and added resilience to your code. Spring Boot’s many purpose-built features make it easy to build and run your microservices in production at scale. And don’t forget, no microservice architecture is complete without Spring Cloud ‒ easing administration and boosting your fault-tolerance. What are microservices? Microservices are a modern approach to software whereby application code is delivered in small, manageable pieces, independent of others. Why build microservices? Their small scale and relative isolation can lead to many additional benefits, such as easier maintenance, improved productivity, greater fault tolerance, better business alignment, and more. Microservices with Spring Boot 微服务开发框架Spring BootWith Spring Boot, your microservices can start small and iterate fast. That’s why it has become the de facto standard for Java™ microservices. Quickstart your project with Spring Initializr and then package as a JAR. With Spring Boot’s embedded server model, you’re ready to go in minutes. Microservice resilience with Spring Cloud 微服务治理Spring Cloud 提供完整的SaaS服务管理架构，包括： service discovery 服务发现 load-balancing 负载均衡 circuit-breaking 熔端 distributed tracing 分布式调用链路追踪 monitoring 应用监控 API gateway 开放能力网关 The distributed nature of microservices brings challenges. Spring helps you mitigate these. With several ready-to-run cloud patterns, Spring Cloud can help with service discovery, load-balancing, circuit-breaking, distributed tracing, and monitoring. It can even act as an API gateway. Build streaming data microservices with Spring Cloud Stream 微服务流式计算解决方案 Spring Cloud StreamSpring Cloud Stream 优点： 对多个消息中间件的api进行统一，使生产消费事件变得容易； 支持实时消息编码，高可用、事件驱动的一个体系。 Spring Cloud Stream makes it easy to consume and produce events, no matter which messaging platform you choose. Spring Cloud Stream connects your microservices with real-time messaging in just a few lines of code, to help you build highly scalable, event-driven systems. Manage microservices 微服务监控 distributed tracing 分布式调用链路追踪 monitoring 应用健康状态监控 提供可视化监控落地方案。 Spring Boot’s optional instrumentation framework, Micrometer, sends metrics straight to Prometheus, Atlas, and more to provide valuable insights. This is complemented by Spring Cloud’s Sleuth and Zipkin projects which offer distributed tracing so that you can follow along with what’s happening in real-time. Microservices on Cloud Foundry 云原生解决方案SpringBoot 可以作为 云原生软件架构的最小开发框架。 The small, stateless nature of microservices makes them ideal for horizontal scaling. Platforms like TAS and PKS can provide scalable infrastructure to match, with and greatly reduce your administrative overhead. Using cloud connectors, you can also consume multiple backend services with ease. Reactive 响应式编程响应式系统的特点有利于构建低延迟、高吞吐量的工作。Project Reactor和Spring产品组合一起使开发人员能够构建可响应，有弹性，有弹性和消息驱动的企业级响应式系统。 Reactive systems have certain characteristics that make them ideal for low-latency, high-throughput workloads. Project Reactor and the Spring portfolio work together to enable developers to build enterprise-grade reactive systems that are responsive, resilient, elastic, and message-driven. What is reactive processing? Reactive processing is a paradigm that enables developers build non-blocking, asynchronous applications that can handle back-pressure (flow control).响应式处理是使开发人员能够构建可处理背压（流控制）的非阻塞异步应用程序的范例。 Why use reactive processing? Reactive systems better utilize modern processors. Also, the inclusion of back-pressure in reactive programming ensures better resilience between decoupled components.响应式系统更好地利用了现代处理器。 另外，在响应式编程中包含背压可确保解耦组件之间具有更好的弹性。 Project Reactor 响应式编程项目Project Reactor is a fully non-blocking foundation with back-pressure support included. It’s the foundation of the reactive stack in the Spring ecosystem and is featured in projects such as Spring WebFlux, Spring Data, and Spring Cloud Gateway. 更多项目： https://projectreactor.io/ Reactive Microservices 响应式微服务工程One of the main reasons developers move from blocking to non-blocking code is efficiency. Reactive code does more work with fewer resources. Project Reactor and Spring WebFlux let developers take advantage of multi-core, next-generation processors—handling potentially massive numbers of concurrent connections. With reactive processing, you can satisfy more concurrent users with fewer microservice instances. Reactive Microservices With Spring Boot 使用 Spring Boot 的响应式微服务工程The Spring portfolio provides two parallel stacks. One is based on a Servlet API with Spring MVC and Spring Data constructs. The other is a fully reactive stack that takes advantage of Spring WebFlux and Spring Data’s reactive repositories. In both cases, Spring Security has you covered with native support for both stacks. Spring产品组合提供了两个并行技术栈。一种基于带有Spring MVC和Spring Data结构的Servlet API。 另一个是完全响应式技术栈，该技术栈利用了Spring WebFlux和Spring Data的响应式存储库。Spring Security为两种技术栈都提供了原生支持。 Integration with common technologies 与通用技术的集成方案以响应式访问和处理数据很重要。 MongoDB，Redis和Cassandra在Spring Data中都具有原生响应式支持。 许多关系数据库（Postgres，Microsoft SQL Server，MySQL，H2和Google Spanner）都通过R2DBC提供了响应式支持。 在消息传递领域，Spring Cloud Stream还支持对RabbitMQ和Kafka等平台的反应式访问。 Accessing and processing data in a reactive way is important. MongoDB, Redis, and Cassandra all have native reactive support in Spring Data. Many relational databases (Postgres, Microsoft SQL Server, MySQL, H2, and Google Spanner) have reactive support via R2DBC. In the world of messaging, Spring Cloud Stream also supports reactive access to platforms like RabbitMQ and Kafka. Event Driven 事件驱动编程事件驱动的系统反映了现代企业的实际工作方式-每天整天都有成千上万的小变化在发生。 Spring具有处理事件并使开发人员能够围绕事件进行开发的能力，这意味着您的应用将与您的业务保持同步。 Event-driven systems reflect how modern businesses actually work–thousands of small changes happening all day, every day. Spring’s ability to handle events and enable developers to build applications around them, means your apps will stay in sync with your business. Spring has a number of event-driven options to choose from： integration streaming cloud functions data flows Event-driven microservices 事件驱动微服务工程概念 When combined with microservices, event streaming opens up exciting opportunities—event-driven architecture being one common example. Spring simplifies the production, processing, and consumption of events, providing several useful abstractions. Streaming data 流式数据事件概念 Streaming data represents a constant flow of events. One example might be a stock ticker. Every time a stock price changes, a new event is created. It’s called “streaming data” because there are thousands of these events resulting in a constant stream of data. Integration 集成方案 事件驱动系统的核心是消息处理。The bedrock of any event-driven system is message handling.Connecting to message platforms, routing messages, transforming messages, processing messages. With Spring you can solve these integration challenges quickly. Spring Cloud StreamSpring Cloud Stream 是集成 Apache Kafka, RabbitMQ, Azure Event Hub 开源项目的一个方案。优化和简化代码编写过程。 当与Apache Kafka，RabbitMQ，Azure Event Hub等一起使用时，Spring Cloud Stream可提高您的生产力，并提供三个关键抽象来简化您的代码。 “Binders”与外部消息传递系统集成。 “Bindings”弥合了消息传递系统和代码之间的鸿沟。 “Messages”提供了代码用于发送和接收数据的结构。 Spring Cloud Stream还为配置、内容转换、错误处理、配置管理、使用者组、分区、监视和运行状况检查提供支持。 Spring Cloud Stream improves your productivity when working with Apache Kafka, RabbitMQ, Azure Event Hub, and more, providing three key abstractions to simplify your code. “Binders” integrate with external messaging systems. “Bindings” bridge the gap between the messaging systems and your code. “Messages” provide the structure that your code uses to send and receive data. Spring Cloud Stream also provides support for provisioning, content conversion, error handling, configuration management, consumer groups, partitioning, monitoring, and health checks. Spring Cloud FunctionSpring Cloud Function 提供使用 Spring API编写 FAAS 解决方案。 编写一次函数并在任何地方（AWS，Azure等）运行它们； 使用所有熟悉且全面的Spring API； 将多个函数（function）链接在一起以创建新的函数（function）； 对多个输入和输出的支持，使得更容易的进行合并、连接和其他更高级。 Spring Cloud Function, enables you to write functions once and run them anywhere (AWS, Azure, etc.), while continuing to use all the familiar and comprehensive Spring APIs. You can chain multiple functions together to create new capabilities. Support for multiple inputs and outputs brings merging, joining, and other more advanced use cases within easy reach. Spring Cloud Data FlowSpring Cloud Data Flow 处理多种多个数据源的获取和推送解决方案。 为开发人员提供了用于处理各种数据源和目标的一系列工具和自动化。 可帮助跨多个云原生平台开发，部署，管理和扩展高吞吐量流数据管道。 具有丰富的用户界面，可用于构建和监视应用程序。 Spring Cloud Data Flow offers developers a range of tools and automation for working with all kinds of data sources and destinations. Spring Cloud Data Flow helps you to develop, deploy, manage, and scale high-throughput streaming data pipelines across multiple cloud-native platforms. It also features a rich user interface for building and monitoring your applications. Spring Cloud Kafka StreamsSpring Cloud Stream 集成 Kafka 的定制 Binder 解决方案。 专注于开发人员的生产力，但是增加了对Kafka特定功能（如KStream，KTable和GlobalKTable）的支持。 负责连接到Kafka，以及创建、配置和维护流和主题。 Spring Cloud Stream provides a second, more specific binder solely for working with Kafka Streams. This special binder still focuses on developer productivity but adds support for Kafka-specific features like KStream, KTable, and GlobalKTable. As with regular Spring Cloud Stream, the binder also takes care of connecting to Kafka, as well as creating, configuring, and maintaining the streams and topics. Spring AMQP and Spring for Apache Kafka使用Spring编写消息中间件编写框架。 通过Spring AMQP和Spring for Apache Kafka项目，将Spring的核心概念应用于基于Kafka或RabbitMQ的消息传递解决方案的开发。 两者都包括“模板”（template）作为高级消息处理抽象，并通过 “侦听器容器”（listener container） 支持消息驱动的POJO。 With the Spring AMQP and Spring for Apache Kafka projects, you can apply core Spring concepts to the development of Kafka- or RabbitMQ-based messaging solutions. Both include “template” as a high-level message handling abstraction, and support message-driven POJOs with a “listener container.” Spring Integration应用程序集成是每个企业面临的挑战。Spring Integration 通过将流行的Spring编程模型扩展到包括所有最常见的集成模式来解决这个挑战。 Spring Connector 可用于消息传递平台、通信协议、文件系统和服务提供商，以及常见模式的实现，例如消息路由、数据转换和过滤器。 Application integration is a challenge for every enterprise. Spring Integration eases this burden by extending the popular Spring programming model to include all the most common integration patterns. There are ready made connectors for messaging platforms, communications protocols, file systems, and service providers, as well as implementations of common patterns like message routing, data transformation, and filters. CloudSpring Cloud 为构建SaaS平台提供了一整套解决方案。 开发分布式系统具有挑战性。 复杂性已从应用程序层转移到网络层，并要求服务之间进行更大的交互。 将代码设为“云原生”意味着要处理 12-Factor ，例如外部配置，无状态，日志记录以及连接到支持服务。 Spring Cloud 项目套件包含使应用程序在云中运行所需的许多服务。 Developing distributed systems can be challenging. Complexity is moved from the application layer to the network layer and demands greater interaction between services. Making your code ‘cloud-native’ means dealing with 12-factor issues such as external configuration, statelessness, logging, and connecting to backing services. The Spring Cloud suite of projects contains many of the services you need to make your applications run in the cloud. 软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论： 使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。 这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。 Spring Cloud architecture highlights 架构设计 Service discovery 服务发现在云服务中，应用程序不能总是知道其他服务的确切位置。 注册中心服务，比如Netflix Eureka，或者一个sidecar解决方案，比如HashiCorp Consul，都会有所帮助。 注册中心客户端，springcloud为流行的注册中心提供DiscoveryClient实现，比如Eureka、Consul、Zookeeper，甚至Kubernetes的内置系统。 服务负载均衡，springcloud负载均衡器可以在服务实例之间小心地分配负载。 In the cloud, applications can’t always know the exact location of other services. A service registry, such as Netflix Eureka, or a sidecar solution, such as HashiCorp Consul, can help. Spring Cloud provides DiscoveryClient implementations for popular registries such as Eureka, Consul, Zookeeper, and even Kubernetes’ built-in system. There’s also a Spring Cloud Load Balancer to help you distribute the load carefully among your service instances. API gateway 能力开发网关Spring Cloud Gateway 提供云架构中多客户端和多服务器访问权限、路由等问题的解决方案。 网关可以保护和路由消息、隐藏服务、限制负载以及许多其他有用的事情。 Spring Cloud Gateway 为您提供了对API层的精确控制。 集成了SpringCloud服务发现和客户端负载平衡解决方案，以简化配置和维护。 With so many clients and servers in play, it’s often helpful to include an API gateway in your cloud architecture. A gateway can take care of securing and routing messages, hiding services, throttling load, and many other useful things. Spring Cloud Gateway gives you precise control of your API layer, integrating Spring Cloud service discovery and client-side load-balancing solutions to simplify configuration and maintenance. Cloud configuration 在线配置Spring Cloud Config 提供多应用程序、多环境和多服务实例，动态配置、配置版本管理解决方案。 云架构中配置不能简单地嵌入到应用程序中。配置必须足够灵活，以应对多个应用程序、环境和服务实例，并在不停机的情况下处理动态更改。 Spring Cloud Config 旨在减轻这些负担，并提供与Git等版本控制系统的集成，以帮助您确保配置的安全。 In the cloud, configuration can’t simply be embedded inside the application. The configuration has to be flexible enough to cope with multiple applications, environments, and service instances, as well as deal with dynamic changes without downtime. Spring Cloud Config is designed to ease these burdens and offers integration with version control systems like Git to help you keep your configuration safe. Circuit breakers 服务断路器 分布式系统存在不可靠的情况。请求可能会遇到超时或完全失败。 断路器可以帮助缓解这些问题，Spring Cloud 断路器提供了三种流行的选择：Resilience4J、Sentinel或Hystrix。 Distributed systems can be unreliable. Requests might encounter timeouts or fail completely. A circuit breaker can help mitigate these issues, and Spring Cloud Circuit Breaker gives you the choice of three popular options: Resilience4J, Sentinel, or Hystrix. Tracing 服务追踪提供基于 Zipkin 的服务追踪方案。 Debugging distributed applications can be complex and take a long time. For any given failure, you might need to piece together traces of information from several independent services. Spring Cloud Sleuth can instrument your applications in a predictable and repeatable way. And when used in conjunction with Zipkin, you can zero in on any latency problems you might have. Testing 服务测试Contract-based 测试方案提高测试效率。 In the cloud, you get extra points for having reliable, trustworthy, stable APIs—but getting there can be a journey. Contract-based testing is one technique that high-performing teams often use to stay on track. It helps by formalizing the content of APIs and building tests around them to ensure code remains in check. Web Applications 网络应用Spring 提供完整的面向浏览器端的编码方案。 Spring makes building web applications fast and hassle-free. By removing much of the boilerplate code and configuration associated with web development, you get a modern web programming model that streamlines the development of server-side HTML applications, REST APIs, and bidirectional, event-based systems. Developer productivity 开发效率Spring Boot 作为一个开箱即用的框架、完整的工具生态可以提高开发效率。 Spring Boot is the starting point of your developer experience, whatever you’re building. Spring Boot is designed to get you up and running as quickly as possible, with minimal upfront configuration. With its embedded application servers, you can be serving in seconds. Spring’s out-of-the-box, production-ready features (like tracing, metrics, and health status) provide developers with deep insight into their applications. Finally, Spring supports multiple JVM languages: Java, Kotlin, and Groovy. Battle-tested security 安全测试Spring Security 支持工业级的授权协议，包括 SAML、OAuth、LDAP。 When it’s time to secure your web application, Spring Security supports many industry-standard authentication protocols, including SAML, OAuth, and LDAP. Get protection from top OWASP attacks, such as session fixation, clickjacking, cross-site request forgery, and more. Data access made easy 数据访问Spring 提供对大数据、关系数据、非关系数据和基于云服务数据的访问能力api。 Spring helps developers connect their web applications to a number of data stores. It supports relational and non-relational databases, map-reduce frameworks, and cloud-based data services. Serverless 无服务 无服务器应用程序利用现代云计算功能和抽象，让您将重点放在逻辑上，而不是基础设施上。 在无服务器环境中，您可以集中精力编写应用程序代码，而底层平台负责扩展、运行时、资源分配、安全性和其他“服务器”细节。 Serverless applications take advantage of modern cloud computing capabilities and abstractions to let you focus on logic rather than on infrastructure. In a serverless environment, you can concentrate on writing application code while the underlying platform takes care of scaling, runtimes, resource allocation, security, and other “server” specifics. What is serverless? 无服务器工作负载是“事件驱动的工作负载，与通常由服务器基础结构处理的方面无关。”诸如“要运行多少实例”和“要使用什么操作系统”之类的问题都由作为服务平台的函数（或FaaS）管理，使开发人员可以自由地关注业务逻辑。Serverless workloads are “event-driven workloads that aren’t concerned with aspects normally handled by server infrastructure.” Concerns like “how many instances to run” and “what operating system to use” are all managed by a Function as a Service platform (or FaaS), leaving developers free to focus on business logic. Serverless characteristics? Serverless applications have a number of specific characteristics, including: Event-driven code execution with triggers Platform handles all the starting, stopping, and scaling chores Scales to zero, with low to no cost when idle Stateless 无服务器应用程序具有许多特定特性，包括： 事件驱动的触发器代码执行 平台处理所有启动、停止和缩放任务 规模扩大成本为零，空闲时成本为零 无状态的 Serverless vs Traditional Stack 传统应用和无服务对比Function as a Service (FaaS) Event-driven execution. Developers delegate all server-specific tasks to the FaaS platform. Developers only write business logic that is invoked by the platform, allowing for a more resilient requirement evolution as business needs change. 事件驱动执行。 开发人员将所有特定于服务器的任务委托给FaaS平台。 开发人员只编写由平台调用的业务逻辑，允许随着业务需求的变化进行更具弹性的需求演化。 Traditional applications Must maintain server infrastructure (installing, configuring, patching, upgrading, etc.). Infrastructure scales in ways that might not be dynamic enough for the workload (wasting resources). Developers write integration code to deal with messaging platforms, HTTP request/responses, etc. 必须维护服务器基础设施（安装、配置、修补、升级等）。 基础设施的扩展方式可能不够动态，无法满足工作负载（浪费资源）。 开发人员编写集成代码来处理消息传递平台、HTTP请求/响应等。 Why Spring and Serverless? 选择 Spring Cloud Function原因 Spring产品组合提供了一个健壮的功能集合，可以在无服务器应用程序中使用。 无论是使用Spring数据访问数据，使用Spring集成的企业集成模式，还是使用Spring框架和projectreactor的最新反应式编程，Spring都能让开发人员从一开始就在无服务器的环境中工作。 Spring还可以帮助您的函数避免供应商锁定。Spring Cloud Function 提供的适配器允许您在其平台上运行代码时与特定于供应商的api分离。 The Spring portfolio provides a robust collection of functionality for use within serverless applications. Whether accessing data with Spring Data, using the enterprise integration patterns with Spring Integration, or using the latest in reactive programming with Spring Framework and Project Reactor, Spring lets developers be productive in a serverless environment from day one. Spring also helps your functions avoid vendor lock-in. The adapters provided by Spring Cloud Function let you decouple from vendor-specific APIs when running your code on their platform. In detail: Spring Cloud FunctionSpring Cloud Function 提供了一些功能，让Spring开发人员从无服务器或FaaS平台获益。 java.util.function 包是Spring云函数使用的编程模型的基础。简而言之，Spring云函数提供了： 编程风格的选择：反应式、命令式或混合式。 功能组合与顺应（如用被动语态组合祈使式功能）。 支持具有多个输入和输出的反应函数，让函数处理合并、连接和其他复杂的流操作。 输入和输出的透明类型转换。 针对目标平台（如projectriff、awslambda等）的部署打包功能；见下文）。 具有灵活签名的函数（POJO函数）,“如果它看起来像一个函数，那么它就是一个函数” Spring的习惯用法和编程模型的所有其他好处。 Spring Cloud Function 提供了适配器，可以在最常见的FaaS服务上运行您的函数，包括 AWS Lambda 、 Apache OpenWhisk 、 Microsoft Azure 和 Project Riff。 Spring Cloud Function provides capabilities that lets Spring developers take advantage of serverless or FaaS platforms. The java.util.function package from core Java serves as the foundation of the programming model used by Spring Cloud Function. In a nutshell, Spring Cloud Function provides: Choice of programming styles: reactive, imperative, or hybrid. Function composition and adaptation (such as composing imperative functions with reactive). Support for reactive function with multiple inputs and outputs to let functions handle merging, joining, and other complex streaming operations. Transparent type conversion of inputs and outputs. Packaging functions for deployments, specific to the target platform (such as Project Riff, AWS Lambda, and more; see below). Functions with flexible signatures (POJO functions) - “if it looks like a function, it’s a function” All other benefits of Spring’s idioms and programming model. Spring Cloud Function provides adaptors so that you can run your functions on the most common FaaS services including Amazon Lambda, Apache OpenWhisk, Microsoft Azure, and Project Riff. Batch 批处理有效处理大量数据的能力使它非常适合许多工作场景。 Spring Batch 实现的行业标准处理模式允许您在JVM上构建健壮的批处理作业。 通过从Spring产品组合中添加Spring引导和其他组件，可以构建任务关键型批处理应用程序（mission-critical batch applications）。 The ability of batch processing to efficiently process large amounts of data makes it ideal for many use cases. Spring Batch’s implementation of industry-standard processing patterns lets you build robust batch jobs on the JVM. Adding Spring Boot and other components from the Spring portfolio lets you build mission-critical batch applications. What is batch processing?Batch processing is the processing of a finite amount of data in a manner that does not require external interaction or interruption.批处理是以不需要外部交互或中断的方式处理有限数量的数据。 Why build batch processes?Batch processes are an extremely efficient way of processing large amounts of data. The ability to schedule and prioritize work based on SLAs lets you allocate resources for best utilization.批处理是处理大量数据的一种非常有效的方法。基于SLA的工作计划和优先级的能力使您能够分配资源以获得最佳利用率。 Batch processing with Spring Spring Batch 实际上是JVM上批处理的标准。 Spring Batch 对常见批处理模式（如基于块的处理和分区）的实现可以创建高性能、可伸缩的批处理应用程序，这些应用程序对于大多数任务关键型流程来说具有足够的弹性。 Spring Boot 提供了一个额外的生产级特性，可以让您加快批处理过程的开发。 Spring Batch is the de facto standard for batch processing on the JVM. Its implementation of common batch patterns, such as chunk-based processing and partitioning, lets you create high-performing, scalable batch applications that are resilient enough for your most mission-critical processes. Spring Boot provides an additional level of production-grade features to let you speed up the development of your batch processes. Batch processing in the cloud批处理非常适合云计算，尤其是基础设施即服务（IaaS）。Spring Batch可以很好的利用云特性，包括以按需、弹性可伸缩和容错方式运行应用程序的能力 Batch processing fits perfectly with cloud computing, and Infrastructure as a Service (IaaS), in particular. The ability to run applications in an on-demand, elastically scalable, and fault-tolerant manner are all cloud features that Spring Batch can use. Integration with common technologies Spring Batch 与其他 Spring API 的集成非常容易。 通过对文件、关系数据库和NoSQL存储的 ItemReader 和 ItemWriter 支持。 通过 Apache Kafka 和 RabbitMQ 提供的Spring数据和消息传递支持。 Spring Batch 能够即时处理大多数场景。 Spring Batch’s integration with other Spring APIs lets you be productive from day one. With ItemReader and ItemWriter support for files, relational databases and NoSQL stores support via Spring Data and messaging support through Apache Kafka and RabbitMQ, Spring Batch has the ability to handle most use cases out of the box. 参考 Spring IO Spring microservices Spring reactive Spring Event Driven Spring cloud Spring Web Applications Spring cloud Spring Serverless Spring Batch 12-factor","tags":[]},{"title":"常见经济周期说明","date":"2022-02-10T16:00:00.000Z","path":"技术人生/常见经济周期说明/","text":"经济学们家早就研究出了3-60年的循环周期。 每3-4年，企业的原材料库存会由空到满，由满到空，这个库存循环，叫基钦周期。 每8-10年，企业的生产设备就会由新购到淘汰，由淘汰到新采，这个设备更迭，是朱格拉周期。 每15-25年，房地产和建筑业就会由新建到过剩，由谷底到高峰，这个地产周期，叫库兹涅茨周期。 每45-60年，顶尖科技就会由兴盛到衰落，由衰落到新生，这个技术变革，叫康德拉季耶夫周期（也叫康波周期）。 每一个周期，都有萌芽、发展、高峰、衰退，如波浪起伏。 在萌芽期，创业氛围浓厚，英雄崭露头角，就像恒大当年，是广东地产四小虎， 在发展期，央行刺激经济，社会现金充足，有志者快马加鞭大干快上，各路大佬大鳄脱颖而出， 在高峰期，社会流动泛滥，股市一片红火，企业家不务正业泡女明星，白领们都想超越巴菲特， 在衰退期，各界收紧银根，杠杆纷纷暴雷，过剩产能出清，在萧条和反思中开启下一轮循环。 研究意义经济周期(Business cycle)：也称商业周期、景气循环， 经济周期一般是指经济活动沿着经济发展的总体趋势所经历的有规律的扩张和收缩。是国民总产出、总收入和总就业的波动，是国民收入或总体经济活动扩张与紧缩的交替或周期性波动变化。 过去把它分为繁荣、衰退、萧条和复苏四个阶段，表现在图形上叫衰退、谷底、扩张和顶峰更为形象，也是现在普遍使用的名称。 在市场经济条件下，企业家们越来越多地关心经济形势，也就是 “经济大气候”的变化。一个企业生产经营状况的好坏，既受其内部条件的影响，又受其外部宏观经济环境和市场环境的影响。 一个企业，无力决定它的外部环境，但可以通过内部条件的改善，来积极适应外部环境的变化，充分利用外部环境，并在一定范围内，改变自己的小环境，以增强自身活力，扩大市场占有率。因此，作为企业家对经济周期波动必须了解、把握，并能制订相应的对策来适应周期的波动，否则将在波动中丧失生机。 阶段定义两阶段法经济波动以经济中的许多成分普遍而同期地扩张和收缩为特征，持续时间通常为2到10年。现代宏观经济学中，经济周期发生在实际GDP相对于潜在GDP上升（扩张）或下降（收缩或衰退）的时候。每一个经济周期都可以分为上升和下降两个阶段。上升阶段也称为繁荣，最高点称为顶峰。然而，顶峰也是经济由盛转衰的转折点，此后经济就进入下降阶段，即衰退。衰退严重则经济进入萧条，衰退的最低点称为谷底。当然，谷底也是经济由衰转盛的一个转折点，此后经济进入上升阶段。经济从一个顶峰到另一个顶峰，或者从一个谷底到另一个谷底，就是一次完整的经济周期。现代经济学关于经济周期的定义，建立在经济增长率变化的基础上，指的是增长率上升和下降的交替过程。 经济周期波动的扩张阶段，是宏观经济环境和市场环境日益活跃的季节。这时，市场需求旺盛，订货饱满，商品畅销，生产趋升，资金周转灵便。企业的供、产、销和人、财、物都比较好安排。企业处于较为宽松有利的外部环境中。 经济周期波动的收缩阶段，企业生存法则。 四阶段法将经济周期分为四阶段：繁荣、衰退、萧条、复苏 (图) 经济周期的特点是国民总产出、总收入、总就业量的波动，它以大多数经济部门的扩张与收缩为标志。 经济衰退（Recession），指经济出现停滞或负增长的时期。不同的国家对衰退有不同的定义，但美国以经济连续两个季度出现负增长为衰退的定义被人们广泛使用。而在宏观经济学上通常定义为“在一年中，一个国家的国内生产总值（GDP）增长连续两个或两个以上季度出现下跌”。但是这个定义并未被全世界各国广泛接受。比如，美国国家经济研究局就将经济衰退定义成更为模糊的“大多数经济领域内的经济活动连续几个月出现下滑”。凯恩斯认为对商品总需求的减少是经济衰退的主要原因。 经济衰退的普遍特征：消费者需求、投资急剧下降；对劳动的需求、产出下降、企业利润急剧下滑、股票价格和利率一般也会下降。 经济萧条指规模广且持续时间长的衰退， 其明显特征是需求严重不足，生产相对严重过剩，销售量下降，价格低落，企业盈利水平极低，生产萎缩，出现大量破产倒闭，失业率增大。 成因外因论外因论认为,周期源于经济体系之外的因素——太阳黑子、战争、革命、选举、金矿或新资源的发现、科学突破或技术创新等等。 太阳黑子理论 太阳黑子理论把经济的周期性波动归因于太阳黑子的周期性变化。因为据说太阳黑子的周期性变化会影响气候的周期变化，而这又会影响农业收成，而农业收成的丰歉又会影响整个经济。太阳黑子的出现是有规律的，大约每十年左右出现一次，因而经济周期大约也是每十年一次。该理论由英国经济学家杰文斯(W.S. Jevons)于1875年提出的。 创新理论 创新(Innovation theory)是奥地利经济学家J·熊波特提出用以解释经济波动与发展的一个概念。所谓创新是指一种新的生产函数，或者说是生产要素的一种“新组合”。生产要素新组合的出现会刺激经济的发展与繁荣。当新组合出现时，老的生产要素组合仍然在市场上存在。新老组合的共存必然给新组合的创新者提供获利条件。而一旦用新组合的技术扩散，被大多数企业获得，最后的阶段——停滞阶段也就临近了。在停滞阶段，因为没有新的技术创新出现，因而很难刺激大规模投资，从而难以摆脱萧条。这种情况直到新的创新出现才被打破，才会有新的繁荣的出现。 总之，该理论把周期性的原因归之为科学技术的创新，而科学技术的创新不可能始终如一地持续不断的出现，从而必然有经济的周期性波动。 政治性理论 外因经济周期的一个主要例证就是政治性周期。政治性周期理论把经济周期性循环的原因归之为政府的周期性的决策（主要是为了循环解决通货膨胀和失业问题）。政治性周期的产生有三个基本条件： ①凯恩斯国民收入决定理论为政策制定者提供了刺激经济的工具。 ②选民喜欢高经济增长、低失业以及低通货膨胀的时期。 ③政治家喜欢连选连任。 内因论内因论认为, 周期源于经济体系内部——收入、成本、投资在市场机制作用下的必然现象。 纯货币理论 该理论主要由英国经济学家霍特里（R.Hawtrey）在1913-1933年的一系列著作中提出的。纯货币理论认为货币供应量和货币流通度直接决定了名义国民收入的波动，而且经济波动完全是由于银行体系交替地扩张和紧缩信用所造成的，尤其以短期利率起着重要的作用。 投资过度理论 投资过度理论把经济的周期性循环归因于投资过度。由于投资过多，与消费品生产相对比，资本品生产发展过快。资本品生产的过度发展促使经济进入繁荣阶段，但资本品过度生产从而导致的过剩又会促进经济进入萧条阶段。 消费不足理论 消费不足理论的出现较为久远。早期有西斯蒙第和马尔萨斯，近代则以霍布森为代表。该理论把经济的衰退归因于消费品的需求赶不上社会对消费品生产的增长。这种不足又根据源于国民收入分配不公所造成的过度储蓄。该理论一个很大的缺陷是，它只解释了经济周期危机产生的原因，而未说明其他三个阶段。因而在周期理论中，它并不占有重要位置。 心理理论 心理理论和投资过度理论是紧密相联的。该理论认为经济的循环周期取决于投资，而投资大小主要取决于业主对未来的预期。而预期却是一种心理现象，而心理现象又具有不确定性的特点。因此，经济波动的最终原因取决于人们对未来的预期。当预期乐观时，增加投资，经济步入复苏与繁荣，当预期悲观时，减少投资，经济则陷入衰退与萧条。随着人们情绪的变化，经济也就周期性地发生波动。 综合论经济周期的生成是诸多因素共同作用的结果；众多成因之间存在错综复杂的的交互影响；在不同的社会条件下，众因素之间会产生不同的组合与作用，故周期的具体进程多有不同；经济周期的具体进程对成因亦有重要影响。 根据对经济周期生成所起的主次作用，经济周期成因可分为基本因素与影响因素。 基本因素是指对经济周期的生成具有根本作用的原因或条件。 如“按资分配”；“货币职能进化”；“市场机制”；“私有制”；“人类自身特性”等。 它们对经济周期生成的作用关系可简示如下： “人类自身特性→私有制→市场机制→按资分配、货币职能进化→经济周期” 基础因素简释： （1）人类自身特性 人类自身所具有的总体特征。 其主要表现似可概括为：永无停歇的探索（客观世界与主观世界）；永不满足的追求（物质享受与精神享受）。 （2）私有制 在人类自身特性驱使下，科技水平与生产能力不断提高、社会财富不断增长，“私有制”萌芽、生根…… （3）市场机制 在私有制的基石上，崇尚自由竞争与自由交换的“市场机制”，成为发展经济的首选架构…… （4）按资分配 在私有制及市场机制的环境中，“按资分配”日渐占据重要地位…… （5）货币职能进化 在商品经济发展的初级阶段，货币作为“一般等价物”，其职能是流通手段、支付手段、价值尺度等（似可称为“原始职能”）；伴随着经济发展、财富累积与按资分配，货币职能出现了“进化”，具有了“投资手段”及“增殖功能”（似可称为“现代职能”），如人们可以将货币进行直接投资（购买股票等）或间接投资（存入银行等），以获取其增殖。 “货币职能进化”与“按资分配”互为因果，众多“消费者”纷纷成为“投资者”： 经济得到迅速发展；贫富差距不断扩大；社会消费力相对萎缩；产品日益过剩…… 影响因素是指对经济周期生成具有影响作用的原因或条件。 如各类天灾人祸（太阳黑子、战争动乱……）、科技重大进步、政策人为干预等等。 相互关系基本因素对周期生成起不可或缺的根本作用；其他因素对周期生成起重要的影响作用。 “一只蝴蝶在巴西扇动翅膀，有可能会在美国的德克萨斯引起一场龙卷风……”（洛伦兹，1979）。若将经济周期喻为龙卷风，“蝴蝶效应”似亦可诠释上述基本因素、其他因素的主要区别。“蝴蝶扇动翅膀”是生成龙卷风的其他因素，若无“大气环流”、“大海洋流”等基本因素，纵有千万只蝴蝶一起扇动翅膀，似仅能生成“风景”；反之，即若所有蝴蝶都不扇动翅膀，德克萨斯的龙卷风亦难销声匿迹…… 基本因素、其他因素之间会产生错综复杂的交互影响，其中包含着我们精神因素（如理念、欲望等心理活动及思考、想象能力等）的巨大力量；精神因素“附体”于基本因素与其他因素，互为因果的产生综合作用…… 它们的关系似可简示如下： 组合作用经济周期成因之间的交互影响生成组合作用。如： 人们的占有能力（或占有欲望）越来越趋向无穷大； 在无穷的占有能力的驱导下，在按资分配等因素的作用下，越来越多的资产（包括劳动力）转化为资本，生产力得到快速发展，但因自然资源（包括环境）的相对限制，生产力必然小于人们的占有能力； 贫富鸿沟不断加深：“穷人”受支付能力等制约、“富人”受生理能力等制约；人们的消费力（社会消费力）日益小于人们的生产力。 当“占有能力&gt;生产力&gt;消费力”成为常态，经济周期必然发生。 影响经济周期成因在不同的社会条件下，会有不同的表现形式并产生不同的组合与作用，故每次经济周期的具体进程多有不同；（即不同行业或产品表现为不同的兴衰存亡……）但经济周期基本进程较为一致。（图2实线所示部分） 经济周期的具体进程对经济周期成因亦有重要影响：经济周期进程中的相关信息经过交汇融合，以多种方式进行反馈，直接影响人们的心理预期与具体行为，使经济周期进程与经济周期成因产生循环影响。（图2虚线所示部分） 类型自19世纪中叶以来，人们在探索经济周期问题时，根据各自掌握的资料提出了不同长度和类型的经济周期。 短周期短周期是1923年英国经济学家基钦提出的一种为期3-4年的经济周期。基钦认为经济周期实际上有主要周期与次要周期2种。 主要周期即中周期，次要周期为3~4年一次的短周期。这种短周期就称基钦周期。 中周期朱格拉周期是1860年法国经济学家朱格拉提出的一种为期9~10年的经济周期。该周期是以国民收入、失业率和大多数经济部门的生产、利润和价格的波动为标志加以划分的。 长周期康德拉季耶夫周期是1926年俄国经济学家康德拉季耶夫提出的一种为期50-60年的经济周期。该周期理论认为，从18世纪末期以后，经历了三个长周期。 第一个长周期从1789年到1849 年，上升部分为25年，下降部分35 年，共60年。第二个长周期从1849年到1896 年，上升部分为24年，下降部分为23 年，共47年。第三个长周期从1896年起，上升部分为24年，1920年以后进入下降期。 建筑周期库兹涅茨周期是1930年美国经济学家库涅茨提出的一种为期15-25年，平均长度为20年左右的经济周期。由于该周期主要是以建筑业的兴旺和衰落这一周期性波动现象为标志加以划分的，所以也被称为“建筑周期”。 综合周期熊彼特周期： 1936年，熊彼特以他的“创新理论”为基础，对各种周期理论进行了综合分析后提出的。熊彼特认为，每一个长周期包括6 个中周期，每一个中周期包括三个短周期。短周期约为40个月，中周期约为910年，长周期为4860年。他以重大的创新为标志，划分了三个长周期。第一个长周期从18世纪80年代到1842年，是“产业革命时期”； 第二个长周期从1842年到1897年，是“蒸汽和钢铁时期”； 第三个长周期从1897年以后，是“电气、化学和汽车时期”。在每个长周期中仍有中等创新所引起的波动，这就形成若干个中周期。在每个中周期中还有小创新所引起的波动，形成若干个短周期。 经济周期理论的争论1939年，美籍奥地利人约瑟夫·阿洛伊斯·熊彼特综合融贯前人的论点，首次提出在资本主义的历史发展过程中，同时存在着长、中、短“三种周期”的理论。在这里，熊彼特沿袭了康德拉季耶夫的说法，把近百余年来资本主义的经济发展过程进一步分为三个“长波”，而且用“创新理论”作为基础，以各个时期的主要技术发明和它们的应用，以及生产技术的突出发展，作为各个“长波”的标志。“中周期”即为“尤格拉周期”。“短周期”即“短波”为“基钦周期”。熊彼特还宣称，上述几种周期并存而且相互交织的情况，正好进一步证明了他的“创新理论”的正确性。在他看来，一个“长波”大约包括有六个“中程周期”，而一个中程周期大约包含有三个“短波”。 当代英国经济学家阿瑟·刘易斯认为，标准的周期是持续时间为九年左右的“尤格拉周期”。这是第一个被确定的周期。大多数人在谈到“周期”时都是指的这个含义。这一评断，应该说比较符合实际。 对康德拉季耶夫周期，即使赞同它的人，也承认它存在明显的缺陷。问题在于，人们对九年左右的“尤格拉周期”研究关注比较多，而对四十至六十年的康德拉季耶夫周期研究关注比较少，特别是在美国经济比较繁荣的90年代以来，尤其如此。 相关影响当经济开始衰退之后，企业的产品滞销，企业经营状况恶化，股息、红利减少，股票价格下降。经济复苏时，企业产品的销量开始上升，企业经营状况好转，企业发放股息、红利，股价逐渐回升。当经济达到繁荣时，企业盈利状况良好，股息、红利增加，股票价格大幅上涨。 股息是指股份公司从提取了公积金、公益金的税后利润中按照股息率派发给股东的收益。红利是上市公司在进行利润分配时，分配给股东的利润。 参考 中国首富和山西首富，全都输给了周期的力量 经济周期 - 搜狗百科","tags":[]},{"title":"编码设计过程效率提升和开源工具完美使用指南","date":"2022-02-10T16:00:00.000Z","path":"技术人生/编码设计过程效率提升和开源工具完美使用指南/","text":"在日常的 Java Web 开发过程中，笔者已经能够找到所有的免费的编码软件和办公软件替代集合，其中大部分是开源的。以 MySql 数据库客户端为例，使用 MyCli 自动提示和高亮进行快速的 Sql 编写，基于 Python 语言编写。使用 PlantUml 能绘制出目前软件设计过程的建模图形，基于 Java 和 Graphviz。老牌的 WPS 能够满足日常办公 Offie 系列的文档编写和查阅，值得称赞的是在以 Windows Mac 为主流的软件氛围下，它提供的 Debian / CentOS 也很好用。还有一个值得注意的现象是有些免费软件是强强联合的产物，例如 VS Code 、 VirutualBox 、MySQL Workbench 。 工具确实提升了办公和开发的效率，过度的依赖工具却并不是好事。国外公司、组织或基金会大多数都以开源为导向的进行软件编写。开源并不等于无限制使用，因为涉及到很多开源协议。笔者这里不细提。至少目前在完全不用盗版软件的情况下可以完成编码、设计等任务。总的来说，开源作为一个全球的协作编码过程，让开发者或组织都受益。在开源的氛围中，站在巨人的肩膀上，个人开发者也可以很容易写出一个软件。 以下为全部工具集合。 编程语言 工具 开发者或组织 平台 官网 JAVA Eclipse Eclipse Foundation Windows/Linux https://www.eclipse.org/downloads/ JAVA Idea Community Jetbrains Windows/Linux https://www.jetbrains.com/idea/download/ Vue/Html5 VS Code Microsoft Corporation Windows/Linux https://code.visualstudio.com/ 思维导图 freemind Jörg Müller,Daniel Polansky etc. Windows/Linux http://freemind.sourceforge.net/ office 办公 WPS 金山办公 Windows/Linux https://www.wps.cn/ MySQL DBeaver 开源软件 Windows/Linux https://dbeaver.io/ MySQL HeidiSql Ansgar Becker Windows https://www.heidisql.com/ MySQL MyCli Thomas Roten(leader) Windows/Linux https://www.mycli.net/ UML PlantUml + VS Code PlantUml Windows/Linux https://plantuml.com/zh/ 虚拟机 VirutualBox Oracle Corporation Windows/Linux https://www.virtualbox.org/","tags":[]},{"title":"项目延期的解决办法","date":"2022-02-10T16:00:00.000Z","path":"技术人生/项目延期的解决办法/","text":"项目延期了，一个是会导致做了的东西没有价值，丧失了努力的动力。二个是项目挤压越来越多，导致后续跟不上项目迭代，加班加点越来越多。 导致项目延期的原因有很多： 需求变动，项目延后或者提前发布。 人员安排不合理，无法按时完成。 开发人员请假有事忙着其他的业务做。 来自军哥的解决办法分享： 提前识别依赖。前后端分离中的接口依赖，服务接口的依赖。 识别关键路径。新的迭代项目都有关键路径，比如电商环境的下单流程，提前打通关键流程就可以提高信心。 提前发布预生产环境。提前一天发布到预生产环境，倒逼产品测试。","tags":[]},{"title":"认真生活认真工作","date":"2022-02-09T16:00:00.000Z","path":"技术人生/认真生活认真工作/","text":"好好工作，好好读书，认真生活。 只需在日常生活中扮演好社会赋予自己的角色，或者对于自己应该做好的事情——公务、家务、学习——都要尽心尽力，孜孜不倦，锲而不舍。这个过程本身就是磨炼人格的修行。 第一种人，是不想工作但不得不工作的人。 1、 这种人，如果是员工，他们追求“钱多、舒适、宽容的工作”；如果是创业者，他们追求“赚快钱”。他们面对现实中容易失望，容易抱怨公司与外部环境，或经常跳槽，或浅尝辄止。2、 他们总以“没找到自己喜欢的工作”为借口，在工作中不用心，不耐烦，不全心全意投入。3、 碰到困难与挫折，容易找借口放弃努力。 第二种人，是赚钱第一、工作第二的人。 这种人对待工作与责任不很用心，只求完成不求完美，有时甚至为了赚钱而不择手段，牺牲工作与责任，损人利已。 这两类人，他们有一个共同点，就是都不尊重工作、不忠诚于工作与责任。对他们而言，工作不是生命真正的需求，是为了谋生不得不做的事情，是一旦有了条件后想要摆脱的事情。 第三种人，把工作当成修行的人。 1、他们是拥有“自我观照”与自我领导力的人.2、他们重塑完成了“工作能力人格”3、他们尊重工作，忠于职责，并喜爱之，享受之。4、他们是聚焦工作、引爆潜能、灵感横溢的人。5、他们是“自燃型”与知行合一的人。6、他们是快乐工作并身心健康的人。 用心做事，心里有你，并且他专注与热爱工作，精益求精，视工作为自己的尊严与生命的一部分。把平凡的工作做得不平凡，同时在工作中达到高级的人格与人生境界。 摘录自： https://mp.weixin.qq.com/s/ec03rH3srZW7FhzBNRslvQ","tags":[]},{"title":"规则3-数字-10条-不要使用BigDecimal对象构造浮点数据","date":"2022-02-06T16:00:00.000Z","path":"Java编码标准指南/规则3-数字-10条-不要使用BigDecimal对象构造浮点数据/","text":"因为浮点数字总是不准确的， 通过 new BigDecimal(double) 获取到的数据总是不准确的。 123456// Prints 0.1000000000000000055511151231257827021181583404541015625// when run in FP-strict modedouble d = 1.1;BigDecimal bd1 = new BigDecimal(d); // Noncompliant; see comment aboveBigDecimal bd2 = new BigDecimal(1.1); // Noncompliant; same resultSystem.out.println(String.format(&quot;bd1 %s bd2%s &quot;,bd1,bd2)); 通过 BigDecimal.valueOf能准确获取到数值。 通过字符串类型能够获取到准确的十进制数据。 123456double d = 1.1;BigDecimal bd1 = BigDecimal.valueOf(d);BigDecimal bd2 = new BigDecimal(&quot;1.1&quot;); // using String constructor will result in precise valueSystem.out.println(String.format(&quot;bd1 %s bd2%s &quot;,bd1,bd2)); 参考 NUM10-J. Do not construct BigDecimal objects from floating-point literals","tags":[]},{"title":"自由软件与 Richard Stallmen","date":"2021-11-29T16:00:00.000Z","path":"技术人生/自由软件与RichardStallmen/","text":"自由软件与 Richard Stallmen “自由软件”和“开源”基本上指的是同一范围的程序。然而，出于不同的价值观，它们对这些程序的看法大相径庭。自由软件运动为用户的计算自由而战斗；这是一个为自由和公正而战的运动。相反，开源理念重视的是实用优势而不是原则利害。我们因此不赞同开源运动，也不使用开源这个词。 “要说一个软件是“自由”的，这意味着它尊重用户的基本自由：自由地运行这个软件，学习和修改它，以及重新发布它的原版或修改版。这是个关于自由权利的问题，而非价格高低。我们讨论的自由是如同自由言论般的权利，不是免费赠饮一样的大派送。” “开源软件和自由软件这两个词在很大程度上描述的是同一类软件，但是它们所基于的价值观却有着本质上的区别。对于自由软件运动而言，自由软件是一个道德底线，是对用户自由的基本尊重。开源软件则与此不同，开源哲学考虑的是怎么做把软件做得“更好”—仅仅从实用的角度。开源的哲学里，非自由软件之所以不好，是因为他们采用了一种劣等的开发方式。” ”作为自由软件运动的成员，我们并不将开源阵营视为敌人。我们的敌人是专有（非自由）软件。但我们希望人们至少应该知道，我们所捍卫的是用户的自由。所以我们不愿被开源支持者们贴错标签。我们倡导的并不是 “开源”，我们反对的也不是 “闭源”。为了清楚起见，我们要避免使用这些词汇。” 自由软件是一种软件分发和开发模式以及自由的价值观，开源软件是一种软件分发和开发模式。 自由软件 &amp; 开源软件实践中，开源与自由软件的区别 首先有些开源许可证对用户过于苛刻，它们就没有被列为自由软件。比如，“Open Watcom”就非自由的，因为其许可证不允许修改该软件和私自使用该软件。 其次，当一个程序的源代码使用的是弱许可证，而非 copyleft，那么其可执行文件就能够附加额外的非自由条款。 最后很多产品带有检测可执行文件签名功能的计算机，它会禁止用户安装另外不同的可执行文件；而只有一家特权公司才能生产可执行文件或完全控制该产品。 开源软件在使用上存在限制，包括源码和终端。从而限制软件的自由。 不同的价值观可以得到类似的结论——可惜总有例外 开源的基本思路是：允许用户修改和再发布软件，是为了让软件更加强大和可靠。可惜这不是个必要条件。很多专有软件的开发者技术也很强。有些时候，哪怕专有软件不尊重用户的自由，依然可以开发出强大而可靠的软件。对于这个事实，自由软件支持者和开源阵营的人对此反应就会不同。 对于一个纯粹的开源狂热者来说—假设他没有被自由软件的理想所影响—可能会说，“你们（专有软件开发者）竟然没用我们的开发模型，还能开发出这么好的软件。这太让我感到意外了。能给我拷一份你们的软件吗？” 这样的态度会让专有软件的诡计得逞—剥夺我们的自由。 而自由软件支持者则会说，“您的软件非常吸引人，不过我更看重我的自由。很遗憾，我不得不放弃使用您的软件。我会用其他的方法完成我的工作，并支持一个实现类似功能的自由软件项目。”你若真心珍视你的自由，我们就可以用行动去捍卫它。 开源的基本思路是：允许用户修改和再发布软件，是为了让软件更加强大和可靠。这是一个开发模型，自由软件也在使用。 强大而可靠的软件，未必是个好东西 但是必须要明确，只有当软件尊重用户的自由时，我们才说软件是在为用户服务。倘若软件本身就有意剥夺用户自由，为其设置各种障碍，那么如此的软件更强大仅仅意味着更多的羁绊，更可靠也就意味着这些障碍难以克服。现实生活中，恶意流氓的功能在专有软件中比比皆是：监视用户，限制用户，后门，强制升级等等。而一些开源软件支持者们竟希望在他们的开源软件中实现类似功能。 迫于电影和唱片公司的压力，越来越多的个人软件被设计得有意限制用户的行为。这种恶意功能的官方讲法是数字版权管理（参见DefectiveByDesign.org）。这种功能与自由软件的核心精神完全背道而驰。说起来，这已然不仅是精神层面背道而驰了，在实际操作上，DRM 的开发者们试图让用户无法修改软件，甚至将此视为违法行为。 尽管如此，一些开源软件的支持者们依然提议开发所谓“开源DRM”软件。这背后的逻辑是：发布这些限制用户自由的软件的源代码，并且允许用户修改它，就可以造出更强大可靠的软件，来继续限制用户的自由。然后，这些软件会被拷贝到某个设备上一并卖到你手里，而那个设备则禁止你修改运行其上的软件。 这样的软件也许称得上是开源软件，并且也的确用的是开源的开发模式。但是它不可能成为自由软件，因为它根本没有尊重用户的自由。倘若说开源的开发模式可以成功地制造如此软件，并且让这些软件更强大更可靠，进而限制你我的自由，那只能说这次开源把一切变得更糟了。 开源软件，发布限制用户自由的软件的源代码，使用开源的开发模式。这种功能与自由软件的核心精神完全背道而驰。这些软件更强大更可靠，进而限制你我的自由，那只能说这次开源把一切变得更糟了。 令人生畏的自由 当年那些人之所以从自由软件运动中分裂出来，发起开源软件运动，主要原因就是因为“自由软件”的道德基础让不少人如坐针毡。的确如此，倘若说起道德，比如用户的自由，开发者的责任等等，往往会迫使人们去思考一些常被忽视的问题，好比说某些行为是否符合道德规范。这种说教确实会让人心生不快，有些人则因此把它们抛诸脑后，从此不闻不问。但这并非意味着，每当论及道德，我们就该退避三舍，闭口不谈。 遗憾的是，开源的领导者们恰恰是选择忽视了这些问题。他们意识到，只要在道德和自由方面装聋作哑，转而只讨论某些自由软件当下可以创收多少效益，就没准能让他们更高效地“卖”软件给一些特定用户，尤其是商业用户。 当开源支持者讨论到这些更深层次的问题时，他们通常的想法就是把源代码作为人类的“礼物”。假定专有软件不发布源代码在道义上是合法的，那么开源是一件好事，它超出了道义的要求。 从这套理论的观点看，这方法倒也真算行之有效了。开源这词说服了众多商业和个人用户，使得他们开始使用，甚至开发自由软件，由此扩大了我们的社区。然而如此的扩张仅仅是表面上的，停留在仅仅关注实用的层次上。由于开源的哲学仅仅停留在实用层面，进而阻碍了人们理解自由软件更深层次的含义。它为我们的社区添加了新鲜血液，却没能教会那些新人如何维持这样一个社区。至此为止，倒也还好，但它还不足以捍卫自由。把用户吸引到自由软件社区来，仅仅是万里长征的第一步，他们还需要懂得去成为自己自由的维护者。 这些没能理解自由软件含义的用户，早晚会出于某些实用角度的考虑，再转投专有软件。无数的软件公司已经开始做出这样的尝试吸引用户使用专有软件，哪怕是发行免费的专有软件。用户只有在懂得珍视自由软件赋予他们的自由之后，才会拒绝如此诱惑。所以，我们必须反复强调自由，才能渐渐扩散自由的理念。“保持沉默”的信条在商业化的过程中可能会有用，但过分强调它，让热爱自由被视为自私，则会害了整个社区。 开源软件专注于实用，阻碍了人们理解自由软件更深层次的含义。它还不足以捍卫自由，但是可以把用户吸引到自由软件社区来，他们还需要懂得去成为自己自由的维护者。没能理解自由软件含义的用户，早晚会出于某些实用角度的考虑，再转投专有软件。“保持沉默”的信条在商业化的过程中可能会有用，但过分强调它，让热爱自由被视为自私，则会害了整个社区。 “FLOSS”和“FOSS”自由软件强调的是软件使用和分发的自由。 FLOSS : Free(Libre) and Open Source Software FOSS: Free and Open Source Software To emphasize that “free software” refers to freedom and not to price, we sometimes write or say “free (libre) software,” adding the French or Spanish word that means free in the sense of freedom. In some contexts, it works to use just “libre software.” 为了强调“自由软件”指的是自由而不是价格，我们有时会使用“自由(Libre)软件”，加上法语或西班牙语的单词，意思是自由。在某些情况下也可以只使用“libre软件”。 思想的对手“自由”和“开放”是一对思想的对手。“自由软件”和“开源”却是不同的概念，虽然从大多数人看待软件的眼光来看，它们讨论的是同一个概念。当人们习惯于用“开源”表达和思考时，他们对自由软件运动哲学的理解和思考就受到了阻碍。如果他们已经把我们以及我们的软件和“开放”一词关联起来，那么在他们意识到我们的立场有所不同之前，我们就应该在思想上为他们敲响警钟。一切宣传“开放”一词的活动都会倾向于遮掩自由软件运动的意义。 所以，自由软件活动家都会被建议不要参与自称“开放”的活动。即使该活动本身是好的，你的每次参与都会由于推动了开源的概念而伤害到自由软件运动。有许多活动是“自由”或“libre”你的每次参与都会对自由软件运动是正面的支持。有这么多项目可选，为什么不选那些多些正面支持的呢？ “自由软件”和“开源”立场有所不同。参与自称“开放”的活动推动了开源的概念而伤害到自由软件运动。 引用 自由软件和开源软件的区别 GNU 和 Linux 之间的联系 FLOSS and FOSS","tags":[]},{"title":"02-01-使用Python语言和Numpy库来构建神经网络模型","date":"2021-11-11T16:00:00.000Z","path":"飞桨PaddlePaddle/02-01-使用Python语言和Numpy库来构建神经网络模型/","text":"02-01-使用Python语言和Numpy库来构建神经网络模型波士顿房价预测任务波士顿房价预测是一个经典的机器学习任务，类似于程序员世界的“Hello World”。和大家对房价的普遍认知相同，波士顿地区的房价受诸多因素影响。该数据集统计了13种可能影响房价的因素和该类型房屋的均价，期望构建一个基于13个因素进行房价预测的模型，如 图1 所示。 对于预测问题，可以根据预测输出的类型是连续的实数值，还是离散的标签，区分为回归任务和分类任务。因为房价是一个连续值，所以房价预测显然是一个回归任务。下面我们尝试用最简单的线性回归模型解决这个问题，并用神经网络来实现这个模型。 线性回归模型假设房价和各影响因素之间能够用线性关系来描述。 线性回归模型使用均方误差作为损失函数（Loss），用以衡量预测房价和真实房价的差异。 公式见参考。 线性回归模型的神经网络结构神经网络的标准结构中每个神经元由加权和与非线性变换构成，然后将多个神经元分层的摆放并连接形成神经网络。线性回归模型可以认为是神经网络模型的一种极简特例，是一个只有加权和、没有非线性变换的神经元（无需形成网络），如 图2 所示。 构建波士顿房价预测任务的神经网络模型深度学习不仅实现了模型的端到端学习，还推动了人工智能进入工业大生产阶段，产生了标准化、自动化和模块化的通用框架。不同场景的深度学习模型具备一定的通用性，五个步骤即可完成模型的构建和训练，如 图3 所示。 正是由于深度学习的建模和训练的过程存在通用性，在构建不同的模型时，只有模型三要素不同，其它步骤基本一致，深度学习框架才有用武之地。 源码地址： 1-2-build_neural_network_using_numpy.py 源码说明地址： 建模的第二步 设计模型 数据处理数据处理包含五个部分：数据导入、数据形状变换、数据集划分、数据归一化处理和封装load data函数。数据预处理后，才能被模型调用。 模型设计模型设计是深度学习模型关键要素之一，也称为网络结构设计，相当于模型的假设空间，即实现模型“前向计算”（从输入到输出）的过程。 训练配置模型设计完成后，需要通过训练配置寻找模型的最优值，即通过损失函数来衡量模型的好坏。训练配置也是深度学习模型关键要素之一。 训练过程上述计算过程描述了如何构建神经网络，通过神经网络完成预测值和损失函数的计算。训练过程是深度学习模型的关键要素之一，其目标是让定义的损失函数Loss尽可能的小，也就是说找到一个参数解使得损失函数取得极小值。 梯度下降法在现实中存在大量的函数正向求解容易，但反向求解较难，被称为单向函数，这种函数在密码学中有大量的应用。密码锁的特点是可以迅速判断一个密钥是否是正确的，但是即使获取到密码锁系统，无法破解出正确的密钥是什么（已知y，求x很难）。 这种情况特别类似于一位想从山峰走到坡谷的盲人，他看不见坡谷在哪（无法逆向求解出Loss导数为0时的参数值），但可以伸脚探索身边的坡度（当前点的导数值，也称为梯度）。那么，求解Loss函数最小值可以这样实现：从当前的参数取值，一步步的按照下坡的方向下降，直到走到最低点。这就是“梯度下降法”。 训练的关键是找到一组(w,b)，使得损失函数L取极小值。 他山之石 飞浆-使用Python语言和Numpy库来构建神经网络模型","tags":[]},{"title":"03-01-案例学习-手写数字识别任务","date":"2021-11-11T16:00:00.000Z","path":"飞桨PaddlePaddle/03-01-案例学习-手写数字识别任务/","text":"03-01-案例学习-手写数字识别任务数字识别是计算机从纸质文档、照片或其他来源接收、理解并识别可读的数字的能力，目前比较受关注的是手写数字识别。手写数字识别是一个典型的图像分类问题，已经被广泛应用于汇款单号识别、手写邮政编码识别等领域，大大缩短了业务处理时间，提升了工作效率和质量。 任务输入：一系列手写数字图片，其中每张图片都是28x28的像素矩阵。 任务输出：经过了大小归一化和居中处理，输出对应的0~9的数字标签。 MNIST数据集MNIST数据集是从NIST的Special Database 3（SD-3）和Special Database 1（SD-1）构建而来。Yann LeCun等人从SD-1和SD-3中各取一半数据作为MNIST训练集和测试集，其中训练集来自250位不同的标注员，且训练集和测试集的标注员完全不同。 MNIST数据集的发布，吸引了大量科学家训练模型。1998年，LeCun分别用单层线性分类器、多层感知器（Multilayer Perceptron, MLP）和多层卷积神经网络LeNet进行实验，使得测试集的误差不断下降（从12%下降到0.7%）。在研究过程中，LeCun提出了卷积神经网络（Convolutional Neural Network，CNN），大幅度地提高了手写字符的识别能力，也因此成为了深度学习领域的奠基人之一。 如今在深度学习领域，卷积神经网络占据了至关重要的地位，从最早LeCun提出的简单LeNet，到如今ImageNet大赛上的优胜模型VGGNet、GoogLeNet、ResNet等，人们在图像分类领域，利用卷积神经网络得到了一系列惊人的结果。 手写数字识别的模型是深度学习中相对简单的模型，非常适用初学者。正如学习编程时，我们输入的第一个程序是打印“Hello World！”一样。 在飞桨的入门教程中，我们选取了手写数字识别模型作为启蒙教材，以便更好的帮助读者快速掌握飞桨平台的使用。 构建手写数字识别的神经网络模型使用飞桨完成手写数字识别模型任务的代码结构如 图2 所示，与使用飞桨完成房价预测模型任务的流程一致，下面的章节中我们将详细介绍每个步骤的具体实现方法和优化思路。 数据处理飞桨提供了多个封装好的数据集API，涵盖计算机视觉、自然语言处理、推荐系统等多个领域，帮助读者快速完成深度学习任务。如在手写数字识别任务中，通过paddle.vision.datasets.MNIST可以直接获取处理好的MNIST训练集、测试集，飞桨API支持如下常见的学术数据集： mnist cifar Conll05 imdb imikolov movielens sentiment uci_housing wmt14 wmt16 通过paddle.vision.datasets.MNIST API设置数据读取器，代码如下所示。 12# 设置数据读取器，API自动读取MNIST数据训练集train_dataset = paddle.vision.datasets.MNIST(mode=&#x27;train&#x27;) 模型设计在房价预测深度学习任务中，我们使用了单层且没有非线性变换的模型，取得了理想的预测效果。在手写数字识别中，我们依然使用这个模型预测输入的图形数字值。其中，模型的输入为784维（28×28）数据，输出为1维数据，如 图6 所示。 输入像素的位置排布信息对理解图像内容非常重要（如将原始尺寸为28×28图像的像素按照7×112的尺寸排布，那么其中的数字将不可识别），因此网络的输入设计为28×28的尺寸，而不是1×784，以便于模型能够正确处理像素之间的空间信息。 下面以类的方式组建手写数字识别的网络。 训练配置训练配置需要先生成模型实例（设为“训练”状态），再设置优化算法和学习率（使用随机梯度下降SGD，学习率设置为0.001）。 训练过程训练过程采用二层循环嵌套方式，训练完成后需要保存模型参数，以便后续使用。 内层循环：负责整个数据集的一次遍历，遍历数据集采用分批次（batch）方式。 外层循环：定义遍历数据集的次数，本次训练中外层循环10次，通过参数EPOCH_NUM设置。 模型测试模型测试的主要目的是验证训练好的模型是否能正确识别出数字，包括如下四步： 声明实例 加载模型：加载训练过程中保存的模型参数， 灌入数据：将测试样本传入模型，模型的状态设置为校验状态（eval），显式告诉框架我们接下来只会使用前向计算的流程，不会计算梯度和梯度反向传播。 获取预测结果，取整后作为预测标签输出。 训练样本乱序、生成批次数据 训练样本乱序： 先将样本按顺序进行编号，建立ID集合index_list。然后将index_list乱序，最后按乱序后的顺序读取数据。 生成批次数据： 先设置合理的batch_size，再将数据转变成符合模型输入要求的np.array格式返回。同时，在返回数据时将Python生成器设置为yield模式，以减少内存占用。 校验数据有效性在实际应用中，原始数据可能存在标注不准确、数据杂乱或格式不统一等情况。因此在完成数据处理流程后，还需要进行数据校验，一般有两种方式： 机器校验：加入一些校验和清理数据的操作。 人工校验：先打印数据输出结果，观察是否是设置的格式。再从训练的结果验证数据处理和读取的有效性。 异步数据读取上面提到的数据读取采用的是同步数据读取方式。对于样本量较大、数据读取较慢的场景，建议采用异步数据读取方式。异步读取数据时，数据读取和模型训练并行执行，从而加快了数据读取速度，牺牲一小部分内存换取数据读取效率的提升，二者关系如 图4 所示。 同步数据读取：数据读取与模型训练串行。当模型需要数据时，才运行数据读取函数获得当前批次的数据。在读取数据期间，模型一直等待数据读取结束才进行训练，数据读取速度相对较慢。 异步数据读取：数据读取和模型训练并行。读取到的数据不断的放入缓存区，无需等待模型训练就可以启动下一轮数据读取。当模型训练完一个批次后，不用等待数据读取过程，直接从缓存区获得下一批次数据进行训练，从而加快了数据读取速度。 异步队列：数据读取和模型训练交互的仓库，二者均可以从仓库中读取数据，它的存在使得两者的工作节奏可以解耦。 使用飞桨实现异步数据读取非常简单，只需要两个步骤： 构建一个继承paddle.io.Dataset类的数据读取器。 通过paddle.io.DataLoader创建异步数据读取的迭代器。 他山之石 第二章：一个案例吃透深度学习（上）》1. 使用飞桨完成手写数字识别模型 第二章：一个案例吃透深度学习（上）》3.【手写数字识别】之数据处理","tags":[]},{"title":"02-00-机器学习和深度学习基础","date":"2021-11-07T16:00:00.000Z","path":"飞桨PaddlePaddle/02-00-机器学习和深度学习基础/","text":"02-00-机器学习和深度学习基础引言概括来说，人工智能、机器学习和深度学习覆盖的技术范畴是逐层递减的。 人工智能是研发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。由于这个定义只阐述了目标，而没有限定方法，因此实现人工智能存在的诸多方法和分支，导致其变成一个“大杂烩”式的学科。 机器学习确定模型参数确定参数的过程与科学家提出假说的方式类似，合理的假说至少可以解释所有的已知观测数据。如果未来观测到不符合理论假说的新数据，科学家会尝试提出新的假说。如天文史上，使用大圆和小圆组合的方式计算天体运行在中世纪是可以拟合观测数据的。但随着欧洲机械工业的进步，天文观测设备逐渐强大，越来越多的观测数据无法套用已有的理论，这促进了使用椭圆计算天体运行的理论假说出现。因此，模型有效的基本条件是能够拟合已知的样本，这给我们提供了学习有效模型的实现方案。 图3 是以HHH为模型的假设，它是一个关于参数www和输入XXX的函数，用H(w,X)H(w, X)H(w,X) 表示。模型的优化目标是H(w,X)H(w, X)H(w,X)的输出与真实输出YYY尽量一致，两者的相差程度即是模型效果的评价函数（相差越小越好）。那么，确定参数的过程就是在已知的样本上，不断减小该评价函数（H(w,X)H(w, X)H(w,X) 和YYY的差距）的过程，直到学习到一个参数www，使得评价函数的取值最小。这个衡量模型预测值和真实值差距的评价函数也被称为损失函数（损失Loss）。 图3：确定模型参数示意图 举例类比，机器如一个机械的学生一样，只能通过尝试答对（最小化损失）大量的习题（已知样本）来学习知识（模型参数www），并期望用学习到的知识（模型参数www）所代表的模型H(w,X)H(w, X)H(w,X)，回答不知道答案的考试题（未知样本）。最小化损失是模型的优化目标，实现损失最小化的方法称为优化算法，也称为寻解算法（找到使得损失函数最小的参数解）。参数www和输入XXX组成公式的基本结构称为假设。在牛顿第二定律的案例中，基于对数据的观测，我们提出了线性假设，即作用力和加速度是线性关系，用线性方程表示。由此可见，模型假设、评价函数（损失/优化目标）和优化算法是构成模型的三个部分。 图4：使用数据去计算假设g去逼近目标f 模型结构介绍那么构成模型的三个部分（模型假设、评价函数和优化算法）是如何支撑机器学习流程的呢？如图5 所示： 图5：机器执行学习的框架 模型假设 ：世界上的可能关系千千万，漫无目标的试探YYYXXX之间的关系显然是十分低效的。因此假设空间先圈定了一个模型能够表达的关系可能，如蓝色圆圈所示。机器还会进一步在假设圈定的圆圈内寻找最优的YYYXXX关系，即确定参数www。 评价函数：寻找最优之前，我们需要先定义什么是最优，即评价一个YYY~XXX关系的好坏的指标。通常衡量该关系是否能很好的拟合现有观测样本，将拟合的误差最小作为优化目标。 优化算法：设置了评价指标后，就可以在假设圈定的范围内，将使得评价指标最优（损失函数最小/最拟合已有观测样本）的YYY~XXX关系找出来，这个寻找的方法即为优化算法。最笨的优化算法即按照参数的可能，穷举每一个可能取值来计算损失函数，保留使得损失函数最小的参数作为最终结果。 从上述过程可以得出，机器学习的过程与牛顿第二定律的学习过程基本一致，都分为假设、评价和优化三个阶段： 假设：通过观察加速度aaa和作用力FFF的观测数据，假设aaa和FFF是线性关系，即a=w⋅Fa = w \\cdot Fa=w⋅F。 评价：对已知观测数据上的拟合效果好，即w⋅Fw \\cdot Fw⋅F计算的结果要和观测的aaa尽量接近。 优化：在参数www的所有可能取值中，发现w=1/mw=1/mw=1/m可使得评价最好（最拟合观测样本）。 机器执行学习任务的框架体现了其学习的本质是“参数估计”（Learning is parameter estimation）。在此基础上，许多看起来完全不一样的问题都可以使用同样的框架进行学习，如科学定律、图像识别、机器翻译和自动问答等，它们的学习目标都是拟合一个“大公式”，如 图6 所示。 图6：机器学习就是拟合一个“大公式” 深度学习机器学习算法理论在上个世纪90年代发展成熟，在许多领域都取得了成功。但平静的日子只延续到2010年左右，随着大数据的涌现和计算机算力提升，深度学习模型异军突起，极大改变了机器学习的应用格局。 那么相比传统的机器学习算法，其实两者在理论结构上是一致的，即：模型假设、评价函数和优化算法，其根本差别在于假设的复杂度，如 图6 所示。 图7：深度学习的模型复杂度难以想象 神经网络的基本概念人工神经网络包括多个神经网络层，如卷积层、全连接层、LSTM等，每一层又包括很多神经元，超过三层的非线性神经网络都可以被称为深度神经网络。通俗的讲，深度学习的模型可以视为是输入到输出的映射函数，如图像到高级语义（美女）的映射，足够深的神经网络理论上可以拟合任何复杂的函数。因此神经网络非常适合学习样本数据的内在规律和表示层次，对文字、图像和语音任务有很好的适用性。因为这几个领域的任务是人工智能的基础模块，所以深度学习被称为实现人工智能的基础也就不足为奇了。 神经网络结构如 图8 所示。 图8：神经网络结构示意图 神经元： 神经网络中每个节点称为神经元，由两部分组成： 加权和：将所有输入加权求和。 非线性变换（激活函数）：加权和的结果经过一个非线性函数变换，让神经元计算具备非线性的能力。 多层连接： 大量这样的节点按照不同的层次排布，形成多层的结构连接起来，即称为神经网络。 前向计算： 从输入计算输出的过程，顺序从网络前至后。 计算图： 以图形化的方式展现神经网络的计算逻辑又称为计算图。 深度学习的发展历程现今的神经网络和深度学习的设计理论是一步步趋于完善的。在这漫长的发展岁月中，一些取得关键突破的闪光时刻，值得我们这些深度学习爱好者们铭记，如 图9 所示。 图9：深度学习发展历程 1940年代：首次提出神经元的结构，但权重是不可学的。 50-60年代：提出权重学习理论，神经元结构趋于完善，开启了神经网络的第一个黄金时代。 1969年：提出异或问题（人们惊讶的发现神经网络模型连简单的异或问题也无法解决，对其的期望从云端跌落到谷底），神经网络模型进入了被束之高阁的黑暗时代。 1986年：新提出的多层神经网络解决了异或问题，但随着90年代后理论更完备并且实践效果更好的SVM等机器学习模型的兴起，神经网络并未得到重视。 2010年左右：深度学习进入真正兴起时期。随着神经网络模型改进的技术在语音和计算机视觉任务上大放异彩，也逐渐被证明在更多的任务，如自然语言处理以及海量数据的任务上更加有效。至此，神经网络模型重新焕发生机，并有了一个更加响亮的名字：深度学习。 深度学习成功所依赖的先决条件：大数据涌现、硬件发展和算法优化有关。 大数据是神经网络发展的有效前提。神经网络和深度学习是非常强大的模型，需要足够量级的训练数据。时至今日，之所以很多传统机器学习算法和人工特征依然是足够有效的方案，原因在于很多场景下没有足够的标记数据来支撑深度学习。深度学习的能力特别像科学家阿基米德的豪言壮语：“给我一根足够长的杠杆，我能撬动地球！”。深度学习也可以发出类似的豪言：“给我足够多的数据，我能够学习任何复杂的关系”。但在现实中，足够长的杠杆与足够多的数据一样，往往只能是一种美好的愿景。直到近些年，各行业IT化程度提高，累积的数据量爆发式地增长，才使得应用深度学习模型成为可能。 依靠硬件的发展和算法的优化。现阶段，依靠更强大的计算机、GPU、autoencoder预训练和并行计算等技术，深度学习在模型训练上的困难已经被逐渐克服。其中，数据量和硬件是更主要的原因。没有前两者，科学家们想优化算法都无从进行。 深度学习的研究和应用蓬勃发展早在1998年，一些科学家就已经使用神经网络模型识别手写数字图像了。但深度学习在计算机视觉应用上的兴起，还是在2012年ImageNet比赛上，使用AlexNet做图像分类。如果比较下1998年和2012年的模型，会发现两者在网络结构上非常类似，仅在细节上有所优化。在这十四年间，计算性能的大幅提升和数据量的爆发式增长，促使模型完成了从“简单的数字识别”到“复杂的图像分类”的跨越。 以深度学习为基础的人工智能技术，在升级改造众多的传统行业领域，存在极其广阔的应用场景。图11 选自艾瑞咨询的研究报告，人工智能技术不仅可在众多行业中落地应用（广度），同时，在部分行业（如安防）已经实现了市场化变现和高速增长（深度），为社会贡献了巨大的经济价值。 图11：以深度学习为基础的AI技术在各行业广泛应用 深度学习改变了AI应用的研发模式实现了端到端的学习深度学习改变了很多领域算法的实现模式。在深度学习兴起之前，很多领域建模的思路是投入大量精力做特征工程，将专家对某个领域的“人工理解”沉淀成特征表达，然后使用简单模型完成任务（如分类或回归）。而在数据充足的情况下，深度学习模型可以实现端到端的学习，即不需要专门做特征工程，将原始的特征输入模型中，模型可同时完成特征提取和分类任务，如 图12 所示。 图12：深度学习实现了端到端的学习 以计算机视觉任务为例，特征工程是诸多图像科学家基于人类对视觉理论的理解，设计出来的一系列提取特征的计算步骤，典型如SIFT特征。在2010年之前的计算机视觉领域，人们普遍使用SIFT一类特征+SVM一类的简单浅层模型完成建模任务。 说明： SIFT特征由David Lowe在1999年提出，在2004年加以完善。SIFT特征是基于物体上的一些局部外观的兴趣点而与影像的大小和旋转无关。对于光线、噪声、微视角改变的容忍度也相当高。基于这些特性，它们是高度显著而且相对容易撷取，在母数庞大的特征数据库中，很容易辨识物体而且鲜有误认。使用SIFT特征描述对于部分物体遮蔽的侦测率也相当高，甚至只需要3个以上的SIFT物体特征就足以计算出位置与方位。在现今的电脑硬件速度下和小型的特征数据库条件下，辨识速度可接近即时运算。SIFT特征的信息量大，适合在海量数据库中快速准确匹配。 实现了深度学习框架标准化除了应用广泛的特点外，深度学习还推动人工智能进入工业大生产阶段，算法的通用性导致标准化、自动化和模块化的框架产生，如 图13 所示。 图13：深度学习模型具有通用性特点 在此之前，不同流派的机器学习算法理论和实现均不同，导致每个算法均要独立实现，如随机森林和支撑向量机（SVM）。但在深度学习框架下，不同模型的算法结构有较大的通用性，如常用于计算机视觉的卷积神经网络模型（CNN）和常用于自然语言处理的长期短期记忆模型(LSTM)，都可以分为组网模块、梯度下降的优化模块和预测模块等。这使得抽象出统一的框架成为了可能，并大大降低了编写建模代码的成本。一些相对通用的模块，如网络基础算子的实现、各种优化算法等都可以由框架实现。建模者只需要关注数据处理，配置组网的方式，以及用少量代码串起训练和预测的流程即可。 在深度学习框架出现之前，机器学习工程师处于手工业作坊生产的时代。为了完成建模，工程师需要储备大量数学知识，并为特征工程工作积累大量行业知识。每个模型是极其个性化的，建模者如同手工业者一样，将自己的积累形成模型的“个性化签名”。而今，“深度学习工程师”进入了工业化大生产时代。只要掌握深度学习必要但少量的理论知识，掌握Python编程，即可在深度学习框架上实现非常有效的模型，甚至与该领域最领先的模型不相上下。建模这个被“老科学家”们长期把持的建模领域面临着颠覆，也是新入行者的机遇。 图14：深度学习工程师处于工业化大生产时代，“老科学家”长期积累的优势不再牢固 人生天地之间，若白驹过隙，忽然而已，每个人都希望留下自己的足迹。为何要学习深度学习技术，以及如何通过这本书来学习呢？一方面，深度学习的应用前景广阔，是极好的发展方向和职业选择。 参考 人工智能、机器学习、深度学习的关系","tags":[]},{"title":"02-02-深度学习框架-飞浆","date":"2021-11-07T16:00:00.000Z","path":"飞桨PaddlePaddle/02-02-深度学习框架-飞浆/","text":"02-02-深度学习框架-飞浆近年来深度学习在很多机器学习领域都有着非常出色的表现，在图像识别、语音识别、自然语言处理、机器人、网络广告投放、医学自动诊断和金融等领域有着广泛应用。面对繁多的应用场景，深度学习框架有助于建模者节省大量而繁琐的外围工作，更聚焦业务场景和模型设计本身。 深度学习框架优势使用深度学习框架完成模型构建有如下两个优势： 节省编写大量底层代码的精力：屏蔽底层实现，用户只需关注模型的逻辑结构。同时，深度学习工具简化了计算，降低了深度学习入门门槛。 省去了部署和适配环境的烦恼：具备灵活的移植性，可将代码部署到CPU/GPU/移动端上，选择具有分布式性能的深度学习工具会使模型训练更高效。 深度学习框架设计思路深度学习框架的本质是框架自动实现建模过程中相对通用的模块，建模者只实现模型个性化的部分，这样可以在“节省投入”和“产出强大”之间达到一个平衡。我们想象一下：假设你是一个深度学习框架的创造者，你期望让框架实现哪些功能呢？ 相信对神经网络模型有所了解的读者都会得出如 表1 所示的设计思路。在构建模型的过程中，每一步所需要完成的任务均可以拆分成个性化和通用化两个部分。 个性化部分：往往是指定模型由哪些逻辑元素组合，由建模者完成。 通用部分：聚焦这些元素的算法实现，由深度学习框架完成。 表1：深度学习框架设计示意图 无论是计算机视觉任务还是自然语言处理任务，使用的深度学习模型结构都是类似的，只是在每个环节指定的实现算法不同。因此，多数情况下，算法实现只是相对有限的一些选择，如常见的Loss函数不超过十种、常用的网络配置也就十几种、常用优化算法不超过五种等等。这些特性使得基于框架建模更像一个编写“模型配置”的过程。 飞桨开源深度学习平台全景飞桨（PaddlePaddle）以百度多年的深度学习技术研究和业务应用为基础，是中国首个开源开放、技术领先、功能完备的产业级深度学习平台，包括飞桨开源平台和飞桨企业版。飞桨开源平台包含核心框架、基础模型库、端到端开发套件与工具组件，持续开源核心能力，为产业、学术、科研创新提供基础底座。飞桨企业版基于飞桨开源平台，针对企业级需求增强了相应特性，包含零门槛AI开发平台EasyDL和全功能AI开发平台BML。EasyDL主要面向中小企业，提供零门槛、预置丰富网络和模型、便捷高效的开发平台；BML是为大型企业提供的功能全面、可灵活定制和被深度集成的开发平台。 飞桨开源平台（以下简称“飞桨”）全景图如 图2 所示。 图2：飞桨全景图 概览图上半部分是从开发、训练到部署的全流程工具，下半部分是预训练模型、各领域的开发套件和模型库等模型资源。 框架和全流程工具飞桨在提供用于模型研发的基础框架外，还推出了一系列的工具组件，来支持深度学习模型从训练到部署的全流程。 1. 模型训练组件飞桨提供了分布式训练框架FleetAPI，还提供了开启云上任务提交工具PaddleCloud。同时，飞桨也支持多任务训练，可使用多任务学习框架PALM。 2. 模型部署组件飞桨针对不同硬件环境，提供了丰富的支持方案： Paddle Inference：飞桨原生推理库，用于服务器端模型部署，支持Python、C、C++、Go等语言，将模型融入业务系统的首选。 Paddle Serving：飞桨服务化部署框架，用于云端服务化部署，可将模型作为单独的Web服务。 Paddle Lite：飞桨轻量化推理引擎，用于Mobile、IoT等场景的部署，有着广泛的硬件支持。 Paddle.js：使用JavaScript（Web）语言部署模型，用于在浏览器、小程序等环境快速部署模型。 PaddleSlim：模型压缩工具，获得更小体积的模型和更快的执行性能。 X2Paddle：飞桨模型转换工具，将其他框架模型转换成Paddle模型，转换格式后可以方便的使用上述5个工具。 3. 其他全研发流程的辅助工具 AutoDL：飞桨自动化深度学习工具，旨在自动网络结构设计，开源的AutoDL设计的图像分类网络在CIFAR10数据集正确率 达到 98%，效果优于目前已公开的10类人类专家设计的网络，居于业内领先位置。 VisualDL：飞桨可视化分析工具，以丰富的图表呈现训练参数变化趋势、模型结构、数据样本、高维数据分布、精度召回曲线等模型关键信息。帮助用户清晰直观地理解深度学习模型训练过程及模型结构，进而实现高效的模型调优、并将算法训练过程及结果分享。 PaddleFL：飞桨联邦学习框架，研究人员可以很轻松地用PaddleFL复制和比较不同的联邦学习算法，便捷地实现大规模分布式集群部署，并且提供丰富的横向和纵向联邦学习策略及其在计算机视觉、自然语言处理、推荐算法等领域的应用。此外，依靠着PaddlePaddle的大规模分布式训练和Kubernetes对训练任务的弹性调度能力，PaddleFL可以基于全栈开源软件轻松部署。 他山之石 深度学习框架-飞浆","tags":[]},{"title":"01-开发环境搭建","date":"2021-11-01T16:00:00.000Z","path":"飞桨PaddlePaddle/01-开发环境搭建/","text":"01-开发环境搭建开发环境需要安装Python。开发工具可以随意选择。 python 安装windows python工具下载 python官网 双击exe安装。 Linux 使用指令 apt install python3 。 验证在控制台输出： 12$ python --versionPython 3.10.0 开发工具 记事本 PyCharm Atom 安装飞浆飞浆网站提供的多版本安装说明。 飞浆网站-安装说明 基于cpu的安装指令： 1python -m pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple 测试安装成功： 1234python3import paddle paddle.utils.run_check()# 如果出现PaddlePaddle is installed successfully!，说明您已成功安装。","tags":[]},{"title":"00-学习材料","date":"2021-10-31T16:00:00.000Z","path":"飞桨PaddlePaddle/00-学习材料/","text":"00-学习材料在线材料 飞浆官网 飞浆官网 零基础实践深度学习 零基础实践深度学习 开发工具 python python官网 python 入门学习 Python 基础教程","tags":[]},{"title":"函数式编程简介","date":"2021-04-02T02:48:07.000Z","path":"编程/函数式编程简介/","text":"函数式编程原则just mapping not “do” or “calculate” denotational not operational (指示语义而不是操作语义) immutablility no side effecs 没有副作用 函数式编程优点不变性通常，函数式编程语言没有可变变量，一旦赋了值，就不能改变。这让代码行为更容易预测，并且减少了系统错误的数量，从而提高了系统的稳定性。 容错 容错是指即使出现错误，系统可以继续运行。有些函数式编程语言（如 Erlang）默认具有容错功能。 任意顺序结果都是一样的。 易于并行化，高度分布式函数式编程语言可以让你创建高度并行化和高度分布式的系统。用于迭代的内置函数（如 map 和 reduce）在区块链开发中发挥作用。 函数式编程模式MonadMonad 是函数式编程的一种实现模式，表示将一个运算过程，通过函数拆解成互相连接的多个步骤的运算。通过提供下一步运算所需的函数进行下一步运算。 半群Semigroup函数式编程中一个重要概念是组合， 一个聚合体或复杂元素是由很多小部分组合而成。但是不是所有的组合形式是一样的。 Map &amp; Reduce 通过map能遍历数组结构内部数据并且转换成想要的对象； 通过reduce能遍历数组转换成目标对象。 参考 函数式编程能否支持更高效的区块链基础设施？ 函数式编程精淬 图解 Monad - 阮一峰 函数式编程模式：半群Semigroup 函数式编程入门教程 - 阮一峰","tags":[]},{"title":"Hello World","date":"2021-04-01T02:48:07.000Z","path":"hello-world/","text":"hello hexo &amp; code-trend!","tags":[]}]